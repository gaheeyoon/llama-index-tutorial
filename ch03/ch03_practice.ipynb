{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "73e43106",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to send telemetry event ClientStartEvent: capture() takes 1 positional argument but 3 were given\n"
     ]
    }
   ],
   "source": [
    "import chromadb\n",
    "\n",
    "# 크로마 클라이언트 생성\n",
    "client = chromadb.Client()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cbfa3639",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to send telemetry event ClientCreateCollectionEvent: capture() takes 1 positional argument but 3 were given\n"
     ]
    }
   ],
   "source": [
    "# 벡터 컬렉션 생성\n",
    "collection = client.create_collection(\"example_collection\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3e5e8e9d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to send telemetry event CollectionAddEvent: capture() takes 1 positional argument but 3 were given\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "벡터 데이터를 컬렉션에 추가했습니다.\n"
     ]
    }
   ],
   "source": [
    "# 임베딩된 벡터 데이터 (예시로 임의 벡터 사용)\n",
    "vectors = [\n",
    "    [0.1, 0.2, 0.3], # 첫 번째 데이터의 벡터\n",
    "    [0.4, 0.5, 0.6], # 두 번째 데이터의 벡터\n",
    "    [0.7, 0.8, 0.9], # 세 번째 데이터의 벡터\n",
    "]\n",
    "\n",
    "# 벡터와 연결된 임의 고유 ID (각 벡터마다 고유한 ID 필요)\n",
    "ids = [\"doc1\", \"doc2\", \"doc3\"]\n",
    "\n",
    "# 벡터 데이터 추가\n",
    "collection.add(ids=ids, embeddings=vectors)\n",
    "print(\"벡터 데이터를 컬렉션에 추가했습니다.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8504944e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to send telemetry event CollectionQueryEvent: capture() takes 1 positional argument but 3 were given\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "유사한 벡터 검색 결과:\n",
      "{\n",
      "    \"검색된 문서 ID\": [\n",
      "        \"doc1\",\n",
      "        \"doc2\"\n",
      "    ],\n",
      "    \"유사도 거리\": [\n",
      "        0.002500001108273864,\n",
      "        0.30250000953674316\n",
      "    ]\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "# 검색할 벡터 (예시로 임의 벡터 사용)\n",
    "query_vector = [0.1, 0.2, 0.25]\n",
    "\n",
    "# 벡터 컬렉션에서 유사한 벡터 검색\n",
    "results = collection.query(query_embeddings=[query_vector], n_results=2)\n",
    "\n",
    "formatted_results = {\n",
    "    \"검색된 문서 ID\": results[\"ids\"][0],\n",
    "    \"유사도 거리\": results[\"distances\"][0]\n",
    "}\n",
    "\n",
    "print(\"\\n유사한 벡터 검색 결과:\")\n",
    "print(json.dumps(formatted_results, indent=4, ensure_ascii=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8ae9eaa6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to send telemetry event ClientCreateCollectionEvent: capture() takes 1 positional argument but 3 were given\n",
      "Failed to send telemetry event CollectionAddEvent: capture() takes 1 positional argument but 3 were given\n",
      "Failed to send telemetry event CollectionQueryEvent: capture() takes 1 positional argument but 3 were given\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "유사한 벡터 검색 결과:\n",
      "{\n",
      "    \"검색된 문서 ID\": [\n",
      "        \"doc1\"\n",
      "    ],\n",
      "    \"유사도 거리\": [\n",
      "        0.0\n",
      "    ],\n",
      "    \"메타데이터\": [\n",
      "        {\n",
      "            \"name\": \"example\",\n",
      "            \"category\": \"A\"\n",
      "        }\n",
      "    ]\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "collection = client.create_collection(\"metadata_example_collection\")\n",
    "\n",
    "# 임베딩된 벡터 데이터 및 메타데이터 추가\n",
    "vectors = [\n",
    "    [0.1, 0.2, 0.3], # 첫 번째 데이터 벡터\n",
    "    [0.4, 0.5, 0.6], # 두 번째 데이터 벡터\n",
    "    [0.7, 0.8, 0.9], # 세 번째 데이터 벡터\n",
    "]\n",
    "\n",
    "ids = [\"doc1\", \"doc2\", \"doc3\"]\n",
    "\n",
    "metadatas = [\n",
    "    {\"name\": \"example\", \"category\": \"A\"}, # 첫 번째 문서의 메타데이터\n",
    "    {\"name\": \"sample\", \"category\": \"B\"}, # 두 번째 문서의 메타데이터\n",
    "    {\"name\": \"example\", \"category\": \"C\"} # 세 번째 문서의 메타데이터\n",
    "]\n",
    "\n",
    "# 벡터 데이터 추가 (메타데이터 포함)\n",
    "collection.add(ids=ids, embeddings=vectors, metadatas=metadatas)\n",
    "\n",
    "results = collection.query(\n",
    "    query_embeddings=[[0.1, 0.2, 0.3]],\n",
    "    n_results=1,\n",
    "    where={\"name\": \"example\"} # 메타데이터 필터 적용\n",
    ")\n",
    "\n",
    "# 검색 결과 정리\n",
    "formatted_results = {\n",
    "    \"검색된 문서 ID\": results[\"ids\"][0] if results[\"ids\"] else [],\n",
    "    \"유사도 거리\": results[\"distances\"][0] if results[\"distances\"] else [],\n",
    "    \"메타데이터\": results[\"metadatas\"][0] if results[\"metadatas\"] else []\n",
    "}\n",
    "\n",
    "print(\"\\n유사한 벡터 검색 결과:\")\n",
    "print(json.dumps(formatted_results, indent=4, ensure_ascii=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "677da948",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting sentence-transformers\n",
      "  Using cached sentence_transformers-4.1.0-py3-none-any.whl.metadata (13 kB)\n",
      "Collecting transformers<5.0.0,>=4.41.0 (from sentence-transformers)\n",
      "  Using cached transformers-4.53.0-py3-none-any.whl.metadata (39 kB)\n",
      "Requirement already satisfied: tqdm in ./ch03_env/lib/python3.11/site-packages (from sentence-transformers) (4.67.1)\n",
      "Collecting torch>=1.11.0 (from sentence-transformers)\n",
      "  Using cached torch-2.7.1-cp311-none-macosx_11_0_arm64.whl.metadata (29 kB)\n",
      "Collecting scikit-learn (from sentence-transformers)\n",
      "  Using cached scikit_learn-1.7.0-cp311-cp311-macosx_12_0_arm64.whl.metadata (31 kB)\n",
      "Collecting scipy (from sentence-transformers)\n",
      "  Using cached scipy-1.16.0-cp311-cp311-macosx_14_0_arm64.whl.metadata (61 kB)\n",
      "Requirement already satisfied: huggingface-hub>=0.20.0 in ./ch03_env/lib/python3.11/site-packages (from sentence-transformers) (0.33.1)\n",
      "Requirement already satisfied: Pillow in ./ch03_env/lib/python3.11/site-packages (from sentence-transformers) (11.2.1)\n",
      "Requirement already satisfied: typing_extensions>=4.5.0 in ./ch03_env/lib/python3.11/site-packages (from sentence-transformers) (4.14.0)\n",
      "Requirement already satisfied: filelock in ./ch03_env/lib/python3.11/site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (3.18.0)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in ./ch03_env/lib/python3.11/site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (2025.5.1)\n",
      "Requirement already satisfied: packaging>=20.9 in ./ch03_env/lib/python3.11/site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (25.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in ./ch03_env/lib/python3.11/site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (6.0.2)\n",
      "Requirement already satisfied: requests in ./ch03_env/lib/python3.11/site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (2.32.4)\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.1.2 in ./ch03_env/lib/python3.11/site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (1.1.5)\n",
      "Requirement already satisfied: sympy>=1.13.3 in ./ch03_env/lib/python3.11/site-packages (from torch>=1.11.0->sentence-transformers) (1.14.0)\n",
      "Requirement already satisfied: networkx in ./ch03_env/lib/python3.11/site-packages (from torch>=1.11.0->sentence-transformers) (3.5)\n",
      "Collecting jinja2 (from torch>=1.11.0->sentence-transformers)\n",
      "  Using cached jinja2-3.1.6-py3-none-any.whl.metadata (2.9 kB)\n",
      "Requirement already satisfied: numpy>=1.17 in ./ch03_env/lib/python3.11/site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (1.26.4)\n",
      "Requirement already satisfied: regex!=2019.12.17 in ./ch03_env/lib/python3.11/site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (2024.11.6)\n",
      "Requirement already satisfied: tokenizers<0.22,>=0.21 in ./ch03_env/lib/python3.11/site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (0.21.2)\n",
      "Collecting safetensors>=0.4.3 (from transformers<5.0.0,>=4.41.0->sentence-transformers)\n",
      "  Using cached safetensors-0.5.3-cp38-abi3-macosx_11_0_arm64.whl.metadata (3.8 kB)\n",
      "Requirement already satisfied: joblib>=1.2.0 in ./ch03_env/lib/python3.11/site-packages (from scikit-learn->sentence-transformers) (1.5.1)\n",
      "Collecting threadpoolctl>=3.1.0 (from scikit-learn->sentence-transformers)\n",
      "  Using cached threadpoolctl-3.6.0-py3-none-any.whl.metadata (13 kB)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in ./ch03_env/lib/python3.11/site-packages (from sympy>=1.13.3->torch>=1.11.0->sentence-transformers) (1.3.0)\n",
      "Collecting MarkupSafe>=2.0 (from jinja2->torch>=1.11.0->sentence-transformers)\n",
      "  Using cached MarkupSafe-3.0.2-cp311-cp311-macosx_11_0_arm64.whl.metadata (4.0 kB)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in ./ch03_env/lib/python3.11/site-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (3.4.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in ./ch03_env/lib/python3.11/site-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in ./ch03_env/lib/python3.11/site-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in ./ch03_env/lib/python3.11/site-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (2025.6.15)\n",
      "Using cached sentence_transformers-4.1.0-py3-none-any.whl (345 kB)\n",
      "Using cached torch-2.7.1-cp311-none-macosx_11_0_arm64.whl (68.6 MB)\n",
      "Using cached transformers-4.53.0-py3-none-any.whl (10.8 MB)\n",
      "Using cached scikit_learn-1.7.0-cp311-cp311-macosx_12_0_arm64.whl (10.7 MB)\n",
      "Using cached scipy-1.16.0-cp311-cp311-macosx_14_0_arm64.whl (20.8 MB)\n",
      "Using cached safetensors-0.5.3-cp38-abi3-macosx_11_0_arm64.whl (418 kB)\n",
      "Using cached threadpoolctl-3.6.0-py3-none-any.whl (18 kB)\n",
      "Using cached jinja2-3.1.6-py3-none-any.whl (134 kB)\n",
      "Using cached MarkupSafe-3.0.2-cp311-cp311-macosx_11_0_arm64.whl (12 kB)\n",
      "Installing collected packages: threadpoolctl, scipy, safetensors, MarkupSafe, scikit-learn, jinja2, torch, transformers, sentence-transformers\n",
      "Successfully installed MarkupSafe-3.0.2 jinja2-3.1.6 safetensors-0.5.3 scikit-learn-1.7.0 scipy-1.16.0 sentence-transformers-4.1.0 threadpoolctl-3.6.0 torch-2.7.1 transformers-4.53.0\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.0\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.1.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install sentence-transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ff162e07",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/gaheeyoon/llamaindex/ch03/ch03_env/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "임베딩 결과: [-3.16610895e-02  9.91079956e-02  3.21413986e-02 -4.77648620e-03\n",
      "  2.06648074e-02 -4.26964127e-02  1.08513214e-01  5.91693372e-02\n",
      " -3.82518992e-02 -2.70917360e-02  1.10797763e-01 -3.27146016e-02\n",
      "  8.14444125e-02 -1.82765927e-02  3.63844149e-02 -3.83140966e-02\n",
      "  3.29664797e-02  3.95625792e-02 -2.65554264e-02 -3.17468233e-02\n",
      "  1.29390964e-02  2.19178889e-02  1.07889235e-01  1.24165481e-02\n",
      " -7.60593340e-02 -5.10003157e-02  3.95048931e-02  1.36652607e-02\n",
      "  8.86634663e-02 -4.19127233e-02  6.43823808e-03  4.20045890e-02\n",
      "  6.79684207e-02  1.37291215e-02  2.50339620e-02 -3.60205397e-02\n",
      " -4.92923744e-02 -1.51257599e-02 -4.84425500e-02  6.49661273e-02\n",
      " -5.19369319e-02 -3.22293006e-02  7.63611794e-02 -1.37317374e-01\n",
      "  1.76454727e-02  2.84964032e-02 -4.42443006e-02 -4.08116356e-02\n",
      " -6.28238097e-02  1.08337730e-01 -3.33937220e-02 -4.31645960e-02\n",
      " -5.31808920e-02  1.91285051e-02  4.64880913e-02 -5.00249416e-02\n",
      " -5.93597591e-02 -3.17170843e-02 -2.08584089e-02 -2.07601730e-02\n",
      "  2.15868503e-02  7.41537753e-03 -6.69788048e-02  7.33071044e-02\n",
      " -5.92239648e-02  8.28641094e-03  3.35812680e-02  3.57119665e-02\n",
      "  6.71475008e-03  3.45605873e-02  7.06920214e-03 -6.44721016e-02\n",
      "  5.00061102e-02 -1.81447379e-02 -9.14585665e-02 -3.30227502e-02\n",
      "  9.14647803e-02  1.37265045e-02  3.55795324e-02 -1.39514133e-02\n",
      " -5.63573390e-02  4.63783555e-03  5.35787409e-03 -1.38113252e-03\n",
      " -3.96536402e-02  1.42094279e-02 -6.29154593e-02  4.22117524e-02\n",
      "  1.74149021e-03  5.99134490e-02 -1.30139869e-02  9.44603980e-02\n",
      " -4.85079326e-02 -3.77961062e-03 -2.03624696e-01  2.03517335e-03\n",
      " -3.11783794e-02 -9.40064143e-04 -7.35910311e-02  2.52734683e-02\n",
      " -1.85040981e-02  7.12737516e-02  8.88845772e-02  9.34030786e-02\n",
      " -7.47099053e-03 -6.66724145e-02  7.08035231e-02 -6.93363026e-02\n",
      "  3.72661687e-02 -1.79751739e-02 -5.19382246e-02 -7.82708824e-02\n",
      " -6.83370009e-02 -6.63840622e-02  3.83139960e-02  4.25541587e-02\n",
      "  4.39657830e-02 -3.98182496e-02 -5.71763739e-02  2.55727880e-02\n",
      "  4.00999486e-02 -8.80820211e-03 -4.20923457e-02 -8.06470290e-02\n",
      " -7.13874251e-02 -6.66664392e-02  3.14591117e-02  4.67961473e-33\n",
      " -8.02345648e-02 -9.14916396e-03 -8.00388027e-03 -3.66544463e-02\n",
      " -1.00813426e-01 -2.28972198e-03 -3.61441337e-02  7.27768941e-03\n",
      " -2.48579942e-02 -1.61838606e-02 -1.81374215e-02 -1.00511676e-02\n",
      " -8.20064694e-02 -6.43664692e-03 -1.31859938e-02 -2.00741012e-02\n",
      " -7.15505034e-02  5.85352778e-02 -1.06153190e-02  7.33175129e-02\n",
      " -1.55127030e-02 -3.54481079e-02  2.02956535e-02 -5.73075050e-03\n",
      "  1.69442892e-02 -3.63551751e-02  3.28085124e-02  1.00962687e-02\n",
      " -2.43480597e-02  3.96641903e-02  4.54084240e-02 -1.14480425e-02\n",
      " -5.70797361e-02 -3.48400064e-02 -1.44315762e-02 -7.76138064e-03\n",
      "  4.22076732e-02  3.82221565e-02  2.25990973e-02 -2.56645749e-03\n",
      " -1.18878996e-03 -5.93661480e-02 -1.27160817e-01 -1.13444692e-02\n",
      "  4.09548618e-02  2.02995036e-02 -7.44119519e-03 -1.47838965e-02\n",
      "  4.96318638e-02 -6.91380352e-02 -5.33183403e-02  2.50073392e-02\n",
      " -1.39349625e-02  3.17271203e-02  7.68011436e-02  4.76932200e-03\n",
      "  9.34305936e-02 -1.11614102e-02 -1.58342477e-02 -1.09409532e-02\n",
      " -8.73262528e-03 -2.13815104e-02 -2.27431655e-02  6.69615269e-02\n",
      "  6.67219684e-02 -4.68352102e-02 -1.85794011e-02  9.28117149e-03\n",
      "  7.51932431e-03 -8.32175091e-02 -7.34891444e-02 -6.53106570e-02\n",
      "  7.53291836e-03  3.50094028e-02 -8.29220042e-02 -7.06544667e-02\n",
      " -4.11291197e-02  2.45150421e-02  3.25210728e-02  5.83253987e-02\n",
      " -5.98802902e-02 -3.90218459e-02 -5.08032413e-03 -1.32420450e-01\n",
      "  1.02178626e-01  3.26106511e-02  2.39515100e-02 -6.92930371e-02\n",
      "  3.15349363e-02  4.29909565e-02 -1.07068576e-01 -1.04299719e-02\n",
      "  1.02780042e-02  7.82946721e-02 -5.16480431e-02 -7.14460177e-33\n",
      " -3.02090608e-02  6.90772012e-02 -4.88003753e-02  1.18422933e-01\n",
      "  1.83583144e-02 -7.05937902e-03  1.34535255e-02  1.23545378e-01\n",
      "  1.78731289e-02  5.65703772e-02 -3.43708470e-02 -4.33189720e-02\n",
      " -3.50099383e-03  2.90891528e-02  9.60231479e-03  4.07433771e-02\n",
      " -7.12897070e-03  2.78969221e-02 -8.76686499e-02  4.65406291e-02\n",
      "  1.28062256e-02 -1.13073457e-03 -5.24803577e-03  7.04181269e-02\n",
      " -1.26896143e-01  5.34984246e-02  5.69460392e-02 -1.35531835e-02\n",
      " -1.04698325e-02 -5.59792155e-03 -6.43180450e-03 -3.46210711e-02\n",
      " -7.61579424e-02  1.57393947e-01 -4.60953824e-02 -5.30090742e-02\n",
      "  4.23092060e-02 -3.62291373e-02 -2.28072368e-02 -7.39242835e-03\n",
      "  4.40358697e-03 -2.92659388e-03 -1.57629643e-02  6.65431097e-02\n",
      " -5.82693378e-03  2.88600083e-02 -6.44207969e-02 -2.98014991e-02\n",
      " -1.46230003e-02 -1.02999978e-01  4.43609692e-02 -5.24196811e-02\n",
      "  1.70256235e-02 -4.94486019e-02  3.66594344e-02  3.23919319e-02\n",
      "  2.07389556e-02 -9.16029047e-03  1.60190798e-02 -4.52867884e-04\n",
      "  4.09052754e-03  4.33296058e-03  2.09116470e-02 -1.87266581e-02\n",
      " -1.54491076e-02 -1.82641484e-02  8.95997584e-02  1.78745501e-02\n",
      " -9.63139348e-03  2.41727941e-02  1.47490218e-01  6.78448677e-02\n",
      " -4.52523455e-02  2.69126892e-02 -1.25533670e-01  6.43150955e-02\n",
      " -3.35196964e-02  4.08308506e-02  2.28958726e-02 -1.72252022e-03\n",
      " -1.52880689e-02  4.21778783e-02  2.12994236e-02 -1.93989649e-03\n",
      " -6.89764172e-02 -9.53511596e-02  5.21997642e-03  3.24661583e-02\n",
      " -3.38602327e-02 -6.09839596e-02 -3.16624679e-02  5.24509735e-02\n",
      "  2.17930805e-02  3.47086564e-02 -3.96354869e-02 -3.52211593e-08\n",
      " -2.54983678e-02 -9.96224582e-02  1.12772984e-02  3.56350909e-03\n",
      "  5.32220490e-02 -4.71067391e-02 -8.66199955e-02  1.22780353e-02\n",
      "  4.96677458e-02 -3.51701453e-02  1.21939816e-01  2.34969426e-02\n",
      " -1.16927609e-01  7.96641633e-02 -2.05888655e-02 -5.92233017e-02\n",
      "  1.75307617e-02  9.98760238e-02 -2.40189605e-03 -3.89059149e-02\n",
      "  5.69635928e-02 -1.09146843e-02  3.23173441e-02 -6.62293211e-02\n",
      "  3.22820619e-02  5.84488623e-02 -9.97481346e-02  7.90634751e-02\n",
      " -1.63215993e-03 -3.97801623e-02  1.29723232e-02  3.09077334e-02\n",
      "  3.60473692e-02  2.48137712e-02  5.27277514e-02  8.96478444e-03\n",
      "  2.79558655e-02  6.22909106e-02  2.81839594e-02  3.46683413e-02\n",
      " -1.68703236e-02 -2.73347069e-02  4.88276742e-02  1.84639990e-02\n",
      "  4.25729267e-02 -7.54590658e-03  3.61319236e-03  2.42078267e-02\n",
      " -9.39819030e-03 -4.86300606e-03 -5.60014285e-02  3.21850479e-02\n",
      "  4.17101420e-02 -8.08182172e-03  8.99976958e-03  6.91673011e-02\n",
      "  8.48260801e-03 -2.58277152e-02  3.71954069e-02  3.10908188e-03\n",
      "  5.09527959e-02  4.52340543e-02 -4.94257323e-02 -3.19217220e-02]\n",
      "임베딩 차원: (384,)\n"
     ]
    }
   ],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "# 모델 로드\n",
    "model = SentenceTransformer('all-MiniLM-L6-v2')\n",
    "\n",
    "# 임베딩할 문장\n",
    "sentence = \"이것은 임베딩 예제입니다.\"\n",
    "\n",
    "# 문장 임베딩 생성\n",
    "embedding = model.encode(sentence)\n",
    "\n",
    "# 임베딩 출력\n",
    "print(\"임베딩 결과:\", embedding)\n",
    "print(\"임베딩 차원:\", embedding.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2094e340",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to send telemetry event ClientStartEvent: capture() takes 1 positional argument but 3 were given\n",
      "Failed to send telemetry event ClientCreateCollectionEvent: capture() takes 1 positional argument but 3 were given\n",
      "Failed to send telemetry event CollectionAddEvent: capture() takes 1 positional argument but 3 were given\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "벡터 데이터를 컬렉션에 추가했습니다.\n",
      "임베딩 차원: (3, 384)\n"
     ]
    }
   ],
   "source": [
    "client = chromadb.Client()\n",
    "collection = client.create_collection(\"example-collection\")\n",
    "\n",
    "# 임베딩 모델 초기화\n",
    "model = SentenceTransformer('all-MiniLM-L6-v2')\n",
    "\n",
    "documents = [\n",
    "    \"고양이는 작은 육식동물로, 주로 애완동물로 기릅니다. 민첩하고 장난기 있는 행동으로 유명합니다.\",\n",
    "    \"강아지는 충성심이 강하고 친절한 동물로, 흔히 인간의 최고의 친구로 불립니다. 주로 애완동물로 기르고, 동반자로서 유명합니다.\",\n",
    "    \"고양이와 강아지는 전 세계적으로 인기 있는 애완동물로, 각각 독특한 특징을 가지고 있습니다.\"\n",
    "]\n",
    "\n",
    "ids = [\"doc1\", \"doc2\", \"doc3\"]\n",
    "\n",
    "embeddings = model.encode(documents)\n",
    "\n",
    "# 벡터 데이터 추가\n",
    "collection.add(\n",
    "    ids=ids,\n",
    "    documents=documents,\n",
    "    embeddings=embeddings,\n",
    ")\n",
    "print(\"벡터 데이터를 컬렉션에 추가했습니다.\")\n",
    "print(\"임베딩 차원:\", embeddings.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "384e03d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to send telemetry event CollectionQueryEvent: capture() takes 1 positional argument but 3 were given\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "유사한 벡터 검색 결과:\n",
      "{\n",
      "    \"검색된 문서 ID\": [\n",
      "        \"doc1\",\n",
      "        \"doc3\"\n",
      "    ],\n",
      "    \"유사도 거리\": [\n",
      "        1.4484708309173584,\n",
      "        1.448585033416748\n",
      "    ]\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "query_text = \"고양이\"\n",
    "query_embedding = model.encode([query_text])\n",
    "\n",
    "# 벡터 컬렉션에서 유사한 벡터 검색\n",
    "results = collection.query(query_embeddings=query_embedding, n_results=2)\n",
    "\n",
    "formatted_results = {\n",
    "    \"검색된 문서 ID\": results[\"ids\"][0],\n",
    "    \"유사도 거리\": results[\"distances\"][0]\n",
    "}\n",
    "\n",
    "print(\"\\n유사한 벡터 검색 결과:\")\n",
    "print(json.dumps(formatted_results, indent=4, ensure_ascii=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e4b3217f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to send telemetry event ClientStartEvent: capture() takes 1 positional argument but 3 were given\n",
      "Failed to send telemetry event ClientCreateCollectionEvent: capture() takes 1 positional argument but 3 were given\n",
      "Failed to send telemetry event CollectionAddEvent: capture() takes 1 positional argument but 3 were given\n"
     ]
    }
   ],
   "source": [
    "from chromadb import PersistentClient\n",
    "\n",
    "client = PersistentClient(path=\"chroma_storage\") # 영구 저장 경로 설정\n",
    "collection = client.get_or_create_collection(\"persistent_collection\")\n",
    "\n",
    "# 컬렉션 생성 및 데이터 추가\n",
    "# 자동으로 디스크 저장됨\n",
    "collection.add(\n",
    "    embeddings=[[0.9, 0.8, 0.7]],\n",
    "    metadatas=[{\"name\": \"persistent_item\"}],\n",
    "    ids=[\"doc3\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0b9d5a29",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to send telemetry event ClientStartEvent: capture() takes 1 positional argument but 3 were given\n",
      "Failed to send telemetry event CollectionQueryEvent: capture() takes 1 positional argument but 3 were given\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "저장된 데이터 검색 결과:\n",
      "{\n",
      "    \"검색된 문서 ID\": [\n",
      "        \"doc3\"\n",
      "    ],\n",
      "    \"유사도 거리\": [\n",
      "        0.0\n",
      "    ],\n",
      "    \"메타데이터\": [\n",
      "        {\n",
      "            \"name\": \"persistent_item\"\n",
      "        }\n",
      "    ]\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "# Chroma 클라이언트 재시작 후 데이터를 불러옴\n",
    "client = PersistentClient(path=\"chroma_storage\")\n",
    "collection = client.get_collection(\"persistent_collection\")\n",
    "\n",
    "# 저장된 데이터 확인\n",
    "results = collection.query(\n",
    "    query_embeddings=[[0.9, 0.8, 0.7]],\n",
    "    n_results=1\n",
    ")\n",
    "\n",
    "# 검색 결과 정리\n",
    "formatted_results = {\n",
    "    \"검색된 문서 ID\": results[\"ids\"][0],\n",
    "    \"유사도 거리\": results[\"distances\"][0],\n",
    "    \"메타데이터\": results[\"metadatas\"][0]\n",
    "}\n",
    "print(\"\\n저장된 데이터 검색 결과:\")\n",
    "print(json.dumps(formatted_results, indent=4, ensure_ascii=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f3d985cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: llama-index==0.11.11 in ./ch03_env/lib/python3.11/site-packages (0.11.11)\n",
      "Collecting llama-index-vector-stores-chroma==0.3.0\n",
      "  Using cached llama_index_vector_stores_chroma-0.3.0-py3-none-any.whl.metadata (698 bytes)\n",
      "Collecting llama-index-embeddings-huggingface==0.3.0\n",
      "  Using cached llama_index_embeddings_huggingface-0.3.0-py3-none-any.whl.metadata (769 bytes)\n",
      "Requirement already satisfied: llama-index-agent-openai<0.4.0,>=0.3.4 in ./ch03_env/lib/python3.11/site-packages (from llama-index==0.11.11) (0.3.4)\n",
      "Requirement already satisfied: llama-index-cli<0.4.0,>=0.3.1 in ./ch03_env/lib/python3.11/site-packages (from llama-index==0.11.11) (0.3.1)\n",
      "Requirement already satisfied: llama-index-core<0.12.0,>=0.11.10 in ./ch03_env/lib/python3.11/site-packages (from llama-index==0.11.11) (0.11.23)\n",
      "Requirement already satisfied: llama-index-embeddings-openai<0.3.0,>=0.2.4 in ./ch03_env/lib/python3.11/site-packages (from llama-index==0.11.11) (0.2.5)\n",
      "Requirement already satisfied: llama-index-indices-managed-llama-cloud>=0.3.0 in ./ch03_env/lib/python3.11/site-packages (from llama-index==0.11.11) (0.6.0)\n",
      "Requirement already satisfied: llama-index-legacy<0.10.0,>=0.9.48 in ./ch03_env/lib/python3.11/site-packages (from llama-index==0.11.11) (0.9.48.post4)\n",
      "Requirement already satisfied: llama-index-llms-openai<0.3.0,>=0.2.9 in ./ch03_env/lib/python3.11/site-packages (from llama-index==0.11.11) (0.2.16)\n",
      "Requirement already satisfied: llama-index-multi-modal-llms-openai<0.3.0,>=0.2.0 in ./ch03_env/lib/python3.11/site-packages (from llama-index==0.11.11) (0.2.3)\n",
      "Requirement already satisfied: llama-index-program-openai<0.3.0,>=0.2.0 in ./ch03_env/lib/python3.11/site-packages (from llama-index==0.11.11) (0.2.0)\n",
      "Requirement already satisfied: llama-index-question-gen-openai<0.3.0,>=0.2.0 in ./ch03_env/lib/python3.11/site-packages (from llama-index==0.11.11) (0.2.0)\n",
      "Requirement already satisfied: llama-index-readers-file<0.3.0,>=0.2.0 in ./ch03_env/lib/python3.11/site-packages (from llama-index==0.11.11) (0.2.2)\n",
      "Requirement already satisfied: llama-index-readers-llama-parse>=0.3.0 in ./ch03_env/lib/python3.11/site-packages (from llama-index==0.11.11) (0.3.0)\n",
      "Requirement already satisfied: nltk>3.8.1 in ./ch03_env/lib/python3.11/site-packages (from llama-index==0.11.11) (3.9.1)\n",
      "Requirement already satisfied: chromadb>=0.5.17 in ./ch03_env/lib/python3.11/site-packages (from llama-index-vector-stores-chroma==0.3.0) (1.0.13)\n",
      "Requirement already satisfied: huggingface-hub>=0.19.0 in ./ch03_env/lib/python3.11/site-packages (from huggingface-hub[inference]>=0.19.0->llama-index-embeddings-huggingface==0.3.0) (0.33.1)\n",
      "Requirement already satisfied: sentence-transformers>=2.6.1 in ./ch03_env/lib/python3.11/site-packages (from llama-index-embeddings-huggingface==0.3.0) (4.1.0)\n",
      "Requirement already satisfied: build>=1.0.3 in ./ch03_env/lib/python3.11/site-packages (from chromadb>=0.5.17->llama-index-vector-stores-chroma==0.3.0) (1.2.2.post1)\n",
      "Requirement already satisfied: pydantic>=1.9 in ./ch03_env/lib/python3.11/site-packages (from chromadb>=0.5.17->llama-index-vector-stores-chroma==0.3.0) (2.11.7)\n",
      "Requirement already satisfied: pybase64>=1.4.1 in ./ch03_env/lib/python3.11/site-packages (from chromadb>=0.5.17->llama-index-vector-stores-chroma==0.3.0) (1.4.1)\n",
      "Requirement already satisfied: uvicorn>=0.18.3 in ./ch03_env/lib/python3.11/site-packages (from uvicorn[standard]>=0.18.3->chromadb>=0.5.17->llama-index-vector-stores-chroma==0.3.0) (0.35.0)\n",
      "Requirement already satisfied: numpy>=1.22.5 in ./ch03_env/lib/python3.11/site-packages (from chromadb>=0.5.17->llama-index-vector-stores-chroma==0.3.0) (1.26.4)\n",
      "Requirement already satisfied: posthog>=2.4.0 in ./ch03_env/lib/python3.11/site-packages (from chromadb>=0.5.17->llama-index-vector-stores-chroma==0.3.0) (6.0.0)\n",
      "Requirement already satisfied: typing-extensions>=4.5.0 in ./ch03_env/lib/python3.11/site-packages (from chromadb>=0.5.17->llama-index-vector-stores-chroma==0.3.0) (4.14.0)\n",
      "Requirement already satisfied: onnxruntime>=1.14.1 in ./ch03_env/lib/python3.11/site-packages (from chromadb>=0.5.17->llama-index-vector-stores-chroma==0.3.0) (1.22.0)\n",
      "Requirement already satisfied: opentelemetry-api>=1.2.0 in ./ch03_env/lib/python3.11/site-packages (from chromadb>=0.5.17->llama-index-vector-stores-chroma==0.3.0) (1.34.1)\n",
      "Requirement already satisfied: opentelemetry-exporter-otlp-proto-grpc>=1.2.0 in ./ch03_env/lib/python3.11/site-packages (from chromadb>=0.5.17->llama-index-vector-stores-chroma==0.3.0) (1.34.1)\n",
      "Requirement already satisfied: opentelemetry-sdk>=1.2.0 in ./ch03_env/lib/python3.11/site-packages (from chromadb>=0.5.17->llama-index-vector-stores-chroma==0.3.0) (1.34.1)\n",
      "Requirement already satisfied: tokenizers>=0.13.2 in ./ch03_env/lib/python3.11/site-packages (from chromadb>=0.5.17->llama-index-vector-stores-chroma==0.3.0) (0.21.2)\n",
      "Requirement already satisfied: pypika>=0.48.9 in ./ch03_env/lib/python3.11/site-packages (from chromadb>=0.5.17->llama-index-vector-stores-chroma==0.3.0) (0.48.9)\n",
      "Requirement already satisfied: tqdm>=4.65.0 in ./ch03_env/lib/python3.11/site-packages (from chromadb>=0.5.17->llama-index-vector-stores-chroma==0.3.0) (4.67.1)\n",
      "Requirement already satisfied: overrides>=7.3.1 in ./ch03_env/lib/python3.11/site-packages (from chromadb>=0.5.17->llama-index-vector-stores-chroma==0.3.0) (7.7.0)\n",
      "Requirement already satisfied: importlib-resources in ./ch03_env/lib/python3.11/site-packages (from chromadb>=0.5.17->llama-index-vector-stores-chroma==0.3.0) (6.5.2)\n",
      "Requirement already satisfied: grpcio>=1.58.0 in ./ch03_env/lib/python3.11/site-packages (from chromadb>=0.5.17->llama-index-vector-stores-chroma==0.3.0) (1.73.1)\n",
      "Requirement already satisfied: bcrypt>=4.0.1 in ./ch03_env/lib/python3.11/site-packages (from chromadb>=0.5.17->llama-index-vector-stores-chroma==0.3.0) (4.3.0)\n",
      "Requirement already satisfied: typer>=0.9.0 in ./ch03_env/lib/python3.11/site-packages (from chromadb>=0.5.17->llama-index-vector-stores-chroma==0.3.0) (0.16.0)\n",
      "Requirement already satisfied: kubernetes>=28.1.0 in ./ch03_env/lib/python3.11/site-packages (from chromadb>=0.5.17->llama-index-vector-stores-chroma==0.3.0) (33.1.0)\n",
      "Requirement already satisfied: tenacity>=8.2.3 in ./ch03_env/lib/python3.11/site-packages (from chromadb>=0.5.17->llama-index-vector-stores-chroma==0.3.0) (8.5.0)\n",
      "Requirement already satisfied: pyyaml>=6.0.0 in ./ch03_env/lib/python3.11/site-packages (from chromadb>=0.5.17->llama-index-vector-stores-chroma==0.3.0) (6.0.2)\n",
      "Requirement already satisfied: mmh3>=4.0.1 in ./ch03_env/lib/python3.11/site-packages (from chromadb>=0.5.17->llama-index-vector-stores-chroma==0.3.0) (5.1.0)\n",
      "Requirement already satisfied: orjson>=3.9.12 in ./ch03_env/lib/python3.11/site-packages (from chromadb>=0.5.17->llama-index-vector-stores-chroma==0.3.0) (3.10.18)\n",
      "Requirement already satisfied: httpx>=0.27.0 in ./ch03_env/lib/python3.11/site-packages (from chromadb>=0.5.17->llama-index-vector-stores-chroma==0.3.0) (0.28.1)\n",
      "Requirement already satisfied: rich>=10.11.0 in ./ch03_env/lib/python3.11/site-packages (from chromadb>=0.5.17->llama-index-vector-stores-chroma==0.3.0) (14.0.0)\n",
      "Requirement already satisfied: jsonschema>=4.19.0 in ./ch03_env/lib/python3.11/site-packages (from chromadb>=0.5.17->llama-index-vector-stores-chroma==0.3.0) (4.24.0)\n",
      "Requirement already satisfied: filelock in ./ch03_env/lib/python3.11/site-packages (from huggingface-hub>=0.19.0->huggingface-hub[inference]>=0.19.0->llama-index-embeddings-huggingface==0.3.0) (3.18.0)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in ./ch03_env/lib/python3.11/site-packages (from huggingface-hub>=0.19.0->huggingface-hub[inference]>=0.19.0->llama-index-embeddings-huggingface==0.3.0) (2025.5.1)\n",
      "Requirement already satisfied: packaging>=20.9 in ./ch03_env/lib/python3.11/site-packages (from huggingface-hub>=0.19.0->huggingface-hub[inference]>=0.19.0->llama-index-embeddings-huggingface==0.3.0) (25.0)\n",
      "Requirement already satisfied: requests in ./ch03_env/lib/python3.11/site-packages (from huggingface-hub>=0.19.0->huggingface-hub[inference]>=0.19.0->llama-index-embeddings-huggingface==0.3.0) (2.32.4)\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.1.2 in ./ch03_env/lib/python3.11/site-packages (from huggingface-hub>=0.19.0->huggingface-hub[inference]>=0.19.0->llama-index-embeddings-huggingface==0.3.0) (1.1.5)\n",
      "Requirement already satisfied: aiohttp in ./ch03_env/lib/python3.11/site-packages (from huggingface-hub[inference]>=0.19.0->llama-index-embeddings-huggingface==0.3.0) (3.12.13)\n",
      "Requirement already satisfied: openai>=1.14.0 in ./ch03_env/lib/python3.11/site-packages (from llama-index-agent-openai<0.4.0,>=0.3.4->llama-index==0.11.11) (1.93.0)\n",
      "Requirement already satisfied: SQLAlchemy>=1.4.49 in ./ch03_env/lib/python3.11/site-packages (from SQLAlchemy[asyncio]>=1.4.49->llama-index-core<0.12.0,>=0.11.10->llama-index==0.11.11) (2.0.41)\n",
      "Requirement already satisfied: dataclasses-json in ./ch03_env/lib/python3.11/site-packages (from llama-index-core<0.12.0,>=0.11.10->llama-index==0.11.11) (0.6.7)\n",
      "Requirement already satisfied: deprecated>=1.2.9.3 in ./ch03_env/lib/python3.11/site-packages (from llama-index-core<0.12.0,>=0.11.10->llama-index==0.11.11) (1.2.18)\n",
      "Requirement already satisfied: dirtyjson<2.0.0,>=1.0.8 in ./ch03_env/lib/python3.11/site-packages (from llama-index-core<0.12.0,>=0.11.10->llama-index==0.11.11) (1.0.8)\n",
      "Requirement already satisfied: filetype<2.0.0,>=1.2.0 in ./ch03_env/lib/python3.11/site-packages (from llama-index-core<0.12.0,>=0.11.10->llama-index==0.11.11) (1.2.0)\n",
      "Requirement already satisfied: nest-asyncio<2.0.0,>=1.5.8 in ./ch03_env/lib/python3.11/site-packages (from llama-index-core<0.12.0,>=0.11.10->llama-index==0.11.11) (1.6.0)\n",
      "Requirement already satisfied: networkx>=3.0 in ./ch03_env/lib/python3.11/site-packages (from llama-index-core<0.12.0,>=0.11.10->llama-index==0.11.11) (3.5)\n",
      "Requirement already satisfied: pillow>=9.0.0 in ./ch03_env/lib/python3.11/site-packages (from llama-index-core<0.12.0,>=0.11.10->llama-index==0.11.11) (11.2.1)\n",
      "Requirement already satisfied: tiktoken>=0.3.3 in ./ch03_env/lib/python3.11/site-packages (from llama-index-core<0.12.0,>=0.11.10->llama-index==0.11.11) (0.9.0)\n",
      "Requirement already satisfied: typing-inspect>=0.8.0 in ./ch03_env/lib/python3.11/site-packages (from llama-index-core<0.12.0,>=0.11.10->llama-index==0.11.11) (0.9.0)\n",
      "Requirement already satisfied: wrapt in ./ch03_env/lib/python3.11/site-packages (from llama-index-core<0.12.0,>=0.11.10->llama-index==0.11.11) (1.17.2)\n",
      "Requirement already satisfied: llama-cloud>=0.1.5 in ./ch03_env/lib/python3.11/site-packages (from llama-index-indices-managed-llama-cloud>=0.3.0->llama-index==0.11.11) (0.1.19)\n",
      "Requirement already satisfied: pandas in ./ch03_env/lib/python3.11/site-packages (from llama-index-legacy<0.10.0,>=0.9.48->llama-index==0.11.11) (2.3.0)\n",
      "Requirement already satisfied: beautifulsoup4<5.0.0,>=4.12.3 in ./ch03_env/lib/python3.11/site-packages (from llama-index-readers-file<0.3.0,>=0.2.0->llama-index==0.11.11) (4.13.4)\n",
      "Requirement already satisfied: pypdf<5.0.0,>=4.0.1 in ./ch03_env/lib/python3.11/site-packages (from llama-index-readers-file<0.3.0,>=0.2.0->llama-index==0.11.11) (4.3.1)\n",
      "Requirement already satisfied: striprtf<0.0.27,>=0.0.26 in ./ch03_env/lib/python3.11/site-packages (from llama-index-readers-file<0.3.0,>=0.2.0->llama-index==0.11.11) (0.0.26)\n",
      "Requirement already satisfied: llama-parse>=0.5.0 in ./ch03_env/lib/python3.11/site-packages (from llama-index-readers-llama-parse>=0.3.0->llama-index==0.11.11) (0.6.21)\n",
      "Requirement already satisfied: click in ./ch03_env/lib/python3.11/site-packages (from nltk>3.8.1->llama-index==0.11.11) (8.2.1)\n",
      "Requirement already satisfied: joblib in ./ch03_env/lib/python3.11/site-packages (from nltk>3.8.1->llama-index==0.11.11) (1.5.1)\n",
      "Requirement already satisfied: regex>=2021.8.3 in ./ch03_env/lib/python3.11/site-packages (from nltk>3.8.1->llama-index==0.11.11) (2024.11.6)\n",
      "Requirement already satisfied: transformers<5.0.0,>=4.41.0 in ./ch03_env/lib/python3.11/site-packages (from sentence-transformers>=2.6.1->llama-index-embeddings-huggingface==0.3.0) (4.53.0)\n",
      "Requirement already satisfied: torch>=1.11.0 in ./ch03_env/lib/python3.11/site-packages (from sentence-transformers>=2.6.1->llama-index-embeddings-huggingface==0.3.0) (2.7.1)\n",
      "Requirement already satisfied: scikit-learn in ./ch03_env/lib/python3.11/site-packages (from sentence-transformers>=2.6.1->llama-index-embeddings-huggingface==0.3.0) (1.7.0)\n",
      "Requirement already satisfied: scipy in ./ch03_env/lib/python3.11/site-packages (from sentence-transformers>=2.6.1->llama-index-embeddings-huggingface==0.3.0) (1.16.0)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in ./ch03_env/lib/python3.11/site-packages (from aiohttp->huggingface-hub[inference]>=0.19.0->llama-index-embeddings-huggingface==0.3.0) (2.6.1)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in ./ch03_env/lib/python3.11/site-packages (from aiohttp->huggingface-hub[inference]>=0.19.0->llama-index-embeddings-huggingface==0.3.0) (1.3.2)\n",
      "Requirement already satisfied: attrs>=17.3.0 in ./ch03_env/lib/python3.11/site-packages (from aiohttp->huggingface-hub[inference]>=0.19.0->llama-index-embeddings-huggingface==0.3.0) (25.3.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in ./ch03_env/lib/python3.11/site-packages (from aiohttp->huggingface-hub[inference]>=0.19.0->llama-index-embeddings-huggingface==0.3.0) (1.7.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in ./ch03_env/lib/python3.11/site-packages (from aiohttp->huggingface-hub[inference]>=0.19.0->llama-index-embeddings-huggingface==0.3.0) (6.6.2)\n",
      "Requirement already satisfied: propcache>=0.2.0 in ./ch03_env/lib/python3.11/site-packages (from aiohttp->huggingface-hub[inference]>=0.19.0->llama-index-embeddings-huggingface==0.3.0) (0.3.2)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in ./ch03_env/lib/python3.11/site-packages (from aiohttp->huggingface-hub[inference]>=0.19.0->llama-index-embeddings-huggingface==0.3.0) (1.20.1)\n",
      "Requirement already satisfied: soupsieve>1.2 in ./ch03_env/lib/python3.11/site-packages (from beautifulsoup4<5.0.0,>=4.12.3->llama-index-readers-file<0.3.0,>=0.2.0->llama-index==0.11.11) (2.7)\n",
      "Requirement already satisfied: pyproject_hooks in ./ch03_env/lib/python3.11/site-packages (from build>=1.0.3->chromadb>=0.5.17->llama-index-vector-stores-chroma==0.3.0) (1.2.0)\n",
      "Requirement already satisfied: anyio in ./ch03_env/lib/python3.11/site-packages (from httpx>=0.27.0->chromadb>=0.5.17->llama-index-vector-stores-chroma==0.3.0) (4.9.0)\n",
      "Requirement already satisfied: certifi in ./ch03_env/lib/python3.11/site-packages (from httpx>=0.27.0->chromadb>=0.5.17->llama-index-vector-stores-chroma==0.3.0) (2025.6.15)\n",
      "Requirement already satisfied: httpcore==1.* in ./ch03_env/lib/python3.11/site-packages (from httpx>=0.27.0->chromadb>=0.5.17->llama-index-vector-stores-chroma==0.3.0) (1.0.9)\n",
      "Requirement already satisfied: idna in ./ch03_env/lib/python3.11/site-packages (from httpx>=0.27.0->chromadb>=0.5.17->llama-index-vector-stores-chroma==0.3.0) (3.10)\n",
      "Requirement already satisfied: h11>=0.16 in ./ch03_env/lib/python3.11/site-packages (from httpcore==1.*->httpx>=0.27.0->chromadb>=0.5.17->llama-index-vector-stores-chroma==0.3.0) (0.16.0)\n",
      "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in ./ch03_env/lib/python3.11/site-packages (from jsonschema>=4.19.0->chromadb>=0.5.17->llama-index-vector-stores-chroma==0.3.0) (2025.4.1)\n",
      "Requirement already satisfied: referencing>=0.28.4 in ./ch03_env/lib/python3.11/site-packages (from jsonschema>=4.19.0->chromadb>=0.5.17->llama-index-vector-stores-chroma==0.3.0) (0.36.2)\n",
      "Requirement already satisfied: rpds-py>=0.7.1 in ./ch03_env/lib/python3.11/site-packages (from jsonschema>=4.19.0->chromadb>=0.5.17->llama-index-vector-stores-chroma==0.3.0) (0.25.1)\n",
      "Requirement already satisfied: six>=1.9.0 in ./ch03_env/lib/python3.11/site-packages (from kubernetes>=28.1.0->chromadb>=0.5.17->llama-index-vector-stores-chroma==0.3.0) (1.17.0)\n",
      "Requirement already satisfied: python-dateutil>=2.5.3 in ./ch03_env/lib/python3.11/site-packages (from kubernetes>=28.1.0->chromadb>=0.5.17->llama-index-vector-stores-chroma==0.3.0) (2.9.0.post0)\n",
      "Requirement already satisfied: google-auth>=1.0.1 in ./ch03_env/lib/python3.11/site-packages (from kubernetes>=28.1.0->chromadb>=0.5.17->llama-index-vector-stores-chroma==0.3.0) (2.40.3)\n",
      "Requirement already satisfied: websocket-client!=0.40.0,!=0.41.*,!=0.42.*,>=0.32.0 in ./ch03_env/lib/python3.11/site-packages (from kubernetes>=28.1.0->chromadb>=0.5.17->llama-index-vector-stores-chroma==0.3.0) (1.8.0)\n",
      "Requirement already satisfied: requests-oauthlib in ./ch03_env/lib/python3.11/site-packages (from kubernetes>=28.1.0->chromadb>=0.5.17->llama-index-vector-stores-chroma==0.3.0) (2.0.0)\n",
      "Requirement already satisfied: oauthlib>=3.2.2 in ./ch03_env/lib/python3.11/site-packages (from kubernetes>=28.1.0->chromadb>=0.5.17->llama-index-vector-stores-chroma==0.3.0) (3.3.1)\n",
      "Requirement already satisfied: urllib3>=1.24.2 in ./ch03_env/lib/python3.11/site-packages (from kubernetes>=28.1.0->chromadb>=0.5.17->llama-index-vector-stores-chroma==0.3.0) (2.5.0)\n",
      "Requirement already satisfied: durationpy>=0.7 in ./ch03_env/lib/python3.11/site-packages (from kubernetes>=28.1.0->chromadb>=0.5.17->llama-index-vector-stores-chroma==0.3.0) (0.10)\n",
      "Requirement already satisfied: llama-cloud-services>=0.6.21 in ./ch03_env/lib/python3.11/site-packages (from llama-parse>=0.5.0->llama-index-readers-llama-parse>=0.3.0->llama-index==0.11.11) (0.6.21)\n",
      "Requirement already satisfied: coloredlogs in ./ch03_env/lib/python3.11/site-packages (from onnxruntime>=1.14.1->chromadb>=0.5.17->llama-index-vector-stores-chroma==0.3.0) (15.0.1)\n",
      "Requirement already satisfied: flatbuffers in ./ch03_env/lib/python3.11/site-packages (from onnxruntime>=1.14.1->chromadb>=0.5.17->llama-index-vector-stores-chroma==0.3.0) (25.2.10)\n",
      "Requirement already satisfied: protobuf in ./ch03_env/lib/python3.11/site-packages (from onnxruntime>=1.14.1->chromadb>=0.5.17->llama-index-vector-stores-chroma==0.3.0) (5.29.5)\n",
      "Requirement already satisfied: sympy in ./ch03_env/lib/python3.11/site-packages (from onnxruntime>=1.14.1->chromadb>=0.5.17->llama-index-vector-stores-chroma==0.3.0) (1.14.0)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in ./ch03_env/lib/python3.11/site-packages (from openai>=1.14.0->llama-index-agent-openai<0.4.0,>=0.3.4->llama-index==0.11.11) (1.9.0)\n",
      "Requirement already satisfied: jiter<1,>=0.4.0 in ./ch03_env/lib/python3.11/site-packages (from openai>=1.14.0->llama-index-agent-openai<0.4.0,>=0.3.4->llama-index==0.11.11) (0.10.0)\n",
      "Requirement already satisfied: sniffio in ./ch03_env/lib/python3.11/site-packages (from openai>=1.14.0->llama-index-agent-openai<0.4.0,>=0.3.4->llama-index==0.11.11) (1.3.1)\n",
      "Requirement already satisfied: importlib-metadata<8.8.0,>=6.0 in ./ch03_env/lib/python3.11/site-packages (from opentelemetry-api>=1.2.0->chromadb>=0.5.17->llama-index-vector-stores-chroma==0.3.0) (8.7.0)\n",
      "Requirement already satisfied: googleapis-common-protos~=1.52 in ./ch03_env/lib/python3.11/site-packages (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb>=0.5.17->llama-index-vector-stores-chroma==0.3.0) (1.70.0)\n",
      "Requirement already satisfied: opentelemetry-exporter-otlp-proto-common==1.34.1 in ./ch03_env/lib/python3.11/site-packages (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb>=0.5.17->llama-index-vector-stores-chroma==0.3.0) (1.34.1)\n",
      "Requirement already satisfied: opentelemetry-proto==1.34.1 in ./ch03_env/lib/python3.11/site-packages (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb>=0.5.17->llama-index-vector-stores-chroma==0.3.0) (1.34.1)\n",
      "Requirement already satisfied: opentelemetry-semantic-conventions==0.55b1 in ./ch03_env/lib/python3.11/site-packages (from opentelemetry-sdk>=1.2.0->chromadb>=0.5.17->llama-index-vector-stores-chroma==0.3.0) (0.55b1)\n",
      "Requirement already satisfied: backoff>=1.10.0 in ./ch03_env/lib/python3.11/site-packages (from posthog>=2.4.0->chromadb>=0.5.17->llama-index-vector-stores-chroma==0.3.0) (2.2.1)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in ./ch03_env/lib/python3.11/site-packages (from pydantic>=1.9->chromadb>=0.5.17->llama-index-vector-stores-chroma==0.3.0) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.33.2 in ./ch03_env/lib/python3.11/site-packages (from pydantic>=1.9->chromadb>=0.5.17->llama-index-vector-stores-chroma==0.3.0) (2.33.2)\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in ./ch03_env/lib/python3.11/site-packages (from pydantic>=1.9->chromadb>=0.5.17->llama-index-vector-stores-chroma==0.3.0) (0.4.1)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in ./ch03_env/lib/python3.11/site-packages (from requests->huggingface-hub>=0.19.0->huggingface-hub[inference]>=0.19.0->llama-index-embeddings-huggingface==0.3.0) (3.4.2)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in ./ch03_env/lib/python3.11/site-packages (from rich>=10.11.0->chromadb>=0.5.17->llama-index-vector-stores-chroma==0.3.0) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in ./ch03_env/lib/python3.11/site-packages (from rich>=10.11.0->chromadb>=0.5.17->llama-index-vector-stores-chroma==0.3.0) (2.19.2)\n",
      "Requirement already satisfied: greenlet>=1 in ./ch03_env/lib/python3.11/site-packages (from SQLAlchemy[asyncio]>=1.4.49->llama-index-core<0.12.0,>=0.11.10->llama-index==0.11.11) (3.2.3)\n",
      "Requirement already satisfied: jinja2 in ./ch03_env/lib/python3.11/site-packages (from torch>=1.11.0->sentence-transformers>=2.6.1->llama-index-embeddings-huggingface==0.3.0) (3.1.6)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in ./ch03_env/lib/python3.11/site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers>=2.6.1->llama-index-embeddings-huggingface==0.3.0) (0.5.3)\n",
      "Requirement already satisfied: shellingham>=1.3.0 in ./ch03_env/lib/python3.11/site-packages (from typer>=0.9.0->chromadb>=0.5.17->llama-index-vector-stores-chroma==0.3.0) (1.5.4)\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in ./ch03_env/lib/python3.11/site-packages (from typing-inspect>=0.8.0->llama-index-core<0.12.0,>=0.11.10->llama-index==0.11.11) (1.1.0)\n",
      "Requirement already satisfied: httptools>=0.6.3 in ./ch03_env/lib/python3.11/site-packages (from uvicorn[standard]>=0.18.3->chromadb>=0.5.17->llama-index-vector-stores-chroma==0.3.0) (0.6.4)\n",
      "Requirement already satisfied: python-dotenv>=0.13 in ./ch03_env/lib/python3.11/site-packages (from uvicorn[standard]>=0.18.3->chromadb>=0.5.17->llama-index-vector-stores-chroma==0.3.0) (1.1.1)\n",
      "Requirement already satisfied: uvloop>=0.15.1 in ./ch03_env/lib/python3.11/site-packages (from uvicorn[standard]>=0.18.3->chromadb>=0.5.17->llama-index-vector-stores-chroma==0.3.0) (0.21.0)\n",
      "Requirement already satisfied: watchfiles>=0.13 in ./ch03_env/lib/python3.11/site-packages (from uvicorn[standard]>=0.18.3->chromadb>=0.5.17->llama-index-vector-stores-chroma==0.3.0) (1.1.0)\n",
      "Requirement already satisfied: websockets>=10.4 in ./ch03_env/lib/python3.11/site-packages (from uvicorn[standard]>=0.18.3->chromadb>=0.5.17->llama-index-vector-stores-chroma==0.3.0) (15.0.1)\n",
      "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in ./ch03_env/lib/python3.11/site-packages (from dataclasses-json->llama-index-core<0.12.0,>=0.11.10->llama-index==0.11.11) (3.26.1)\n",
      "Requirement already satisfied: pytz>=2020.1 in ./ch03_env/lib/python3.11/site-packages (from pandas->llama-index-legacy<0.10.0,>=0.9.48->llama-index==0.11.11) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in ./ch03_env/lib/python3.11/site-packages (from pandas->llama-index-legacy<0.10.0,>=0.9.48->llama-index==0.11.11) (2025.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in ./ch03_env/lib/python3.11/site-packages (from scikit-learn->sentence-transformers>=2.6.1->llama-index-embeddings-huggingface==0.3.0) (3.6.0)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in ./ch03_env/lib/python3.11/site-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb>=0.5.17->llama-index-vector-stores-chroma==0.3.0) (5.5.2)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in ./ch03_env/lib/python3.11/site-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb>=0.5.17->llama-index-vector-stores-chroma==0.3.0) (0.4.2)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in ./ch03_env/lib/python3.11/site-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb>=0.5.17->llama-index-vector-stores-chroma==0.3.0) (4.9.1)\n",
      "Requirement already satisfied: zipp>=3.20 in ./ch03_env/lib/python3.11/site-packages (from importlib-metadata<8.8.0,>=6.0->opentelemetry-api>=1.2.0->chromadb>=0.5.17->llama-index-vector-stores-chroma==0.3.0) (3.23.0)\n",
      "Requirement already satisfied: platformdirs<5.0.0,>=4.3.7 in ./ch03_env/lib/python3.11/site-packages (from llama-cloud-services>=0.6.21->llama-parse>=0.5.0->llama-index-readers-llama-parse>=0.3.0->llama-index==0.11.11) (4.3.8)\n",
      "Requirement already satisfied: mdurl~=0.1 in ./ch03_env/lib/python3.11/site-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->chromadb>=0.5.17->llama-index-vector-stores-chroma==0.3.0) (0.1.2)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in ./ch03_env/lib/python3.11/site-packages (from sympy->onnxruntime>=1.14.1->chromadb>=0.5.17->llama-index-vector-stores-chroma==0.3.0) (1.3.0)\n",
      "Requirement already satisfied: humanfriendly>=9.1 in ./ch03_env/lib/python3.11/site-packages (from coloredlogs->onnxruntime>=1.14.1->chromadb>=0.5.17->llama-index-vector-stores-chroma==0.3.0) (10.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in ./ch03_env/lib/python3.11/site-packages (from jinja2->torch>=1.11.0->sentence-transformers>=2.6.1->llama-index-embeddings-huggingface==0.3.0) (3.0.2)\n",
      "Requirement already satisfied: pyasn1<0.7.0,>=0.6.1 in ./ch03_env/lib/python3.11/site-packages (from pyasn1-modules>=0.2.1->google-auth>=1.0.1->kubernetes>=28.1.0->chromadb>=0.5.17->llama-index-vector-stores-chroma==0.3.0) (0.6.1)\n",
      "Using cached llama_index_vector_stores_chroma-0.3.0-py3-none-any.whl (5.2 kB)\n",
      "Using cached llama_index_embeddings_huggingface-0.3.0-py3-none-any.whl (8.6 kB)\n",
      "Installing collected packages: llama-index-embeddings-huggingface, llama-index-vector-stores-chroma\n",
      "Successfully installed llama-index-embeddings-huggingface-0.3.0 llama-index-vector-stores-chroma-0.3.0\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.0\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.1.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install llama-index==0.11.11 \\\n",
    "    llama-index-vector-stores-chroma==0.3.0 \\\n",
    "        llama-index-embeddings-huggingface==0.3.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e80cab75",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to send telemetry event ClientStartEvent: capture() takes 1 positional argument but 3 were given\n",
      "Failed to send telemetry event ClientCreateCollectionEvent: capture() takes 1 positional argument but 3 were given\n"
     ]
    }
   ],
   "source": [
    "import chromadb\n",
    "from llama_index.core.schema import Document\n",
    "from llama_index.embeddings.huggingface import HuggingFaceEmbedding\n",
    "import os\n",
    "api_key = os.environ.get(\"OPENAI_API_KEY\")\n",
    "\n",
    "# ChromaDB 클라이언트 생성 및 컬렉션 준비\n",
    "# 데이터를 저장할 로컬 경로 지정\n",
    "client = chromadb.PersistentClient(path=\"./chroma_db\") \n",
    "# 컬렉션 생성 또는 불러오기\n",
    "collection = client.get_or_create_collection(\"example-collection\") \n",
    "\n",
    "# Hugging Face 임베딩 모델 설정\n",
    "embed_model = HuggingFaceEmbedding(model_name=\"all-MiniLM-L6-v2\")\n",
    "\n",
    "# 문서 데이터 준비\n",
    "documents = [\n",
    "    \"고양이는 작은 육식동물로, 주로 애완동물로 기릅니다. 민첩하고 장난기 있는 행동으로 유명합니다.\",\n",
    "    \"강아지는 충성심이 강하고 친절한 동물로, 흔히 인간의 최고의 친구로 불립니다. 주로 애완동물로 기르고, 동반자로서 유명합니다.\",\n",
    "    \"고양이와 강아지는 전 세계적으로 인기 있는 애완동물로, 각각 독특한 특징을 가지고 있습니다.\"\n",
    "]\n",
    "ids = [\"doc1\", \"doc2\", \"doc3\"]\n",
    "\n",
    "# 문서를 LlamaIndex의 Document 형식으로 변환\n",
    "nodes = [Document(text=doc, id_=doc_id) for doc, doc_id in zip(documents, ids)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8d7cbc93",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from llama_index.vector_stores.chroma import ChromaVectorStore\n",
    "from llama_index.core import VectorStoreIndex\n",
    "from llama_index.llms.openai import OpenAI\n",
    "\n",
    "llm = OpenAI(api_key=os.environ[\"OPENAI_API_KEY\"])\n",
    "\n",
    "# Chroma 벡터 스토어 생성\n",
    "vector_store = ChromaVectorStore(chroma_collection=collection)\n",
    "\n",
    "# LlamaIndex의 VectorStoreIndex 생성\n",
    "index = VectorStoreIndex.from_documents(nodes, vector_store=vector_store,\n",
    "embed_model= embed_model, llm=llm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "cf33a9cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[질의 결과]\n",
      "고양이는 독립적이고 까다로운 동물로 알려져 있습니다. 주로 깨끗한 습성을 가지고 있고, 자신만의 영역을 중요시합니다. 애정 표현이 상대적으로 덜한 편이며, 고양이는 주로 자신의 시간을 혼자 보내는 것을 선호합니다.\n"
     ]
    }
   ],
   "source": [
    "# 쿼리 엔진 생성\n",
    "query_engine = index.as_query_engine()\n",
    "\n",
    "# 질의 수행\n",
    "query_text = \"고양이에 대해 알려줘\"\n",
    "response = query_engine.query(query_text)\n",
    "\n",
    "# 결과 출력\n",
    "print(\"[질의 결과]\")\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25f11b91",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core import Settings\n",
    "print(f\"현재 임베딩 모델: {Settings.embed_model}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5db50d6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "documents = [\n",
    "    \"고양이는 작은 육식동물로, 주로 애완동물로 기릅니다. 민첩하고 장난기 있는 행동으로 유명합니다.\",\n",
    "    \"강아지는 충성심이 강하고 친절한 동물로, 흔히 인간의 최고의 친구로 불립니다. 주로 애완동물로 기르고, 동반자로서 유명합니다.\",\n",
    "    \"고양이와 강아지는 전 세계적으로 인기 있는 애완동물로, 각각 독특한 특징을 가지고 있습니다.\"\n",
    "]\n",
    "ids = [\"doc1\", \"doc2\", \"doc3\"]\n",
    "\n",
    "# 문서를 LlamaIndex의 Document 형식으로 변환\n",
    "nodes = [Document(text=doc, id_=doc_id) for doc, doc_id in zip(documents, ids)]\n",
    "\n",
    "# Chroma 벡터 스토어 생성\n",
    "vector_store = ChromaVectorStore(chroma_collection=collection)\n",
    "\n",
    "# LlamaIndex의 VectorStoreIndex 생성\n",
    "index = VectorStoreIndex.from_documents(nodes, vector_store=vector_store)\n",
    "\n",
    "# 쿼리 엔진 생성 (기본적인 검색 + 답변 생성 기능 활성화)\n",
    "query_engine = index.as_query_engine()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "4cb9c7cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[질의 결과]\n",
      "고양이는 작은 육식동물로, 주로 애완동물로 기르며 민첩하고 장난기 있는 행동으로 유명합니다.\n",
      "\n",
      "[검색 문서]\n",
      "1. 고양이는 작은 육식동물로, 주로 애완동물로 기릅니다. 민첩하고 장난기 있는 행동으로 유명합니다.\n",
      "\n",
      "2. 고양이와 강아지는 전 세계적으로 인기 있는 애완동물로, 각각 독특한 특징을 가지고 있습니다.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "query_text = \"고양이에 대해 알려줘\"\n",
    "response = query_engine.query(query_text)\n",
    "\n",
    "# 최종 응답 출력\n",
    "print(\"[질의 결과]\")\n",
    "print(response)\n",
    "\n",
    "# 응답 생성에 사용된 문서 확인\n",
    "print(\"\\n[검색 문서]\")\n",
    "for i, node in enumerate(response.source_nodes, 1):\n",
    "    print(f\"{i}. {node.text}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4a6af339",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pinecone==6.0.2\n",
      "  Using cached pinecone-6.0.2-py3-none-any.whl.metadata (9.0 kB)\n",
      "Requirement already satisfied: certifi>=2019.11.17 in ./ch03_env/lib/python3.11/site-packages (from pinecone==6.0.2) (2025.6.15)\n",
      "Collecting pinecone-plugin-interface<0.0.8,>=0.0.7 (from pinecone==6.0.2)\n",
      "  Using cached pinecone_plugin_interface-0.0.7-py3-none-any.whl.metadata (1.2 kB)\n",
      "Requirement already satisfied: python-dateutil>=2.5.3 in ./ch03_env/lib/python3.11/site-packages (from pinecone==6.0.2) (2.9.0.post0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4 in ./ch03_env/lib/python3.11/site-packages (from pinecone==6.0.2) (4.14.0)\n",
      "Requirement already satisfied: urllib3>=1.26.0 in ./ch03_env/lib/python3.11/site-packages (from pinecone==6.0.2) (2.5.0)\n",
      "Requirement already satisfied: six>=1.5 in ./ch03_env/lib/python3.11/site-packages (from python-dateutil>=2.5.3->pinecone==6.0.2) (1.17.0)\n",
      "Using cached pinecone-6.0.2-py3-none-any.whl (421 kB)\n",
      "Using cached pinecone_plugin_interface-0.0.7-py3-none-any.whl (6.2 kB)\n",
      "Installing collected packages: pinecone-plugin-interface, pinecone\n",
      "Successfully installed pinecone-6.0.2 pinecone-plugin-interface-0.0.7\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.0\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.1.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install pinecone==6.0.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9c2513ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/gaheeyoon/llamaindex/ch03/ch03_env/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from pinecone import Pinecone\n",
    "import os\n",
    "\n",
    "# 환경 변수에서 API 키 가져오기\n",
    "api_key = os.environ.get(\"PINECONE_API_KEY\")\n",
    "pc = Pinecone(api_key=api_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cd78b5c7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{\n",
       "    \"name\": \"my-index\",\n",
       "    \"metric\": \"cosine\",\n",
       "    \"host\": \"my-index-g5gwtyw.svc.aped-4627-b74a.pinecone.io\",\n",
       "    \"spec\": {\n",
       "        \"serverless\": {\n",
       "            \"cloud\": \"aws\",\n",
       "            \"region\": \"us-east-1\"\n",
       "        }\n",
       "    },\n",
       "    \"status\": {\n",
       "        \"ready\": true,\n",
       "        \"state\": \"Ready\"\n",
       "    },\n",
       "    \"vector_type\": \"dense\",\n",
       "    \"dimension\": 3,\n",
       "    \"deletion_protection\": \"disabled\",\n",
       "    \"tags\": null\n",
       "}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pinecone import ServerlessSpec\n",
    "\n",
    "index_name = \"my-index\"\n",
    "\n",
    "pc.create_index(\n",
    "    name=index_name,\n",
    "    dimension=3, # 벡터의 차원 수\n",
    "    metric=\"cosine\", # 유사도 측정 방식 (cosine, euclidean, dotproduct 중 선택)\n",
    "    spec=ServerlessSpec(\n",
    "        cloud=\"aws\", # 사용할 클라우드: aws 또는 gcp\n",
    "        region=\"us-east-1\" # 리전 설정 (free tier에서 지원되는 리전을 사용해야 함)\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c67d2c4b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "아이템 임베딩을 인덱스에 추가했습니다.\n"
     ]
    }
   ],
   "source": [
    "index = pc.Index(index_name)\n",
    "# 벡터 데이터 삽입\n",
    "vectors = [\n",
    "    [0.1, 0.2, 0.3], # 첫 번째 데이터의 벡터\n",
    "    [0.4, 0.5, 0.6], # 두 번째 데이터의 벡터\n",
    "    [0.7, 0.8, 0.9], # 세 번째 데이터의 벡터\n",
    "]\n",
    "\n",
    "# 벡터를 인덱스에 추가\n",
    "ids = [\"doc1\", \"doc2\", \"doc3\"]\n",
    "index.upsert([(id, vector) for id, vector in zip(ids, vectors)])\n",
    "print(\"아이템 임베딩을 인덱스에 추가했습니다.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8fb3e802",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "유사한 벡터 검색 결과:\n",
      "{\n",
      "    \"검색된 문서 ID\": \"doc1\",\n",
      "    \"유사도 거리\": 0.998880625\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "# 유사 벡터 검색\n",
    "results = index.query(\n",
    "    vector=[[0.1, 0.2, 0.3]], # 검색할 쿼리 벡터\n",
    "    top_k=2, # 가장 유사한 2개의 벡터 반환\n",
    "    include_metadata=False\n",
    ")\n",
    "\n",
    "formatted_results = {\n",
    "    \"검색된 문서 ID\": results[\"matches\"][0][\"id\"],\n",
    "    \"유사도 거리\": results[\"matches\"][0][\"score\"]\n",
    "}\n",
    "\n",
    "print(\"\\n유사한 벡터 검색 결과:\")\n",
    "print(json.dumps(formatted_results, indent=4, ensure_ascii=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "70e060ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 메타데이터와 함께 벡터 삽입\n",
    "vectors = [\n",
    "    ([0.1, 0.2, 0.3], {\"category\": \"A\", \"year\": 2020}),\n",
    "    ([0.4, 0.5, 0.6], {\"category\": \"B\", \"year\": 2021}),\n",
    "    ([0.7, 0.8, 0.9], {\"category\": \"A\", \"year\": 2022}),\n",
    "]\n",
    "\n",
    "ids = [\"doc1\", \"doc2\", \"doc3\"]\n",
    "index.upsert([(id, vector, metadata) for id, (vector, metadata) in zip(ids, vectors)])\n",
    "\n",
    "# 검색 벡터\n",
    "query_vector = [0.1, 0.2, 0.25]\n",
    "\n",
    "# 메타데이터 필터링 조건\n",
    "filter_condition = {\n",
    "    \"category\": {\"$eq\": \"A\"},\n",
    "    \"year\": {\"$gt\": 2020}\n",
    "}\n",
    "\n",
    "# 검색\n",
    "query_result = index.query(\n",
    "    vector=query_vector,\n",
    "    top_k=2,\n",
    "    filter=filter_condition,\n",
    "    include_metadata=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2bc7ebf7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "유사한 벡터 검색 결과:\n",
      "{\n",
      "    \"검색된 문서 ID\": \"doc3\",\n",
      "    \"메타데이터\": {\n",
      "        \"category\": \"A\",\n",
      "        \"year\": 2022.0\n",
      "    }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "formatted_results = {\n",
    "    \"검색된 문서 ID\": query_result[\"matches\"][0][\"id\"],\n",
    "    \"메타데이터\": query_result[\"matches\"][0][\"metadata\"]\n",
    "}\n",
    "\n",
    "print(\"\\n유사한 벡터 검색 결과:\")\n",
    "print(json.dumps(formatted_results, indent=4, ensure_ascii=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "dc9adbf6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: llama-index==0.11.11 in ./ch03_env/lib/python3.11/site-packages (0.11.11)\n",
      "Collecting llama-index-vector-stores-pinecone==0.3.0\n",
      "  Using cached llama_index_vector_stores_pinecone-0.3.0-py3-none-any.whl.metadata (719 bytes)\n",
      "Requirement already satisfied: llama-index-embeddings-huggingface==0.3.0 in ./ch03_env/lib/python3.11/site-packages (0.3.0)\n",
      "Requirement already satisfied: llama-index-agent-openai<0.4.0,>=0.3.4 in ./ch03_env/lib/python3.11/site-packages (from llama-index==0.11.11) (0.3.4)\n",
      "Requirement already satisfied: llama-index-cli<0.4.0,>=0.3.1 in ./ch03_env/lib/python3.11/site-packages (from llama-index==0.11.11) (0.3.1)\n",
      "Requirement already satisfied: llama-index-core<0.12.0,>=0.11.10 in ./ch03_env/lib/python3.11/site-packages (from llama-index==0.11.11) (0.11.23)\n",
      "Requirement already satisfied: llama-index-embeddings-openai<0.3.0,>=0.2.4 in ./ch03_env/lib/python3.11/site-packages (from llama-index==0.11.11) (0.2.5)\n",
      "Requirement already satisfied: llama-index-indices-managed-llama-cloud>=0.3.0 in ./ch03_env/lib/python3.11/site-packages (from llama-index==0.11.11) (0.6.0)\n",
      "Requirement already satisfied: llama-index-legacy<0.10.0,>=0.9.48 in ./ch03_env/lib/python3.11/site-packages (from llama-index==0.11.11) (0.9.48.post4)\n",
      "Requirement already satisfied: llama-index-llms-openai<0.3.0,>=0.2.9 in ./ch03_env/lib/python3.11/site-packages (from llama-index==0.11.11) (0.2.16)\n",
      "Requirement already satisfied: llama-index-multi-modal-llms-openai<0.3.0,>=0.2.0 in ./ch03_env/lib/python3.11/site-packages (from llama-index==0.11.11) (0.2.3)\n",
      "Requirement already satisfied: llama-index-program-openai<0.3.0,>=0.2.0 in ./ch03_env/lib/python3.11/site-packages (from llama-index==0.11.11) (0.2.0)\n",
      "Requirement already satisfied: llama-index-question-gen-openai<0.3.0,>=0.2.0 in ./ch03_env/lib/python3.11/site-packages (from llama-index==0.11.11) (0.2.0)\n",
      "Requirement already satisfied: llama-index-readers-file<0.3.0,>=0.2.0 in ./ch03_env/lib/python3.11/site-packages (from llama-index==0.11.11) (0.2.2)\n",
      "Requirement already satisfied: llama-index-readers-llama-parse>=0.3.0 in ./ch03_env/lib/python3.11/site-packages (from llama-index==0.11.11) (0.3.0)\n",
      "Requirement already satisfied: nltk>3.8.1 in ./ch03_env/lib/python3.11/site-packages (from llama-index==0.11.11) (3.9.1)\n",
      "Collecting pinecone-client<6.0.0,>=3.2.2 (from llama-index-vector-stores-pinecone==0.3.0)\n",
      "  Using cached pinecone_client-5.0.1-py3-none-any.whl.metadata (19 kB)\n",
      "Requirement already satisfied: huggingface-hub>=0.19.0 in ./ch03_env/lib/python3.11/site-packages (from huggingface-hub[inference]>=0.19.0->llama-index-embeddings-huggingface==0.3.0) (0.33.1)\n",
      "Requirement already satisfied: sentence-transformers>=2.6.1 in ./ch03_env/lib/python3.11/site-packages (from llama-index-embeddings-huggingface==0.3.0) (4.1.0)\n",
      "Requirement already satisfied: filelock in ./ch03_env/lib/python3.11/site-packages (from huggingface-hub>=0.19.0->huggingface-hub[inference]>=0.19.0->llama-index-embeddings-huggingface==0.3.0) (3.18.0)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in ./ch03_env/lib/python3.11/site-packages (from huggingface-hub>=0.19.0->huggingface-hub[inference]>=0.19.0->llama-index-embeddings-huggingface==0.3.0) (2025.5.1)\n",
      "Requirement already satisfied: packaging>=20.9 in ./ch03_env/lib/python3.11/site-packages (from huggingface-hub>=0.19.0->huggingface-hub[inference]>=0.19.0->llama-index-embeddings-huggingface==0.3.0) (25.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in ./ch03_env/lib/python3.11/site-packages (from huggingface-hub>=0.19.0->huggingface-hub[inference]>=0.19.0->llama-index-embeddings-huggingface==0.3.0) (6.0.2)\n",
      "Requirement already satisfied: requests in ./ch03_env/lib/python3.11/site-packages (from huggingface-hub>=0.19.0->huggingface-hub[inference]>=0.19.0->llama-index-embeddings-huggingface==0.3.0) (2.32.4)\n",
      "Requirement already satisfied: tqdm>=4.42.1 in ./ch03_env/lib/python3.11/site-packages (from huggingface-hub>=0.19.0->huggingface-hub[inference]>=0.19.0->llama-index-embeddings-huggingface==0.3.0) (4.67.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in ./ch03_env/lib/python3.11/site-packages (from huggingface-hub>=0.19.0->huggingface-hub[inference]>=0.19.0->llama-index-embeddings-huggingface==0.3.0) (4.14.0)\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.1.2 in ./ch03_env/lib/python3.11/site-packages (from huggingface-hub>=0.19.0->huggingface-hub[inference]>=0.19.0->llama-index-embeddings-huggingface==0.3.0) (1.1.5)\n",
      "Requirement already satisfied: aiohttp in ./ch03_env/lib/python3.11/site-packages (from huggingface-hub[inference]>=0.19.0->llama-index-embeddings-huggingface==0.3.0) (3.12.13)\n",
      "Requirement already satisfied: openai>=1.14.0 in ./ch03_env/lib/python3.11/site-packages (from llama-index-agent-openai<0.4.0,>=0.3.4->llama-index==0.11.11) (1.93.0)\n",
      "Requirement already satisfied: SQLAlchemy>=1.4.49 in ./ch03_env/lib/python3.11/site-packages (from SQLAlchemy[asyncio]>=1.4.49->llama-index-core<0.12.0,>=0.11.10->llama-index==0.11.11) (2.0.41)\n",
      "Requirement already satisfied: dataclasses-json in ./ch03_env/lib/python3.11/site-packages (from llama-index-core<0.12.0,>=0.11.10->llama-index==0.11.11) (0.6.7)\n",
      "Requirement already satisfied: deprecated>=1.2.9.3 in ./ch03_env/lib/python3.11/site-packages (from llama-index-core<0.12.0,>=0.11.10->llama-index==0.11.11) (1.2.18)\n",
      "Requirement already satisfied: dirtyjson<2.0.0,>=1.0.8 in ./ch03_env/lib/python3.11/site-packages (from llama-index-core<0.12.0,>=0.11.10->llama-index==0.11.11) (1.0.8)\n",
      "Requirement already satisfied: filetype<2.0.0,>=1.2.0 in ./ch03_env/lib/python3.11/site-packages (from llama-index-core<0.12.0,>=0.11.10->llama-index==0.11.11) (1.2.0)\n",
      "Requirement already satisfied: httpx in ./ch03_env/lib/python3.11/site-packages (from llama-index-core<0.12.0,>=0.11.10->llama-index==0.11.11) (0.28.1)\n",
      "Requirement already satisfied: nest-asyncio<2.0.0,>=1.5.8 in ./ch03_env/lib/python3.11/site-packages (from llama-index-core<0.12.0,>=0.11.10->llama-index==0.11.11) (1.6.0)\n",
      "Requirement already satisfied: networkx>=3.0 in ./ch03_env/lib/python3.11/site-packages (from llama-index-core<0.12.0,>=0.11.10->llama-index==0.11.11) (3.5)\n",
      "Requirement already satisfied: numpy<2.0.0 in ./ch03_env/lib/python3.11/site-packages (from llama-index-core<0.12.0,>=0.11.10->llama-index==0.11.11) (1.26.4)\n",
      "Requirement already satisfied: pillow>=9.0.0 in ./ch03_env/lib/python3.11/site-packages (from llama-index-core<0.12.0,>=0.11.10->llama-index==0.11.11) (11.2.1)\n",
      "Requirement already satisfied: pydantic<3.0.0,>=2.7.0 in ./ch03_env/lib/python3.11/site-packages (from llama-index-core<0.12.0,>=0.11.10->llama-index==0.11.11) (2.11.7)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<9.0.0,>=8.2.0 in ./ch03_env/lib/python3.11/site-packages (from llama-index-core<0.12.0,>=0.11.10->llama-index==0.11.11) (8.5.0)\n",
      "Requirement already satisfied: tiktoken>=0.3.3 in ./ch03_env/lib/python3.11/site-packages (from llama-index-core<0.12.0,>=0.11.10->llama-index==0.11.11) (0.9.0)\n",
      "Requirement already satisfied: typing-inspect>=0.8.0 in ./ch03_env/lib/python3.11/site-packages (from llama-index-core<0.12.0,>=0.11.10->llama-index==0.11.11) (0.9.0)\n",
      "Requirement already satisfied: wrapt in ./ch03_env/lib/python3.11/site-packages (from llama-index-core<0.12.0,>=0.11.10->llama-index==0.11.11) (1.17.2)\n",
      "Requirement already satisfied: llama-cloud>=0.1.5 in ./ch03_env/lib/python3.11/site-packages (from llama-index-indices-managed-llama-cloud>=0.3.0->llama-index==0.11.11) (0.1.19)\n",
      "Requirement already satisfied: pandas in ./ch03_env/lib/python3.11/site-packages (from llama-index-legacy<0.10.0,>=0.9.48->llama-index==0.11.11) (2.3.0)\n",
      "Requirement already satisfied: beautifulsoup4<5.0.0,>=4.12.3 in ./ch03_env/lib/python3.11/site-packages (from llama-index-readers-file<0.3.0,>=0.2.0->llama-index==0.11.11) (4.13.4)\n",
      "Requirement already satisfied: pypdf<5.0.0,>=4.0.1 in ./ch03_env/lib/python3.11/site-packages (from llama-index-readers-file<0.3.0,>=0.2.0->llama-index==0.11.11) (4.3.1)\n",
      "Requirement already satisfied: striprtf<0.0.27,>=0.0.26 in ./ch03_env/lib/python3.11/site-packages (from llama-index-readers-file<0.3.0,>=0.2.0->llama-index==0.11.11) (0.0.26)\n",
      "Requirement already satisfied: llama-parse>=0.5.0 in ./ch03_env/lib/python3.11/site-packages (from llama-index-readers-llama-parse>=0.3.0->llama-index==0.11.11) (0.6.21)\n",
      "Requirement already satisfied: click in ./ch03_env/lib/python3.11/site-packages (from nltk>3.8.1->llama-index==0.11.11) (8.2.1)\n",
      "Requirement already satisfied: joblib in ./ch03_env/lib/python3.11/site-packages (from nltk>3.8.1->llama-index==0.11.11) (1.5.1)\n",
      "Requirement already satisfied: regex>=2021.8.3 in ./ch03_env/lib/python3.11/site-packages (from nltk>3.8.1->llama-index==0.11.11) (2024.11.6)\n",
      "Requirement already satisfied: certifi>=2019.11.17 in ./ch03_env/lib/python3.11/site-packages (from pinecone-client<6.0.0,>=3.2.2->llama-index-vector-stores-pinecone==0.3.0) (2025.6.15)\n",
      "Collecting pinecone-plugin-inference<2.0.0,>=1.0.3 (from pinecone-client<6.0.0,>=3.2.2->llama-index-vector-stores-pinecone==0.3.0)\n",
      "  Using cached pinecone_plugin_inference-1.1.0-py3-none-any.whl.metadata (2.2 kB)\n",
      "Requirement already satisfied: pinecone-plugin-interface<0.0.8,>=0.0.7 in ./ch03_env/lib/python3.11/site-packages (from pinecone-client<6.0.0,>=3.2.2->llama-index-vector-stores-pinecone==0.3.0) (0.0.7)\n",
      "Requirement already satisfied: urllib3>=1.26.0 in ./ch03_env/lib/python3.11/site-packages (from pinecone-client<6.0.0,>=3.2.2->llama-index-vector-stores-pinecone==0.3.0) (2.5.0)\n",
      "Requirement already satisfied: transformers<5.0.0,>=4.41.0 in ./ch03_env/lib/python3.11/site-packages (from sentence-transformers>=2.6.1->llama-index-embeddings-huggingface==0.3.0) (4.53.0)\n",
      "Requirement already satisfied: torch>=1.11.0 in ./ch03_env/lib/python3.11/site-packages (from sentence-transformers>=2.6.1->llama-index-embeddings-huggingface==0.3.0) (2.7.1)\n",
      "Requirement already satisfied: scikit-learn in ./ch03_env/lib/python3.11/site-packages (from sentence-transformers>=2.6.1->llama-index-embeddings-huggingface==0.3.0) (1.7.0)\n",
      "Requirement already satisfied: scipy in ./ch03_env/lib/python3.11/site-packages (from sentence-transformers>=2.6.1->llama-index-embeddings-huggingface==0.3.0) (1.16.0)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in ./ch03_env/lib/python3.11/site-packages (from aiohttp->huggingface-hub[inference]>=0.19.0->llama-index-embeddings-huggingface==0.3.0) (2.6.1)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in ./ch03_env/lib/python3.11/site-packages (from aiohttp->huggingface-hub[inference]>=0.19.0->llama-index-embeddings-huggingface==0.3.0) (1.3.2)\n",
      "Requirement already satisfied: attrs>=17.3.0 in ./ch03_env/lib/python3.11/site-packages (from aiohttp->huggingface-hub[inference]>=0.19.0->llama-index-embeddings-huggingface==0.3.0) (25.3.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in ./ch03_env/lib/python3.11/site-packages (from aiohttp->huggingface-hub[inference]>=0.19.0->llama-index-embeddings-huggingface==0.3.0) (1.7.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in ./ch03_env/lib/python3.11/site-packages (from aiohttp->huggingface-hub[inference]>=0.19.0->llama-index-embeddings-huggingface==0.3.0) (6.6.2)\n",
      "Requirement already satisfied: propcache>=0.2.0 in ./ch03_env/lib/python3.11/site-packages (from aiohttp->huggingface-hub[inference]>=0.19.0->llama-index-embeddings-huggingface==0.3.0) (0.3.2)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in ./ch03_env/lib/python3.11/site-packages (from aiohttp->huggingface-hub[inference]>=0.19.0->llama-index-embeddings-huggingface==0.3.0) (1.20.1)\n",
      "Requirement already satisfied: soupsieve>1.2 in ./ch03_env/lib/python3.11/site-packages (from beautifulsoup4<5.0.0,>=4.12.3->llama-index-readers-file<0.3.0,>=0.2.0->llama-index==0.11.11) (2.7)\n",
      "Requirement already satisfied: anyio in ./ch03_env/lib/python3.11/site-packages (from httpx->llama-index-core<0.12.0,>=0.11.10->llama-index==0.11.11) (4.9.0)\n",
      "Requirement already satisfied: httpcore==1.* in ./ch03_env/lib/python3.11/site-packages (from httpx->llama-index-core<0.12.0,>=0.11.10->llama-index==0.11.11) (1.0.9)\n",
      "Requirement already satisfied: idna in ./ch03_env/lib/python3.11/site-packages (from httpx->llama-index-core<0.12.0,>=0.11.10->llama-index==0.11.11) (3.10)\n",
      "Requirement already satisfied: h11>=0.16 in ./ch03_env/lib/python3.11/site-packages (from httpcore==1.*->httpx->llama-index-core<0.12.0,>=0.11.10->llama-index==0.11.11) (0.16.0)\n",
      "Requirement already satisfied: llama-cloud-services>=0.6.21 in ./ch03_env/lib/python3.11/site-packages (from llama-parse>=0.5.0->llama-index-readers-llama-parse>=0.3.0->llama-index==0.11.11) (0.6.21)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in ./ch03_env/lib/python3.11/site-packages (from openai>=1.14.0->llama-index-agent-openai<0.4.0,>=0.3.4->llama-index==0.11.11) (1.9.0)\n",
      "Requirement already satisfied: jiter<1,>=0.4.0 in ./ch03_env/lib/python3.11/site-packages (from openai>=1.14.0->llama-index-agent-openai<0.4.0,>=0.3.4->llama-index==0.11.11) (0.10.0)\n",
      "Requirement already satisfied: sniffio in ./ch03_env/lib/python3.11/site-packages (from openai>=1.14.0->llama-index-agent-openai<0.4.0,>=0.3.4->llama-index==0.11.11) (1.3.1)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in ./ch03_env/lib/python3.11/site-packages (from pydantic<3.0.0,>=2.7.0->llama-index-core<0.12.0,>=0.11.10->llama-index==0.11.11) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.33.2 in ./ch03_env/lib/python3.11/site-packages (from pydantic<3.0.0,>=2.7.0->llama-index-core<0.12.0,>=0.11.10->llama-index==0.11.11) (2.33.2)\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in ./ch03_env/lib/python3.11/site-packages (from pydantic<3.0.0,>=2.7.0->llama-index-core<0.12.0,>=0.11.10->llama-index==0.11.11) (0.4.1)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in ./ch03_env/lib/python3.11/site-packages (from requests->huggingface-hub>=0.19.0->huggingface-hub[inference]>=0.19.0->llama-index-embeddings-huggingface==0.3.0) (3.4.2)\n",
      "Requirement already satisfied: greenlet>=1 in ./ch03_env/lib/python3.11/site-packages (from SQLAlchemy[asyncio]>=1.4.49->llama-index-core<0.12.0,>=0.11.10->llama-index==0.11.11) (3.2.3)\n",
      "Requirement already satisfied: sympy>=1.13.3 in ./ch03_env/lib/python3.11/site-packages (from torch>=1.11.0->sentence-transformers>=2.6.1->llama-index-embeddings-huggingface==0.3.0) (1.14.0)\n",
      "Requirement already satisfied: jinja2 in ./ch03_env/lib/python3.11/site-packages (from torch>=1.11.0->sentence-transformers>=2.6.1->llama-index-embeddings-huggingface==0.3.0) (3.1.6)\n",
      "Requirement already satisfied: tokenizers<0.22,>=0.21 in ./ch03_env/lib/python3.11/site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers>=2.6.1->llama-index-embeddings-huggingface==0.3.0) (0.21.2)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in ./ch03_env/lib/python3.11/site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers>=2.6.1->llama-index-embeddings-huggingface==0.3.0) (0.5.3)\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in ./ch03_env/lib/python3.11/site-packages (from typing-inspect>=0.8.0->llama-index-core<0.12.0,>=0.11.10->llama-index==0.11.11) (1.1.0)\n",
      "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in ./ch03_env/lib/python3.11/site-packages (from dataclasses-json->llama-index-core<0.12.0,>=0.11.10->llama-index==0.11.11) (3.26.1)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in ./ch03_env/lib/python3.11/site-packages (from pandas->llama-index-legacy<0.10.0,>=0.9.48->llama-index==0.11.11) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in ./ch03_env/lib/python3.11/site-packages (from pandas->llama-index-legacy<0.10.0,>=0.9.48->llama-index==0.11.11) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in ./ch03_env/lib/python3.11/site-packages (from pandas->llama-index-legacy<0.10.0,>=0.9.48->llama-index==0.11.11) (2025.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in ./ch03_env/lib/python3.11/site-packages (from scikit-learn->sentence-transformers>=2.6.1->llama-index-embeddings-huggingface==0.3.0) (3.6.0)\n",
      "Requirement already satisfied: platformdirs<5.0.0,>=4.3.7 in ./ch03_env/lib/python3.11/site-packages (from llama-cloud-services>=0.6.21->llama-parse>=0.5.0->llama-index-readers-llama-parse>=0.3.0->llama-index==0.11.11) (4.3.8)\n",
      "Requirement already satisfied: python-dotenv<2.0.0,>=1.0.1 in ./ch03_env/lib/python3.11/site-packages (from llama-cloud-services>=0.6.21->llama-parse>=0.5.0->llama-index-readers-llama-parse>=0.3.0->llama-index==0.11.11) (1.1.1)\n",
      "Requirement already satisfied: six>=1.5 in ./ch03_env/lib/python3.11/site-packages (from python-dateutil>=2.8.2->pandas->llama-index-legacy<0.10.0,>=0.9.48->llama-index==0.11.11) (1.17.0)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in ./ch03_env/lib/python3.11/site-packages (from sympy>=1.13.3->torch>=1.11.0->sentence-transformers>=2.6.1->llama-index-embeddings-huggingface==0.3.0) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in ./ch03_env/lib/python3.11/site-packages (from jinja2->torch>=1.11.0->sentence-transformers>=2.6.1->llama-index-embeddings-huggingface==0.3.0) (3.0.2)\n",
      "Using cached llama_index_vector_stores_pinecone-0.3.0-py3-none-any.whl (7.6 kB)\n",
      "Using cached pinecone_client-5.0.1-py3-none-any.whl (244 kB)\n",
      "Using cached pinecone_plugin_inference-1.1.0-py3-none-any.whl (85 kB)\n",
      "Installing collected packages: pinecone-plugin-inference, pinecone-client, llama-index-vector-stores-pinecone\n",
      "Successfully installed llama-index-vector-stores-pinecone-0.3.0 pinecone-client-5.0.1 pinecone-plugin-inference-1.1.0\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.0\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.1.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install llama-index==0.11.11 \\\n",
    "    llama-index-vector-stores-pinecone==0.3.0 \\\n",
    "        llama-index-embeddings-huggingface==0.3.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c35a0016",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pinecone import Pinecone\n",
    "from llama_index.core.schema import Document\n",
    "from llama_index.vector_stores.pinecone import PineconeVectorStore\n",
    "from llama_index.core import VectorStoreIndex\n",
    "from llama_index.embeddings.huggingface import HuggingFaceEmbedding\n",
    "from llama_index.core.schema import Document\n",
    "import os\n",
    "\n",
    "api_key = os.environ.get(\"PINECONE_API_KEY\")\n",
    "pc = Pinecone(api_key=api_key)\n",
    "index_name = \"example\"\n",
    "spec = {\n",
    "    \"serverless\": {\n",
    "        \"cloud\": \"aws\",\n",
    "        \"region\": \"us-east-1\"\n",
    "    }\n",
    "}\n",
    "\n",
    "# 인덱스 생성 (존재하지 않는 경우)\n",
    "if index_name not in pc.list_indexes():\n",
    "    pc.create_index(\n",
    "        name=index_name,\n",
    "        dimension=3,\n",
    "        metric=\"cosine\",\n",
    "        spec=spec\n",
    "    )\n",
    "index = pc.Index(index_name)\n",
    "\n",
    "# LlamaIndex에서 사용할 HuggingFace 임베딩 모델 설정\n",
    "embed_model = HuggingFaceEmbedding(model_name=\"all-MiniLM-L6-v2\")\n",
    "\n",
    "# 문서 데이터\n",
    "documents = [\n",
    "    \"고양이는 작은 육식동물로, 주로 애완동물로 기릅니다. 민첩하고 장난기 있는 행동으로 유명합니다.\",\n",
    "    \"강아지는 충성심이 강하고 친절한 동물로, 흔히 인간의 최고의 친구로 불립니다. 주로 애완동물로 기르고, 동반자로서 유명합니다.\",\n",
    "    \"고양이와 강아지는 전 세계적으로 인기 있는 애완동물로, 각각 독특한 특징을 가지고 있습니다.\"\n",
    "]\n",
    "ids = [\"doc1\", \"doc2\", \"doc3\"]\n",
    "\n",
    "# 문서를 Document 형식으로 변환\n",
    "nodes = [Document(text=doc, id_=doc_id) for doc, doc_id in zip(documents, ids)]\n",
    "\n",
    "# Pinecone 벡터 스토어 생성\n",
    "vector_store = PineconeVectorStore(pinecone_index=index)\n",
    "\n",
    "# LlamaIndex의 VectorStoreIndex 생성\n",
    "index = VectorStoreIndex.from_documents(nodes, vector_store=vector_store,\n",
    "embed_model= embed_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "cbf0c8c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[질의 결과]\n",
      "고양이는 독립적이고 까다로운 동물로 알려져 있습니다. 주로 자신의 영역을 중시하며, 깨끗한 습성을 가지고 있습니다. 애정을 표현하는 방식이 다양하며, 주인에게 애정을 나타내는 방식이 강아지와는 조금 다를 수 있습니다.\n"
     ]
    }
   ],
   "source": [
    "query_engine = index.as_query_engine()\n",
    "\n",
    "# 질의 수행\n",
    "query_text = \"고양이에 대해 알려줘\"\n",
    "response = query_engine.query(query_text)\n",
    "\n",
    "# 결과 출력\n",
    "print(\"\\n[질의 결과]\")\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "98108beb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[질의 결과]\n",
      "고양이는 작은 육식동물로, 주로 애완동물로 기르며 민첩하고 장난기 있는 행동으로 유명합니다.\n",
      "\n",
      "[응답에 사용된 문서]\n",
      "1. 고양이는 작은 육식동물로, 주로 애완동물로 기릅니다. 민첩하고 장난기 있는 행동으로 유명합니다.\n",
      "\n",
      "2. 고양이와 강아지는 전 세계적으로 인기 있는 애완동물로, 각각 독특한 특징을 가지고 있습니다.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "vector_store = PineconeVectorStore(pinecone_index=index)\n",
    "\n",
    "# LlamaIndex의 VectorStoreIndex 생성\n",
    "index = VectorStoreIndex.from_documents(nodes, vector_store=vector_store)\n",
    "\n",
    "# 쿼리 엔진 생성\n",
    "query_engine = index.as_query_engine()\n",
    "\n",
    "# 질의 수행\n",
    "query_text = \"고양이에 대해 알려줘\"\n",
    "response = query_engine.query(query_text)\n",
    "\n",
    "# 최종 응답 출력\n",
    "print(\"[질의 결과]\")\n",
    "print(response)\n",
    "\n",
    "# 응답 생성에 사용된 문서 확인\n",
    "print(\"\\n[응답에 사용된 문서]\")\n",
    "for i, node in enumerate(response.source_nodes, 1):\n",
    "    print(f\"{i}. {node.text}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c1403651",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting llama-index-vector-stores-qdrant==0.3.0\n",
      "  Using cached llama_index_vector_stores_qdrant-0.3.0-py3-none-any.whl.metadata (767 bytes)\n",
      "Requirement already satisfied: grpcio<2.0.0,>=1.60.0 in ./ch03_env/lib/python3.11/site-packages (from llama-index-vector-stores-qdrant==0.3.0) (1.73.1)\n",
      "Requirement already satisfied: llama-index-core<0.12.0,>=0.11.0 in ./ch03_env/lib/python3.11/site-packages (from llama-index-vector-stores-qdrant==0.3.0) (0.11.23)\n",
      "Collecting qdrant-client>=1.7.1 (from llama-index-vector-stores-qdrant==0.3.0)\n",
      "  Downloading qdrant_client-1.14.3-py3-none-any.whl.metadata (10 kB)\n",
      "Requirement already satisfied: PyYAML>=6.0.1 in ./ch03_env/lib/python3.11/site-packages (from llama-index-core<0.12.0,>=0.11.0->llama-index-vector-stores-qdrant==0.3.0) (6.0.2)\n",
      "Requirement already satisfied: SQLAlchemy>=1.4.49 in ./ch03_env/lib/python3.11/site-packages (from SQLAlchemy[asyncio]>=1.4.49->llama-index-core<0.12.0,>=0.11.0->llama-index-vector-stores-qdrant==0.3.0) (2.0.41)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.6 in ./ch03_env/lib/python3.11/site-packages (from llama-index-core<0.12.0,>=0.11.0->llama-index-vector-stores-qdrant==0.3.0) (3.12.13)\n",
      "Requirement already satisfied: dataclasses-json in ./ch03_env/lib/python3.11/site-packages (from llama-index-core<0.12.0,>=0.11.0->llama-index-vector-stores-qdrant==0.3.0) (0.6.7)\n",
      "Requirement already satisfied: deprecated>=1.2.9.3 in ./ch03_env/lib/python3.11/site-packages (from llama-index-core<0.12.0,>=0.11.0->llama-index-vector-stores-qdrant==0.3.0) (1.2.18)\n",
      "Requirement already satisfied: dirtyjson<2.0.0,>=1.0.8 in ./ch03_env/lib/python3.11/site-packages (from llama-index-core<0.12.0,>=0.11.0->llama-index-vector-stores-qdrant==0.3.0) (1.0.8)\n",
      "Requirement already satisfied: filetype<2.0.0,>=1.2.0 in ./ch03_env/lib/python3.11/site-packages (from llama-index-core<0.12.0,>=0.11.0->llama-index-vector-stores-qdrant==0.3.0) (1.2.0)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in ./ch03_env/lib/python3.11/site-packages (from llama-index-core<0.12.0,>=0.11.0->llama-index-vector-stores-qdrant==0.3.0) (2025.5.1)\n",
      "Requirement already satisfied: httpx in ./ch03_env/lib/python3.11/site-packages (from llama-index-core<0.12.0,>=0.11.0->llama-index-vector-stores-qdrant==0.3.0) (0.28.1)\n",
      "Requirement already satisfied: nest-asyncio<2.0.0,>=1.5.8 in ./ch03_env/lib/python3.11/site-packages (from llama-index-core<0.12.0,>=0.11.0->llama-index-vector-stores-qdrant==0.3.0) (1.6.0)\n",
      "Requirement already satisfied: networkx>=3.0 in ./ch03_env/lib/python3.11/site-packages (from llama-index-core<0.12.0,>=0.11.0->llama-index-vector-stores-qdrant==0.3.0) (3.5)\n",
      "Requirement already satisfied: nltk>3.8.1 in ./ch03_env/lib/python3.11/site-packages (from llama-index-core<0.12.0,>=0.11.0->llama-index-vector-stores-qdrant==0.3.0) (3.9.1)\n",
      "Requirement already satisfied: numpy<2.0.0 in ./ch03_env/lib/python3.11/site-packages (from llama-index-core<0.12.0,>=0.11.0->llama-index-vector-stores-qdrant==0.3.0) (1.26.4)\n",
      "Requirement already satisfied: pillow>=9.0.0 in ./ch03_env/lib/python3.11/site-packages (from llama-index-core<0.12.0,>=0.11.0->llama-index-vector-stores-qdrant==0.3.0) (11.2.1)\n",
      "Requirement already satisfied: pydantic<3.0.0,>=2.7.0 in ./ch03_env/lib/python3.11/site-packages (from llama-index-core<0.12.0,>=0.11.0->llama-index-vector-stores-qdrant==0.3.0) (2.11.7)\n",
      "Requirement already satisfied: requests>=2.31.0 in ./ch03_env/lib/python3.11/site-packages (from llama-index-core<0.12.0,>=0.11.0->llama-index-vector-stores-qdrant==0.3.0) (2.32.4)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<9.0.0,>=8.2.0 in ./ch03_env/lib/python3.11/site-packages (from llama-index-core<0.12.0,>=0.11.0->llama-index-vector-stores-qdrant==0.3.0) (8.5.0)\n",
      "Requirement already satisfied: tiktoken>=0.3.3 in ./ch03_env/lib/python3.11/site-packages (from llama-index-core<0.12.0,>=0.11.0->llama-index-vector-stores-qdrant==0.3.0) (0.9.0)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.66.1 in ./ch03_env/lib/python3.11/site-packages (from llama-index-core<0.12.0,>=0.11.0->llama-index-vector-stores-qdrant==0.3.0) (4.67.1)\n",
      "Requirement already satisfied: typing-extensions>=4.5.0 in ./ch03_env/lib/python3.11/site-packages (from llama-index-core<0.12.0,>=0.11.0->llama-index-vector-stores-qdrant==0.3.0) (4.14.0)\n",
      "Requirement already satisfied: typing-inspect>=0.8.0 in ./ch03_env/lib/python3.11/site-packages (from llama-index-core<0.12.0,>=0.11.0->llama-index-vector-stores-qdrant==0.3.0) (0.9.0)\n",
      "Requirement already satisfied: wrapt in ./ch03_env/lib/python3.11/site-packages (from llama-index-core<0.12.0,>=0.11.0->llama-index-vector-stores-qdrant==0.3.0) (1.17.2)\n",
      "Collecting portalocker<3.0.0,>=2.7.0 (from qdrant-client>=1.7.1->llama-index-vector-stores-qdrant==0.3.0)\n",
      "  Using cached portalocker-2.10.1-py3-none-any.whl.metadata (8.5 kB)\n",
      "Requirement already satisfied: protobuf>=3.20.0 in ./ch03_env/lib/python3.11/site-packages (from qdrant-client>=1.7.1->llama-index-vector-stores-qdrant==0.3.0) (5.29.5)\n",
      "Requirement already satisfied: urllib3<3,>=1.26.14 in ./ch03_env/lib/python3.11/site-packages (from qdrant-client>=1.7.1->llama-index-vector-stores-qdrant==0.3.0) (2.5.0)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in ./ch03_env/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.12.0,>=0.11.0->llama-index-vector-stores-qdrant==0.3.0) (2.6.1)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in ./ch03_env/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.12.0,>=0.11.0->llama-index-vector-stores-qdrant==0.3.0) (1.3.2)\n",
      "Requirement already satisfied: attrs>=17.3.0 in ./ch03_env/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.12.0,>=0.11.0->llama-index-vector-stores-qdrant==0.3.0) (25.3.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in ./ch03_env/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.12.0,>=0.11.0->llama-index-vector-stores-qdrant==0.3.0) (1.7.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in ./ch03_env/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.12.0,>=0.11.0->llama-index-vector-stores-qdrant==0.3.0) (6.6.2)\n",
      "Requirement already satisfied: propcache>=0.2.0 in ./ch03_env/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.12.0,>=0.11.0->llama-index-vector-stores-qdrant==0.3.0) (0.3.2)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in ./ch03_env/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.12.0,>=0.11.0->llama-index-vector-stores-qdrant==0.3.0) (1.20.1)\n",
      "Requirement already satisfied: anyio in ./ch03_env/lib/python3.11/site-packages (from httpx->llama-index-core<0.12.0,>=0.11.0->llama-index-vector-stores-qdrant==0.3.0) (4.9.0)\n",
      "Requirement already satisfied: certifi in ./ch03_env/lib/python3.11/site-packages (from httpx->llama-index-core<0.12.0,>=0.11.0->llama-index-vector-stores-qdrant==0.3.0) (2025.6.15)\n",
      "Requirement already satisfied: httpcore==1.* in ./ch03_env/lib/python3.11/site-packages (from httpx->llama-index-core<0.12.0,>=0.11.0->llama-index-vector-stores-qdrant==0.3.0) (1.0.9)\n",
      "Requirement already satisfied: idna in ./ch03_env/lib/python3.11/site-packages (from httpx->llama-index-core<0.12.0,>=0.11.0->llama-index-vector-stores-qdrant==0.3.0) (3.10)\n",
      "Requirement already satisfied: h11>=0.16 in ./ch03_env/lib/python3.11/site-packages (from httpcore==1.*->httpx->llama-index-core<0.12.0,>=0.11.0->llama-index-vector-stores-qdrant==0.3.0) (0.16.0)\n",
      "Collecting h2<5,>=3 (from httpx[http2]>=0.20.0->qdrant-client>=1.7.1->llama-index-vector-stores-qdrant==0.3.0)\n",
      "  Using cached h2-4.2.0-py3-none-any.whl.metadata (5.1 kB)\n",
      "Requirement already satisfied: click in ./ch03_env/lib/python3.11/site-packages (from nltk>3.8.1->llama-index-core<0.12.0,>=0.11.0->llama-index-vector-stores-qdrant==0.3.0) (8.2.1)\n",
      "Requirement already satisfied: joblib in ./ch03_env/lib/python3.11/site-packages (from nltk>3.8.1->llama-index-core<0.12.0,>=0.11.0->llama-index-vector-stores-qdrant==0.3.0) (1.5.1)\n",
      "Requirement already satisfied: regex>=2021.8.3 in ./ch03_env/lib/python3.11/site-packages (from nltk>3.8.1->llama-index-core<0.12.0,>=0.11.0->llama-index-vector-stores-qdrant==0.3.0) (2024.11.6)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in ./ch03_env/lib/python3.11/site-packages (from pydantic<3.0.0,>=2.7.0->llama-index-core<0.12.0,>=0.11.0->llama-index-vector-stores-qdrant==0.3.0) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.33.2 in ./ch03_env/lib/python3.11/site-packages (from pydantic<3.0.0,>=2.7.0->llama-index-core<0.12.0,>=0.11.0->llama-index-vector-stores-qdrant==0.3.0) (2.33.2)\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in ./ch03_env/lib/python3.11/site-packages (from pydantic<3.0.0,>=2.7.0->llama-index-core<0.12.0,>=0.11.0->llama-index-vector-stores-qdrant==0.3.0) (0.4.1)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in ./ch03_env/lib/python3.11/site-packages (from requests>=2.31.0->llama-index-core<0.12.0,>=0.11.0->llama-index-vector-stores-qdrant==0.3.0) (3.4.2)\n",
      "Requirement already satisfied: greenlet>=1 in ./ch03_env/lib/python3.11/site-packages (from SQLAlchemy[asyncio]>=1.4.49->llama-index-core<0.12.0,>=0.11.0->llama-index-vector-stores-qdrant==0.3.0) (3.2.3)\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in ./ch03_env/lib/python3.11/site-packages (from typing-inspect>=0.8.0->llama-index-core<0.12.0,>=0.11.0->llama-index-vector-stores-qdrant==0.3.0) (1.1.0)\n",
      "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in ./ch03_env/lib/python3.11/site-packages (from dataclasses-json->llama-index-core<0.12.0,>=0.11.0->llama-index-vector-stores-qdrant==0.3.0) (3.26.1)\n",
      "Collecting hyperframe<7,>=6.1 (from h2<5,>=3->httpx[http2]>=0.20.0->qdrant-client>=1.7.1->llama-index-vector-stores-qdrant==0.3.0)\n",
      "  Using cached hyperframe-6.1.0-py3-none-any.whl.metadata (4.3 kB)\n",
      "Collecting hpack<5,>=4.1 (from h2<5,>=3->httpx[http2]>=0.20.0->qdrant-client>=1.7.1->llama-index-vector-stores-qdrant==0.3.0)\n",
      "  Using cached hpack-4.1.0-py3-none-any.whl.metadata (4.6 kB)\n",
      "Requirement already satisfied: packaging>=17.0 in ./ch03_env/lib/python3.11/site-packages (from marshmallow<4.0.0,>=3.18.0->dataclasses-json->llama-index-core<0.12.0,>=0.11.0->llama-index-vector-stores-qdrant==0.3.0) (25.0)\n",
      "Requirement already satisfied: sniffio>=1.1 in ./ch03_env/lib/python3.11/site-packages (from anyio->httpx->llama-index-core<0.12.0,>=0.11.0->llama-index-vector-stores-qdrant==0.3.0) (1.3.1)\n",
      "Using cached llama_index_vector_stores_qdrant-0.3.0-py3-none-any.whl (11 kB)\n",
      "Downloading qdrant_client-1.14.3-py3-none-any.whl (328 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m329.0/329.0 kB\u001b[0m \u001b[31m7.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hUsing cached portalocker-2.10.1-py3-none-any.whl (18 kB)\n",
      "Using cached h2-4.2.0-py3-none-any.whl (60 kB)\n",
      "Using cached hpack-4.1.0-py3-none-any.whl (34 kB)\n",
      "Using cached hyperframe-6.1.0-py3-none-any.whl (13 kB)\n",
      "Installing collected packages: portalocker, hyperframe, hpack, h2, qdrant-client, llama-index-vector-stores-qdrant\n",
      "Successfully installed h2-4.2.0 hpack-4.1.0 hyperframe-6.1.0 llama-index-vector-stores-qdrant-0.3.0 portalocker-2.10.1 qdrant-client-1.14.3\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.0\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.1.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install llama-index-vector-stores-qdrant==0.3.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "02112f11",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core import VectorStoreIndex\n",
    "from llama_index.vector_stores.qdrant import QdrantVectorStore\n",
    "from qdrant_client import QdrantClient\n",
    "from qdrant_client.models import Distance, VectorParams\n",
    "from llama_index.core.schema import Document\n",
    "from qdrant_client import QdrantClient\n",
    "client = QdrantClient(\":memory:\")\n",
    "\n",
    "# 문서 데이터\n",
    "documents = [\n",
    "    \"고양이는 작은 육식동물로, 주로 애완동물로 기릅니다. 민첩하고 장난기 있는 행동으로 유명합니다.\",\n",
    "    \"강아지는 충성심이 강하고 친절한 동물로, 흔히 인간의 최고의 친구로 불립니다. 주로 애완동물로 기르고, 동반자로서 유명합니다.\",\n",
    "    \"고양이와 강아지는 전 세계적으로 인기 있는 애완동물로, 각각 독특한 특징을 가지고 있습니다.\"\n",
    "]\n",
    "ids = [\"doc1\", \"doc2\", \"doc3\"]\n",
    "\n",
    "# 문서를 Document 형식으로 변환\n",
    "documents = [Document(text=doc, id_=doc_id) for doc, doc_id in zip(documents,\n",
    "ids)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c2c4e9c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 특정 디렉터리에 저장 할 경우\n",
    "client = QdrantClient(path=\"./qdrant_db\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "92e917b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Qdrant에 새로운 컬렉션 생성\n",
    "collection_name = \"llama_index_qdrant\"\n",
    "client.create_collection(\n",
    "    collection_name=collection_name,\n",
    "    vectors_config=VectorParams(size=768, distance=Distance.COSINE)\n",
    ")\n",
    "\n",
    "# Qdrant 벡터 스토어 설정\n",
    "vector_store = QdrantVectorStore(client=client, collection_name=collection_name)\n",
    "\n",
    "# 인덱스 생성 및 저장\n",
    "index = VectorStoreIndex.from_documents(documents, vector_store=vector_store)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1035d8c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[질의 결과]\n",
      "고양이는 작은 육식동물로, 주로 애완동물로 기르며 민첩하고 장난기 있는 행동으로 유명합니다.\n",
      "\n",
      "[응답에 사용된 문서]\n",
      "1. 고양이는 작은 육식동물로, 주로 애완동물로 기릅니다. 민첩하고 장난기 있는 행동으로 유명합니다.\n",
      "\n",
      "2. 고양이와 강아지는 전 세계적으로 인기 있는 애완동물로, 각각 독특한 특징을 가지고 있습니다.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 쿼리 엔진 생성 및 실행\n",
    "query_engine = index.as_query_engine()\n",
    "query_text = \"고양이\"\n",
    "response = query_engine.query(query_text)\n",
    "\n",
    "# 최종 응답 출력\n",
    "print(\"[질의 결과]\")\n",
    "print(response)\n",
    "\n",
    "# 응답 생성에 사용된 문서 확인\n",
    "print(\"\\n[응답에 사용된 문서]\")\n",
    "for i, node in enumerate(response.source_nodes, 1):\n",
    "    print(f\"{i}. {node.text}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "65c59121",
   "metadata": {},
   "outputs": [],
   "source": [
    "client = QdrantClient(\"http://localhost\", port=6333)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39a18611",
   "metadata": {},
   "outputs": [],
   "source": [
    "from qdrant_client import QdrantClient\n",
    "from qdrant_client.models import Distance, VectorParams\n",
    "from llama_index.core.schema import Document\n",
    "\n",
    "# Qdrant 클라우드 서버에 연결 (API 키 사용)\n",
    "QDRANT_API_KEY = os.environ.get(\"QDRANT_API_KEY\")\n",
    "\n",
    "QDRANT_HOST = \"host_주소:6333\"\n",
    "client = QdrantClient(QDRANT_HOST, api_key=QDRANT_API_KEY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "e8d7cb1a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[질의 결과]\n",
      "고양이는 작은 육식동물로, 주로 애완동물로 기르며 민첩하고 장난기 있는 행동으로 유명합니다.\n",
      "\n",
      "[응답에 사용된 문서]\n",
      "1. 고양이는 작은 육식동물로, 주로 애완동물로 기릅니다. 민첩하고 장난기 있는 행동으로 유명합니다.\n",
      "\n",
      "2. 고양이와 강아지는 전 세계적으로 인기 있는 애완동물로, 각각 독특한 특징을 가지고 있습니다.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Qdrant 벡터 스토어 설정\n",
    "vector_store = QdrantVectorStore(client=client, collection_name=collection_name)\n",
    "\n",
    "# 인덱스 생성 및 저장\n",
    "index = VectorStoreIndex.from_documents(documents, vector_store=vector_store)\n",
    "\n",
    "# 쿼리 엔진 생성 및 실행\n",
    "query_engine = index.as_query_engine()\n",
    "query_text = \"고양이\"\n",
    "response = query_engine.query(query_text)\n",
    "\n",
    "# 최종 응답 출력\n",
    "print(\"\\n[질의 결과]\")\n",
    "print(response)\n",
    "\n",
    "# 응답 생성에 사용된 문서 확인\n",
    "print(\"\\n[응답에 사용된 문서]\")\n",
    "for i, node in enumerate(response.source_nodes, 1):\n",
    "    print(f\"{i}. {node.text}\\n\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ch03_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
