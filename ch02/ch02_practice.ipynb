{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f07cda6f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting docx2txt\n",
      "  Using cached docx2txt-0.9-py3-none-any.whl.metadata (529 bytes)\n",
      "Using cached docx2txt-0.9-py3-none-any.whl (4.0 kB)\n",
      "Installing collected packages: docx2txt\n",
      "Successfully installed docx2txt-0.9\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.0\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.1.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install docx2txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cf7a6cf2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Ignoring wrong pointing object 6 0 (offset 0)\n"
     ]
    }
   ],
   "source": [
    "from llama_index.core import SimpleDirectoryReader\n",
    "\n",
    "documents = SimpleDirectoryReader(\"sample_docs\").load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "16e8fd87",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Document 1:\n",
      "This is the content of file 1.\n",
      "\n",
      "\n",
      "Document 2:\n",
      "This is the content of file 2.\n",
      "\n",
      "\n",
      "Document 3:\n",
      "This is the content of file 3. \n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# documents 리스트의 각 요소에 접근하여 내용 출력\n",
    "for i, document in enumerate(documents):\n",
    "    print(f\"Document {i+1}:\")\n",
    "    print(document.text)\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7aec09dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Ignoring wrong pointing object 6 0 (offset 0)\n"
     ]
    }
   ],
   "source": [
    "documents = SimpleDirectoryReader(\"sample_docs\", recursive=True).load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "064beea0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Document 1:\n",
      "This is the content of file 1.\n",
      "\n",
      "\n",
      "Document 2:\n",
      "This is the content of file 2.\n",
      "\n",
      "\n",
      "Document 3:\n",
      "This is the content of file 3. \n",
      "\n",
      "\n",
      "Document 4:\n",
      "This is the content of file 4.\n",
      "\n",
      "\n",
      "Document 5:\n",
      "This is the content of file 5.\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# documents 리스트의 각 요소에 접근하여 내용 출력\n",
    "for i, document in enumerate(documents):\n",
    "    print(f\"Document {i+1}:\")\n",
    "    print(document.text)\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3769b5b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Ignoring wrong pointing object 6 0 (offset 0)\n"
     ]
    }
   ],
   "source": [
    "documents = SimpleDirectoryReader(\n",
    "    \"sample_docs\", required_exts=[\".txt\", \".pdf\"], recursive=True\n",
    ").load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "74a83d12",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Document 1:\n",
      "This is the content of file 1.\n",
      "\n",
      "\n",
      "Document 2:\n",
      "This is the content of file 3. \n",
      "\n",
      "\n",
      "Document 3:\n",
      "This is the content of file 4.\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# documents 리스트의 각 요소에 접근하여 내용 출력\n",
    "for i, document in enumerate(documents):\n",
    "    print(f\"Document {i+1}:\")\n",
    "    print(document.text)\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d5fb6c62",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Document 1 metadata:\n",
      "{'file_path': '/Users/gaheeyoon/llamaindex/ch02/sample_docs/file1.txt', 'file_name': 'file1.txt', 'file_type': 'text/plain', 'file_size': 30, 'creation_date': '2025-06-28', 'last_modified_date': '2025-06-28'}\n",
      "\n",
      "\n",
      "Document 2 metadata:\n",
      "{'page_label': '1', 'file_name': 'file3.pdf', 'file_path': '/Users/gaheeyoon/llamaindex/ch02/sample_docs/file3.pdf', 'file_type': 'application/pdf', 'file_size': 9631, 'creation_date': '2025-06-28', 'last_modified_date': '2025-06-28'}\n",
      "\n",
      "\n",
      "Document 3 metadata:\n",
      "{'file_path': '/Users/gaheeyoon/llamaindex/ch02/sample_docs/sub_sample_docs/file4.txt', 'file_name': 'file4.txt', 'file_type': 'text/plain', 'file_size': 30, 'creation_date': '2025-06-28', 'last_modified_date': '2025-06-28'}\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# documents 리스트의 각 요소에 접근하여 메타데이터를 출력\n",
    "for i, document in enumerate(documents):\n",
    "    print(f\"Document {i+1} metadata:\")\n",
    "    print(document.metadata)\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e24471af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting llama-index-readers-database==0.3.0\n",
      "  Using cached llama_index_readers_database-0.3.0-py3-none-any.whl.metadata (1.9 kB)\n",
      "Collecting llama-index-core<0.13.0,>=0.12.0 (from llama-index-readers-database==0.3.0)\n",
      "  Using cached llama_index_core-0.12.44-py3-none-any.whl.metadata (2.5 kB)\n",
      "Requirement already satisfied: aiohttp<4,>=3.8.6 in ./ch02_env/lib/python3.11/site-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-readers-database==0.3.0) (3.12.13)\n",
      "Collecting aiosqlite (from llama-index-core<0.13.0,>=0.12.0->llama-index-readers-database==0.3.0)\n",
      "  Using cached aiosqlite-0.21.0-py3-none-any.whl.metadata (4.3 kB)\n",
      "Collecting banks<3,>=2.0.0 (from llama-index-core<0.13.0,>=0.12.0->llama-index-readers-database==0.3.0)\n",
      "  Using cached banks-2.1.3-py3-none-any.whl.metadata (12 kB)\n",
      "Requirement already satisfied: dataclasses-json in ./ch02_env/lib/python3.11/site-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-readers-database==0.3.0) (0.6.7)\n",
      "Requirement already satisfied: deprecated>=1.2.9.3 in ./ch02_env/lib/python3.11/site-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-readers-database==0.3.0) (1.2.18)\n",
      "Requirement already satisfied: dirtyjson<2,>=1.0.8 in ./ch02_env/lib/python3.11/site-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-readers-database==0.3.0) (1.0.8)\n",
      "Requirement already satisfied: filetype<2,>=1.2.0 in ./ch02_env/lib/python3.11/site-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-readers-database==0.3.0) (1.2.0)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in ./ch02_env/lib/python3.11/site-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-readers-database==0.3.0) (2025.5.1)\n",
      "Requirement already satisfied: httpx in ./ch02_env/lib/python3.11/site-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-readers-database==0.3.0) (0.28.1)\n",
      "Collecting llama-index-workflows<2,>=1.0.1 (from llama-index-core<0.13.0,>=0.12.0->llama-index-readers-database==0.3.0)\n",
      "  Using cached llama_index_workflows-1.0.1-py3-none-any.whl.metadata (5.5 kB)\n",
      "Requirement already satisfied: nest-asyncio<2,>=1.5.8 in ./ch02_env/lib/python3.11/site-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-readers-database==0.3.0) (1.6.0)\n",
      "Requirement already satisfied: networkx>=3.0 in ./ch02_env/lib/python3.11/site-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-readers-database==0.3.0) (3.5)\n",
      "Requirement already satisfied: nltk>3.8.1 in ./ch02_env/lib/python3.11/site-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-readers-database==0.3.0) (3.9.1)\n",
      "Requirement already satisfied: numpy in ./ch02_env/lib/python3.11/site-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-readers-database==0.3.0) (1.26.4)\n",
      "Requirement already satisfied: pillow>=9.0.0 in ./ch02_env/lib/python3.11/site-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-readers-database==0.3.0) (11.2.1)\n",
      "Requirement already satisfied: pydantic>=2.8.0 in ./ch02_env/lib/python3.11/site-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-readers-database==0.3.0) (2.11.7)\n",
      "Requirement already satisfied: pyyaml>=6.0.1 in ./ch02_env/lib/python3.11/site-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-readers-database==0.3.0) (6.0.2)\n",
      "Requirement already satisfied: requests>=2.31.0 in ./ch02_env/lib/python3.11/site-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-readers-database==0.3.0) (2.32.4)\n",
      "Collecting setuptools>=80.9.0 (from llama-index-core<0.13.0,>=0.12.0->llama-index-readers-database==0.3.0)\n",
      "  Using cached setuptools-80.9.0-py3-none-any.whl.metadata (6.6 kB)\n",
      "Requirement already satisfied: sqlalchemy>=1.4.49 in ./ch02_env/lib/python3.11/site-packages (from sqlalchemy[asyncio]>=1.4.49->llama-index-core<0.13.0,>=0.12.0->llama-index-readers-database==0.3.0) (2.0.41)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.2.0 in ./ch02_env/lib/python3.11/site-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-readers-database==0.3.0) (8.5.0)\n",
      "Requirement already satisfied: tiktoken>=0.7.0 in ./ch02_env/lib/python3.11/site-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-readers-database==0.3.0) (0.9.0)\n",
      "Requirement already satisfied: tqdm<5,>=4.66.1 in ./ch02_env/lib/python3.11/site-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-readers-database==0.3.0) (4.67.1)\n",
      "Requirement already satisfied: typing-extensions>=4.5.0 in ./ch02_env/lib/python3.11/site-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-readers-database==0.3.0) (4.14.0)\n",
      "Requirement already satisfied: typing-inspect>=0.8.0 in ./ch02_env/lib/python3.11/site-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-readers-database==0.3.0) (0.9.0)\n",
      "Requirement already satisfied: wrapt in ./ch02_env/lib/python3.11/site-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-readers-database==0.3.0) (1.17.2)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in ./ch02_env/lib/python3.11/site-packages (from aiohttp<4,>=3.8.6->llama-index-core<0.13.0,>=0.12.0->llama-index-readers-database==0.3.0) (2.6.1)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in ./ch02_env/lib/python3.11/site-packages (from aiohttp<4,>=3.8.6->llama-index-core<0.13.0,>=0.12.0->llama-index-readers-database==0.3.0) (1.3.2)\n",
      "Requirement already satisfied: attrs>=17.3.0 in ./ch02_env/lib/python3.11/site-packages (from aiohttp<4,>=3.8.6->llama-index-core<0.13.0,>=0.12.0->llama-index-readers-database==0.3.0) (25.3.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in ./ch02_env/lib/python3.11/site-packages (from aiohttp<4,>=3.8.6->llama-index-core<0.13.0,>=0.12.0->llama-index-readers-database==0.3.0) (1.7.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in ./ch02_env/lib/python3.11/site-packages (from aiohttp<4,>=3.8.6->llama-index-core<0.13.0,>=0.12.0->llama-index-readers-database==0.3.0) (6.6.0)\n",
      "Requirement already satisfied: propcache>=0.2.0 in ./ch02_env/lib/python3.11/site-packages (from aiohttp<4,>=3.8.6->llama-index-core<0.13.0,>=0.12.0->llama-index-readers-database==0.3.0) (0.3.2)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in ./ch02_env/lib/python3.11/site-packages (from aiohttp<4,>=3.8.6->llama-index-core<0.13.0,>=0.12.0->llama-index-readers-database==0.3.0) (1.20.1)\n",
      "Collecting griffe (from banks<3,>=2.0.0->llama-index-core<0.13.0,>=0.12.0->llama-index-readers-database==0.3.0)\n",
      "  Using cached griffe-1.7.3-py3-none-any.whl.metadata (5.0 kB)\n",
      "Collecting jinja2 (from banks<3,>=2.0.0->llama-index-core<0.13.0,>=0.12.0->llama-index-readers-database==0.3.0)\n",
      "  Using cached jinja2-3.1.6-py3-none-any.whl.metadata (2.9 kB)\n",
      "Requirement already satisfied: platformdirs in ./ch02_env/lib/python3.11/site-packages (from banks<3,>=2.0.0->llama-index-core<0.13.0,>=0.12.0->llama-index-readers-database==0.3.0) (4.3.8)\n",
      "Collecting llama-index-instrumentation>=0.1.0 (from llama-index-workflows<2,>=1.0.1->llama-index-core<0.13.0,>=0.12.0->llama-index-readers-database==0.3.0)\n",
      "  Using cached llama_index_instrumentation-0.2.0-py3-none-any.whl.metadata (252 bytes)\n",
      "Requirement already satisfied: click in ./ch02_env/lib/python3.11/site-packages (from nltk>3.8.1->llama-index-core<0.13.0,>=0.12.0->llama-index-readers-database==0.3.0) (8.2.1)\n",
      "Requirement already satisfied: joblib in ./ch02_env/lib/python3.11/site-packages (from nltk>3.8.1->llama-index-core<0.13.0,>=0.12.0->llama-index-readers-database==0.3.0) (1.5.1)\n",
      "Requirement already satisfied: regex>=2021.8.3 in ./ch02_env/lib/python3.11/site-packages (from nltk>3.8.1->llama-index-core<0.13.0,>=0.12.0->llama-index-readers-database==0.3.0) (2024.11.6)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in ./ch02_env/lib/python3.11/site-packages (from pydantic>=2.8.0->llama-index-core<0.13.0,>=0.12.0->llama-index-readers-database==0.3.0) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.33.2 in ./ch02_env/lib/python3.11/site-packages (from pydantic>=2.8.0->llama-index-core<0.13.0,>=0.12.0->llama-index-readers-database==0.3.0) (2.33.2)\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in ./ch02_env/lib/python3.11/site-packages (from pydantic>=2.8.0->llama-index-core<0.13.0,>=0.12.0->llama-index-readers-database==0.3.0) (0.4.1)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in ./ch02_env/lib/python3.11/site-packages (from requests>=2.31.0->llama-index-core<0.13.0,>=0.12.0->llama-index-readers-database==0.3.0) (3.4.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in ./ch02_env/lib/python3.11/site-packages (from requests>=2.31.0->llama-index-core<0.13.0,>=0.12.0->llama-index-readers-database==0.3.0) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in ./ch02_env/lib/python3.11/site-packages (from requests>=2.31.0->llama-index-core<0.13.0,>=0.12.0->llama-index-readers-database==0.3.0) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in ./ch02_env/lib/python3.11/site-packages (from requests>=2.31.0->llama-index-core<0.13.0,>=0.12.0->llama-index-readers-database==0.3.0) (2025.6.15)\n",
      "Requirement already satisfied: greenlet>=1 in ./ch02_env/lib/python3.11/site-packages (from sqlalchemy[asyncio]>=1.4.49->llama-index-core<0.13.0,>=0.12.0->llama-index-readers-database==0.3.0) (3.2.3)\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in ./ch02_env/lib/python3.11/site-packages (from typing-inspect>=0.8.0->llama-index-core<0.13.0,>=0.12.0->llama-index-readers-database==0.3.0) (1.1.0)\n",
      "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in ./ch02_env/lib/python3.11/site-packages (from dataclasses-json->llama-index-core<0.13.0,>=0.12.0->llama-index-readers-database==0.3.0) (3.26.1)\n",
      "Requirement already satisfied: anyio in ./ch02_env/lib/python3.11/site-packages (from httpx->llama-index-core<0.13.0,>=0.12.0->llama-index-readers-database==0.3.0) (4.9.0)\n",
      "Requirement already satisfied: httpcore==1.* in ./ch02_env/lib/python3.11/site-packages (from httpx->llama-index-core<0.13.0,>=0.12.0->llama-index-readers-database==0.3.0) (1.0.9)\n",
      "Requirement already satisfied: h11>=0.16 in ./ch02_env/lib/python3.11/site-packages (from httpcore==1.*->httpx->llama-index-core<0.13.0,>=0.12.0->llama-index-readers-database==0.3.0) (0.16.0)\n",
      "Requirement already satisfied: packaging>=17.0 in ./ch02_env/lib/python3.11/site-packages (from marshmallow<4.0.0,>=3.18.0->dataclasses-json->llama-index-core<0.13.0,>=0.12.0->llama-index-readers-database==0.3.0) (25.0)\n",
      "Requirement already satisfied: sniffio>=1.1 in ./ch02_env/lib/python3.11/site-packages (from anyio->httpx->llama-index-core<0.13.0,>=0.12.0->llama-index-readers-database==0.3.0) (1.3.1)\n",
      "Collecting colorama>=0.4 (from griffe->banks<3,>=2.0.0->llama-index-core<0.13.0,>=0.12.0->llama-index-readers-database==0.3.0)\n",
      "  Using cached colorama-0.4.6-py2.py3-none-any.whl.metadata (17 kB)\n",
      "Collecting MarkupSafe>=2.0 (from jinja2->banks<3,>=2.0.0->llama-index-core<0.13.0,>=0.12.0->llama-index-readers-database==0.3.0)\n",
      "  Using cached MarkupSafe-3.0.2-cp311-cp311-macosx_11_0_arm64.whl.metadata (4.0 kB)\n",
      "Using cached llama_index_readers_database-0.3.0-py3-none-any.whl (3.2 kB)\n",
      "Using cached llama_index_core-0.12.44-py3-none-any.whl (7.6 MB)\n",
      "Using cached banks-2.1.3-py3-none-any.whl (28 kB)\n",
      "Using cached llama_index_workflows-1.0.1-py3-none-any.whl (36 kB)\n",
      "Using cached setuptools-80.9.0-py3-none-any.whl (1.2 MB)\n",
      "Using cached aiosqlite-0.21.0-py3-none-any.whl (15 kB)\n",
      "Using cached llama_index_instrumentation-0.2.0-py3-none-any.whl (14 kB)\n",
      "Using cached griffe-1.7.3-py3-none-any.whl (129 kB)\n",
      "Using cached jinja2-3.1.6-py3-none-any.whl (134 kB)\n",
      "Using cached colorama-0.4.6-py2.py3-none-any.whl (25 kB)\n",
      "Using cached MarkupSafe-3.0.2-cp311-cp311-macosx_11_0_arm64.whl (12 kB)\n",
      "Installing collected packages: setuptools, MarkupSafe, colorama, aiosqlite, jinja2, griffe, llama-index-instrumentation, banks, llama-index-workflows, llama-index-core, llama-index-readers-database\n",
      "  Attempting uninstall: setuptools\n",
      "    Found existing installation: setuptools 65.5.0\n",
      "    Uninstalling setuptools-65.5.0:\n",
      "      Successfully uninstalled setuptools-65.5.0\n",
      "  Attempting uninstall: llama-index-core\n",
      "    Found existing installation: llama-index-core 0.11.23\n",
      "    Uninstalling llama-index-core-0.11.23:\n",
      "      Successfully uninstalled llama-index-core-0.11.23\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "llama-index-question-gen-openai 0.2.0 requires llama-index-core<0.12.0,>=0.11.0, but you have llama-index-core 0.12.44 which is incompatible.\n",
      "llama-index 0.11.11 requires llama-index-core<0.12.0,>=0.11.10, but you have llama-index-core 0.12.44 which is incompatible.\n",
      "llama-index-program-openai 0.2.0 requires llama-index-core<0.12.0,>=0.11.0, but you have llama-index-core 0.12.44 which is incompatible.\n",
      "llama-index-agent-openai 0.3.4 requires llama-index-core<0.12.0,>=0.11.0, but you have llama-index-core 0.12.44 which is incompatible.\n",
      "llama-index-multi-modal-llms-openai 0.2.3 requires llama-index-core<0.12.0,>=0.11.0, but you have llama-index-core 0.12.44 which is incompatible.\n",
      "llama-index-embeddings-openai 0.2.5 requires llama-index-core<0.12.0,>=0.11.0, but you have llama-index-core 0.12.44 which is incompatible.\n",
      "llama-index-cli 0.3.1 requires llama-index-core<0.12.0,>=0.11.0, but you have llama-index-core 0.12.44 which is incompatible.\n",
      "llama-index-readers-llama-parse 0.3.0 requires llama-index-core<0.12.0,>=0.11.0, but you have llama-index-core 0.12.44 which is incompatible.\n",
      "llama-index-readers-file 0.2.2 requires llama-index-core<0.12.0,>=0.11.0, but you have llama-index-core 0.12.44 which is incompatible.\n",
      "llama-index-llms-openai 0.2.16 requires llama-index-core<0.12.0,>=0.11.7, but you have llama-index-core 0.12.44 which is incompatible.\n",
      "llama-index-indices-managed-llama-cloud 0.6.0 requires llama-index-core<0.12.0,>=0.11.13.post1, but you have llama-index-core 0.12.44 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed MarkupSafe-3.0.2 aiosqlite-0.21.0 banks-2.1.3 colorama-0.4.6 griffe-1.7.3 jinja2-3.1.6 llama-index-core-0.12.44 llama-index-instrumentation-0.2.0 llama-index-readers-database-0.3.0 llama-index-workflows-1.0.1 setuptools-80.9.0\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.0\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.1.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install llama-index-readers-database==0.3.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "bb2c0d7a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pymysql\n",
      "  Using cached PyMySQL-1.1.1-py3-none-any.whl.metadata (4.4 kB)\n",
      "Using cached PyMySQL-1.1.1-py3-none-any.whl (44 kB)\n",
      "Installing collected packages: pymysql\n",
      "Successfully installed pymysql-1.1.1\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.0\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.1.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install pymysql"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "80f7be47",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sqlalchemy import create_engine\n",
    "from llama_index.readers.database import DatabaseReader\n",
    "\n",
    "# MySQL 연결 정보 직접 입력\n",
    "scheme = \"mysql+pymysql\"\n",
    "host = \"localhost\"\n",
    "port = \"3306\"\n",
    "user = \"root\"\n",
    "dbname = \"test_db\"\n",
    "password = \"your_password\"\n",
    "password = \"mysql5171\"\n",
    "\n",
    "connection_string = f\"{scheme}://{user}:{password}@{host}:{port}/{dbname}\"\n",
    "\n",
    "engine = create_engine(connection_string)\n",
    "reader = DatabaseReader(sql_database=engine)\n",
    "\n",
    "# 데이터 로드\n",
    "query = \"SELECT * FROM users\"\n",
    "documents = reader.load_data(query=query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9c550f65",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Document 1:\n",
      "ID 6cfca4af-21aa-4240-9b2e-e651bbb7626a\n",
      "Row id: 1, name: Alice, email: alice@example.com, age: 30\n",
      "--------------------------------------------------\n",
      "Document 2:\n",
      "ID fd8e3c93-f63e-4e06-a7b1-a0c03abaedd3\n",
      "Row id: 2, name: Bob, email: bob@example.com, age: 25\n",
      "--------------------------------------------------\n",
      "Document 3:\n",
      "ID 0e1e8461-e329-4627-b10e-0ebc652242ac\n",
      "Row id: 3, name: Charlie, email: charlie@example.com, age: 35\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# documents 리스트의 각 요소 출력\n",
    "for idx, doc in enumerate(documents):\n",
    "    print(f\"Document {idx + 1}:\")\n",
    "    print(f\"ID {doc.id_}\")\n",
    "    print(f\"Row {doc.text}\")\n",
    "    print(\"-\" * 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "52d20b1d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Doc ID: c87a078d-9969-4af1-bfda-2669f3a35a07\n",
      "Text: 영화 '기생충'은 가난한 가족인 기우네가 부유한 박 사장네 집에 하나씩 취업하면서 벌어지는 이야기입니다. 처음에는\n",
      "평화로워 보이지만, 이들의 거짓말이 쌓이며 긴장감이 점점 고조됩니다. 박 사장네 집에는 비밀 지하실이 존재하며, 그곳에는\n",
      "오랫동안 숨어 살던 남자가 있다는 반전이 있습니다.이 사실을 알게 된 기우네 가족은 예상치 못한 위기를 맞이하게 됩니다. 결국\n",
      "극한 상황에서 벌어지는 사건으로 인해 비극적인 결말로 이어집니다.\n"
     ]
    }
   ],
   "source": [
    "from llama_index.core import Document\n",
    "\n",
    "# 텍스트 데이터를 기반으로 문서 생성\n",
    "document_text = (\n",
    "    \"영화 '기생충'은 가난한 가족인 기우네가 부유한 박 사장네 집에 하나씩 취업하면서 벌어지는 이야기입니다. \"\n",
    "    \"처음에는 평화로워 보이지만, 이들의 거짓말이 쌓이며 긴장감이 점점 고조됩니다. \"\n",
    "    \"박 사장네 집에는 비밀 지하실이 존재하며, 그곳에는 오랫동안 숨어 살던 남자가 있다는 반전이 있습니다.\"\n",
    "    \"이 사실을 알게 된 기우네 가족은 예상치 못한 위기를 맞이하게 됩니다. \"\n",
    "    \"결국 극한 상황에서 벌어지는 사건으로 인해 비극적인 결말로 이어집니다.\"\n",
    ")\n",
    "document = Document(text=document_text)\n",
    "\n",
    "# 메타데이터 추가\n",
    "document.metadata = {\"author\": \"영화 해설\", \"subject\": \"기생충 줄거리\"}\n",
    "\n",
    "print(document)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "4b8ad4dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "생성된 노드들\n",
      "노드 1: 영화 '기생충'은 가난한 가족인 기우네가 부유한 박 사장네 집에 하나씩 취업하면서 벌어지는 이야기입니다.\n",
      " 메타데이터: {'type': '영화 줄거리', 'genre': '드라마', 'node_id': 1}\n",
      "노드 2: 처음에는 평화로워 보이지만, 이들의 거짓말이 쌓이며 긴장감이 점점 고조됩니다.\n",
      " 메타데이터: {'type': '영화 줄거리', 'genre': '드라마', 'node_id': 2}\n",
      "노드 3: 박 사장네 집에는 비밀 지하실이 존재하며, 그곳에는 오랫동안 숨어 살던 남자가 있다는 반전이 있습니다.\n",
      " 메타데이터: {'type': '영화 줄거리', 'genre': '드라마', 'node_id': 3}\n",
      "노드 4: 이 사실을 알게 된 기우네 가족은 예상치 못한 위기를 맞이하게 됩니다.\n",
      " 메타데이터: {'type': '영화 줄거리', 'genre': '드라마', 'node_id': 4}\n",
      "노드 5: 결국 극한 상황에서 벌어지는 사건으로 인해 비극적인 결말로 이어집니다.\n",
      " 메타데이터: {'type': '영화 줄거리', 'genre': '드라마', 'node_id': 5}\n"
     ]
    }
   ],
   "source": [
    "from llama_index.core.node_parser import SimpleNodeParser\n",
    "\n",
    "parser = SimpleNodeParser(chunk_size=80, chunk_overlap=0)\n",
    "nodes = parser.get_nodes_from_documents([document])\n",
    "\n",
    "print(\"\\n생성된 노드들\")\n",
    "for idx, node in enumerate(nodes, start=1):\n",
    "    node.metadata = {\"type\": \"영화 줄거리\", \"genre\": \"드라마\", \"node_id\": idx}\n",
    "    print(f\"노드 {idx}: {node.text}\")\n",
    "    print(f\" 메타데이터: {node.metadata}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a51f79f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "청크 1: 영화 '기생충'은 가난한 가족인 기우네가 부유한 박 사장네 집에 하나씩 취업하면서 벌어지는 이야기입니다. 처음에는 평화로워 보이지만, 이들의\n",
      "[토큰 개수: 77]\n",
      "\n",
      "청크 2: 거짓말이 쌓이며 긴장감이 점점 고조됩니다. 박 사장네 집에는 비밀 지하실이 존재하며, 그곳에는 오랫동안 숨어 살던 남자가 있다는\n",
      "[토큰 개수: 78]\n",
      "\n",
      "청크 3: 반전이 있습니다.이 사실을 알게 된 기우네 가족은 예상치 못한 위기를 맞이하게 됩니다. 결국 극한 상황에서 벌어지는 사건으로 인해 비극적인 결말로 이어집니다.\n",
      "[토큰 개수: 80]\n",
      "\n",
      "총 생성된 청크 개수: 3\n"
     ]
    }
   ],
   "source": [
    "from llama_index.core.node_parser import TokenTextSplitter\n",
    "import tiktoken\n",
    "\n",
    "# cl100k_base 토크나이저 로드\n",
    "tokenizer = tiktoken.get_encoding(\"cl100k_base\")\n",
    "\n",
    "token_splitter = TokenTextSplitter(chunk_size=80, chunk_overlap=0)\n",
    "\n",
    "chunks = token_splitter.split_text(document_text)\n",
    "\n",
    "for i, chunk in enumerate(chunks):\n",
    "    token_count = len(tokenizer.encode(chunk))  # 각 청크의 토큰 개수 계산\n",
    "    print(f\"청크 {i+1}: {chunk}\\n[토큰 개수: {token_count}]\\n\")\n",
    "\n",
    "print(f\"총 생성된 청크 개수: {len(chunks)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "638a1d7f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "문서 단위 검색 결과\n",
      "문서 검색 응답: 이 영화의 반전은 박 사장네 집에 있는 비밀 지하실에 오랫동안 숨어 살던 남자가 있다는 사실입니다.\n",
      "- 결과 1: 영화 '기생충'은 가난한 가족인 기우네가 부유한 박 사장네 집에 하나씩 취업하면서 벌어지는 이야기입니다. 처음에는 평화로워 보이지만, 이들의 거짓말이 쌓이며 긴장감이 점점 고조됩니다. 박 사장네 집에는 비밀 지하실이 존재하며, 그곳에는 오랫동안 숨어 살던 남자가 있다는 반전이 있습니다.이 사실을 알게 된 기우네 가족은 예상치 못한 위기를 맞이하게 됩니다. 결국 극한 상황에서 벌어지는 사건으로 인해 비극적인 결말로 이어집니다.\n",
      "\n",
      "노드 단위 검색 결과\n",
      "노드 검색 응답: 남자가 박 사장네 집의 비밀 지하실에 숨어 살았다는 것입니다.\n",
      "- 결과 노드 1: 박 사장네 집에는 비밀 지하실이 존재하며, 그곳에는 오랫동안 숨어 살던 남자가 있다는 반전이 있습니다.\n",
      "- 결과 노드 2: 결국 극한 상황에서 벌어지는 사건으로 인해 비극적인 결말로 이어집니다.\n"
     ]
    }
   ],
   "source": [
    "from llama_index.core import VectorStoreIndex, Document, Settings\n",
    "from llama_index.core.node_parser import SimpleNodeParser\n",
    "from llama_index.llms.openai import OpenAI\n",
    "import os\n",
    "\n",
    "# OpenAI 설정\n",
    "llm = OpenAI(\n",
    "    api_key=os.environ[\"OPENAI_API_KEY\"],\n",
    "    model=\"gpt-4o-mini\",\n",
    "    system_prompt=\"반드시 한국어로 답변하세요.\",\n",
    ")\n",
    "\n",
    "# 문서 단위 검색을 위한 전체 문서 인덱스 생성\n",
    "full_doc_index = VectorStoreIndex.from_documents([document], llm=llm)\n",
    "\n",
    "# 노드 단위 검색을 위한 인덱스 생성\n",
    "node_index = VectorStoreIndex(nodes, llm=llm)\n",
    "\n",
    "# 검색 비교\n",
    "query_text = \"이 영화의 반전은?\"\n",
    "\n",
    "## 문서 단위 검색\n",
    "print(\"\\n문서 단위 검색 결과\")\n",
    "doc_query_engine = full_doc_index.as_query_engine()\n",
    "doc_response = doc_query_engine.query(query_text)\n",
    "print(f\"문서 검색 응답: {doc_response.response}\")\n",
    "if doc_response.source_nodes:\n",
    "    for idx, document in enumerate(doc_response.source_nodes, start=1):\n",
    "        print(f\"- 결과 {idx}: {document.node.text}\")\n",
    "\n",
    "## 노드 단위 검색\n",
    "print(\"\\n노드 단위 검색 결과\")\n",
    "node_query_engine = node_index.as_query_engine()\n",
    "node_response = node_query_engine.query(query_text)\n",
    "print(f\"노드 검색 응답: {node_response.response}\")\n",
    "if node_response.source_nodes:\n",
    "    for idx, document in enumerate(node_response.source_nodes, start=1):\n",
    "        print(f\"- 결과 노드 {idx}: {document.node.text}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "32875bfc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "기본 청킹 크기: 1024\n"
     ]
    }
   ],
   "source": [
    "from llama_index.core.node_parser import SimpleNodeParser\n",
    "\n",
    "parser = SimpleNodeParser()\n",
    "print(f\"기본 청킹 크기: {parser.chunk_size}\")  # 출력: 1024"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "a322ab88",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== 토큰 기반 분할 결과 ===\n",
      "Chunk 1: 영화 '기생충'은 가난한 가족인 기우네가 부유한 박 사장네 집에 하나씩 취업하면서 \n",
      "\n",
      "Chunk 2: 취업하면서 벌어지는 이야기입니다. 처음에는 평화로워 보이지만, 이들의 거짓말이 쌓이며 \n",
      "\n",
      "Chunk 3: 쌓이며 긴장감이 점점 고조됩니다. 그러나 이 영화의 반전은 지하실에서 시작됩니다. \n",
      "\n"
     ]
    }
   ],
   "source": [
    "sample_text = \"영화 '기생충'은 가난한 가족인 기우네가 부유한 박 사장네 집에 하나씩 취업하면서 벌어지는 이야기입니다. 처음에는 평화로워 보이지만, 이들의 거짓말이 쌓이며 긴장감이 점점 고조됩니다. 그러나 이 영화의 반전은 지하실에서 시작됩니다.\"\n",
    "\n",
    "token_splitter = TokenTextSplitter(chunk_size=50, chunk_overlap=10)\n",
    "\n",
    "token_chunks = token_splitter.split_text(sample_text)\n",
    "print(\"=== 토큰 기반 분할 결과 ===\")\n",
    "for i, chunk in enumerate(token_chunks):\n",
    "    print(f\"Chunk {i + 1}:\", chunk.strip(), \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "71022f9e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== 문장 기반 분할 결과 ===\n",
      "Chunk 1: 영화 '기생충'은 가난한 가족인 기우네가 부유한 박 사장네 집에 하나씩 취업하면서 \n",
      "\n",
      "Chunk 2: 벌어지는 이야기입니다. \n",
      "\n",
      "Chunk 3: 처음에는 평화로워 보이지만, 이들의 거짓말이 쌓이며 긴장감이 점점 고조됩니다. \n",
      "\n",
      "Chunk 4: 그러나 이 영화의 반전은 지하실에서 시작됩니다. \n",
      "\n"
     ]
    }
   ],
   "source": [
    "from llama_index.core.node_parser.text.sentence import SentenceSplitter\n",
    "\n",
    "splitter = SentenceSplitter(chunk_size=50, chunk_overlap=0)\n",
    "\n",
    "sentence_chunks = splitter.split_text(sample_text)\n",
    "print(\"=== 문장 기반 분할 결과 ===\")\n",
    "for i, chunk in enumerate(sentence_chunks):\n",
    "    print(f\"Chunk {i + 1}:\", chunk.strip(), \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "08ecc381",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== 의미 기반 분할 결과 ===\n",
      "Chunk 1: 영화 '기생충'은 가난한 가족인 기우네가 부유한 박 사장네 집에 하나씩 취업하면서 벌어지는 이야기입니다. \n",
      "\n",
      "Chunk 2: 처음에는 평화로워 보이지만, 이들의 거짓말이 쌓이며 긴장감이 점점 고조됩니다. \n",
      "\n",
      "Chunk 3: 그러나 이 영화의 반전은 지하실에서 시작됩니다. \n",
      "\n"
     ]
    }
   ],
   "source": [
    "from llama_index.core.node_parser import SemanticSplitterNodeParser\n",
    "from llama_index.embeddings.openai import OpenAIEmbedding\n",
    "\n",
    "embed_model = OpenAIEmbedding()\n",
    "\n",
    "splitter = SemanticSplitterNodeParser(\n",
    "    buffer_size=1, breakpoint_percentile_threshold=95, embed_model=embed_model\n",
    ")\n",
    "\n",
    "chunks = splitter.sentence_splitter(sample_text)\n",
    "print(\"=== 의미 기반 분할 결과 ===\")\n",
    "for i, chunk in enumerate(chunks):\n",
    "    print(f\"Chunk {i + 1}:\", chunk.strip(), \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "c0620851",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting transformers\n",
      "  Using cached transformers-4.53.0-py3-none-any.whl.metadata (39 kB)\n",
      "Collecting filelock (from transformers)\n",
      "  Using cached filelock-3.18.0-py3-none-any.whl.metadata (2.9 kB)\n",
      "Collecting huggingface-hub<1.0,>=0.30.0 (from transformers)\n",
      "  Using cached huggingface_hub-0.33.1-py3-none-any.whl.metadata (14 kB)\n",
      "Requirement already satisfied: numpy>=1.17 in ./ch02_env/lib/python3.11/site-packages (from transformers) (1.26.4)\n",
      "Requirement already satisfied: packaging>=20.0 in ./ch02_env/lib/python3.11/site-packages (from transformers) (25.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in ./ch02_env/lib/python3.11/site-packages (from transformers) (6.0.2)\n",
      "Requirement already satisfied: regex!=2019.12.17 in ./ch02_env/lib/python3.11/site-packages (from transformers) (2024.11.6)\n",
      "Requirement already satisfied: requests in ./ch02_env/lib/python3.11/site-packages (from transformers) (2.32.4)\n",
      "Collecting tokenizers<0.22,>=0.21 (from transformers)\n",
      "  Using cached tokenizers-0.21.2-cp39-abi3-macosx_11_0_arm64.whl.metadata (6.8 kB)\n",
      "Collecting safetensors>=0.4.3 (from transformers)\n",
      "  Using cached safetensors-0.5.3-cp38-abi3-macosx_11_0_arm64.whl.metadata (3.8 kB)\n",
      "Requirement already satisfied: tqdm>=4.27 in ./ch02_env/lib/python3.11/site-packages (from transformers) (4.67.1)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in ./ch02_env/lib/python3.11/site-packages (from huggingface-hub<1.0,>=0.30.0->transformers) (2025.5.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in ./ch02_env/lib/python3.11/site-packages (from huggingface-hub<1.0,>=0.30.0->transformers) (4.14.0)\n",
      "Collecting hf-xet<2.0.0,>=1.1.2 (from huggingface-hub<1.0,>=0.30.0->transformers)\n",
      "  Using cached hf_xet-1.1.5-cp37-abi3-macosx_11_0_arm64.whl.metadata (879 bytes)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in ./ch02_env/lib/python3.11/site-packages (from requests->transformers) (3.4.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in ./ch02_env/lib/python3.11/site-packages (from requests->transformers) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in ./ch02_env/lib/python3.11/site-packages (from requests->transformers) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in ./ch02_env/lib/python3.11/site-packages (from requests->transformers) (2025.6.15)\n",
      "Using cached transformers-4.53.0-py3-none-any.whl (10.8 MB)\n",
      "Using cached huggingface_hub-0.33.1-py3-none-any.whl (515 kB)\n",
      "Using cached safetensors-0.5.3-cp38-abi3-macosx_11_0_arm64.whl (418 kB)\n",
      "Using cached tokenizers-0.21.2-cp39-abi3-macosx_11_0_arm64.whl (2.7 MB)\n",
      "Using cached filelock-3.18.0-py3-none-any.whl (16 kB)\n",
      "Using cached hf_xet-1.1.5-cp37-abi3-macosx_11_0_arm64.whl (2.6 MB)\n",
      "Installing collected packages: safetensors, hf-xet, filelock, huggingface-hub, tokenizers, transformers\n",
      "Successfully installed filelock-3.18.0 hf-xet-1.1.5 huggingface-hub-0.33.1 safetensors-0.5.3 tokenizers-0.21.2 transformers-4.53.0\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.0\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.1.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Collecting llama-index-embeddings-huggingface\n",
      "  Using cached llama_index_embeddings_huggingface-0.5.5-py3-none-any.whl.metadata (458 bytes)\n",
      "Requirement already satisfied: huggingface-hub>=0.19.0 in ./ch02_env/lib/python3.11/site-packages (from huggingface-hub[inference]>=0.19.0->llama-index-embeddings-huggingface) (0.33.1)\n",
      "Requirement already satisfied: llama-index-core<0.13,>=0.12.0 in ./ch02_env/lib/python3.11/site-packages (from llama-index-embeddings-huggingface) (0.12.44)\n",
      "Collecting sentence-transformers>=2.6.1 (from llama-index-embeddings-huggingface)\n",
      "  Using cached sentence_transformers-4.1.0-py3-none-any.whl.metadata (13 kB)\n",
      "Requirement already satisfied: filelock in ./ch02_env/lib/python3.11/site-packages (from huggingface-hub>=0.19.0->huggingface-hub[inference]>=0.19.0->llama-index-embeddings-huggingface) (3.18.0)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in ./ch02_env/lib/python3.11/site-packages (from huggingface-hub>=0.19.0->huggingface-hub[inference]>=0.19.0->llama-index-embeddings-huggingface) (2025.5.1)\n",
      "Requirement already satisfied: packaging>=20.9 in ./ch02_env/lib/python3.11/site-packages (from huggingface-hub>=0.19.0->huggingface-hub[inference]>=0.19.0->llama-index-embeddings-huggingface) (25.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in ./ch02_env/lib/python3.11/site-packages (from huggingface-hub>=0.19.0->huggingface-hub[inference]>=0.19.0->llama-index-embeddings-huggingface) (6.0.2)\n",
      "Requirement already satisfied: requests in ./ch02_env/lib/python3.11/site-packages (from huggingface-hub>=0.19.0->huggingface-hub[inference]>=0.19.0->llama-index-embeddings-huggingface) (2.32.4)\n",
      "Requirement already satisfied: tqdm>=4.42.1 in ./ch02_env/lib/python3.11/site-packages (from huggingface-hub>=0.19.0->huggingface-hub[inference]>=0.19.0->llama-index-embeddings-huggingface) (4.67.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in ./ch02_env/lib/python3.11/site-packages (from huggingface-hub>=0.19.0->huggingface-hub[inference]>=0.19.0->llama-index-embeddings-huggingface) (4.14.0)\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.1.2 in ./ch02_env/lib/python3.11/site-packages (from huggingface-hub>=0.19.0->huggingface-hub[inference]>=0.19.0->llama-index-embeddings-huggingface) (1.1.5)\n",
      "Requirement already satisfied: aiohttp in ./ch02_env/lib/python3.11/site-packages (from huggingface-hub[inference]>=0.19.0->llama-index-embeddings-huggingface) (3.12.13)\n",
      "Requirement already satisfied: aiosqlite in ./ch02_env/lib/python3.11/site-packages (from llama-index-core<0.13,>=0.12.0->llama-index-embeddings-huggingface) (0.21.0)\n",
      "Requirement already satisfied: banks<3,>=2.0.0 in ./ch02_env/lib/python3.11/site-packages (from llama-index-core<0.13,>=0.12.0->llama-index-embeddings-huggingface) (2.1.3)\n",
      "Requirement already satisfied: dataclasses-json in ./ch02_env/lib/python3.11/site-packages (from llama-index-core<0.13,>=0.12.0->llama-index-embeddings-huggingface) (0.6.7)\n",
      "Requirement already satisfied: deprecated>=1.2.9.3 in ./ch02_env/lib/python3.11/site-packages (from llama-index-core<0.13,>=0.12.0->llama-index-embeddings-huggingface) (1.2.18)\n",
      "Requirement already satisfied: dirtyjson<2,>=1.0.8 in ./ch02_env/lib/python3.11/site-packages (from llama-index-core<0.13,>=0.12.0->llama-index-embeddings-huggingface) (1.0.8)\n",
      "Requirement already satisfied: filetype<2,>=1.2.0 in ./ch02_env/lib/python3.11/site-packages (from llama-index-core<0.13,>=0.12.0->llama-index-embeddings-huggingface) (1.2.0)\n",
      "Requirement already satisfied: httpx in ./ch02_env/lib/python3.11/site-packages (from llama-index-core<0.13,>=0.12.0->llama-index-embeddings-huggingface) (0.28.1)\n",
      "Requirement already satisfied: llama-index-workflows<2,>=1.0.1 in ./ch02_env/lib/python3.11/site-packages (from llama-index-core<0.13,>=0.12.0->llama-index-embeddings-huggingface) (1.0.1)\n",
      "Requirement already satisfied: nest-asyncio<2,>=1.5.8 in ./ch02_env/lib/python3.11/site-packages (from llama-index-core<0.13,>=0.12.0->llama-index-embeddings-huggingface) (1.6.0)\n",
      "Requirement already satisfied: networkx>=3.0 in ./ch02_env/lib/python3.11/site-packages (from llama-index-core<0.13,>=0.12.0->llama-index-embeddings-huggingface) (3.5)\n",
      "Requirement already satisfied: nltk>3.8.1 in ./ch02_env/lib/python3.11/site-packages (from llama-index-core<0.13,>=0.12.0->llama-index-embeddings-huggingface) (3.9.1)\n",
      "Requirement already satisfied: numpy in ./ch02_env/lib/python3.11/site-packages (from llama-index-core<0.13,>=0.12.0->llama-index-embeddings-huggingface) (1.26.4)\n",
      "Requirement already satisfied: pillow>=9.0.0 in ./ch02_env/lib/python3.11/site-packages (from llama-index-core<0.13,>=0.12.0->llama-index-embeddings-huggingface) (11.2.1)\n",
      "Requirement already satisfied: pydantic>=2.8.0 in ./ch02_env/lib/python3.11/site-packages (from llama-index-core<0.13,>=0.12.0->llama-index-embeddings-huggingface) (2.11.7)\n",
      "Requirement already satisfied: setuptools>=80.9.0 in ./ch02_env/lib/python3.11/site-packages (from llama-index-core<0.13,>=0.12.0->llama-index-embeddings-huggingface) (80.9.0)\n",
      "Requirement already satisfied: sqlalchemy>=1.4.49 in ./ch02_env/lib/python3.11/site-packages (from sqlalchemy[asyncio]>=1.4.49->llama-index-core<0.13,>=0.12.0->llama-index-embeddings-huggingface) (2.0.41)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.2.0 in ./ch02_env/lib/python3.11/site-packages (from llama-index-core<0.13,>=0.12.0->llama-index-embeddings-huggingface) (8.5.0)\n",
      "Requirement already satisfied: tiktoken>=0.7.0 in ./ch02_env/lib/python3.11/site-packages (from llama-index-core<0.13,>=0.12.0->llama-index-embeddings-huggingface) (0.9.0)\n",
      "Requirement already satisfied: typing-inspect>=0.8.0 in ./ch02_env/lib/python3.11/site-packages (from llama-index-core<0.13,>=0.12.0->llama-index-embeddings-huggingface) (0.9.0)\n",
      "Requirement already satisfied: wrapt in ./ch02_env/lib/python3.11/site-packages (from llama-index-core<0.13,>=0.12.0->llama-index-embeddings-huggingface) (1.17.2)\n",
      "Requirement already satisfied: transformers<5.0.0,>=4.41.0 in ./ch02_env/lib/python3.11/site-packages (from sentence-transformers>=2.6.1->llama-index-embeddings-huggingface) (4.53.0)\n",
      "Collecting torch>=1.11.0 (from sentence-transformers>=2.6.1->llama-index-embeddings-huggingface)\n",
      "  Using cached torch-2.7.1-cp311-none-macosx_11_0_arm64.whl.metadata (29 kB)\n",
      "Collecting scikit-learn (from sentence-transformers>=2.6.1->llama-index-embeddings-huggingface)\n",
      "  Using cached scikit_learn-1.7.0-cp311-cp311-macosx_12_0_arm64.whl.metadata (31 kB)\n",
      "Collecting scipy (from sentence-transformers>=2.6.1->llama-index-embeddings-huggingface)\n",
      "  Using cached scipy-1.16.0-cp311-cp311-macosx_14_0_arm64.whl.metadata (61 kB)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in ./ch02_env/lib/python3.11/site-packages (from aiohttp->huggingface-hub[inference]>=0.19.0->llama-index-embeddings-huggingface) (2.6.1)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in ./ch02_env/lib/python3.11/site-packages (from aiohttp->huggingface-hub[inference]>=0.19.0->llama-index-embeddings-huggingface) (1.3.2)\n",
      "Requirement already satisfied: attrs>=17.3.0 in ./ch02_env/lib/python3.11/site-packages (from aiohttp->huggingface-hub[inference]>=0.19.0->llama-index-embeddings-huggingface) (25.3.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in ./ch02_env/lib/python3.11/site-packages (from aiohttp->huggingface-hub[inference]>=0.19.0->llama-index-embeddings-huggingface) (1.7.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in ./ch02_env/lib/python3.11/site-packages (from aiohttp->huggingface-hub[inference]>=0.19.0->llama-index-embeddings-huggingface) (6.6.0)\n",
      "Requirement already satisfied: propcache>=0.2.0 in ./ch02_env/lib/python3.11/site-packages (from aiohttp->huggingface-hub[inference]>=0.19.0->llama-index-embeddings-huggingface) (0.3.2)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in ./ch02_env/lib/python3.11/site-packages (from aiohttp->huggingface-hub[inference]>=0.19.0->llama-index-embeddings-huggingface) (1.20.1)\n",
      "Requirement already satisfied: griffe in ./ch02_env/lib/python3.11/site-packages (from banks<3,>=2.0.0->llama-index-core<0.13,>=0.12.0->llama-index-embeddings-huggingface) (1.7.3)\n",
      "Requirement already satisfied: jinja2 in ./ch02_env/lib/python3.11/site-packages (from banks<3,>=2.0.0->llama-index-core<0.13,>=0.12.0->llama-index-embeddings-huggingface) (3.1.6)\n",
      "Requirement already satisfied: platformdirs in ./ch02_env/lib/python3.11/site-packages (from banks<3,>=2.0.0->llama-index-core<0.13,>=0.12.0->llama-index-embeddings-huggingface) (4.3.8)\n",
      "Requirement already satisfied: llama-index-instrumentation>=0.1.0 in ./ch02_env/lib/python3.11/site-packages (from llama-index-workflows<2,>=1.0.1->llama-index-core<0.13,>=0.12.0->llama-index-embeddings-huggingface) (0.2.0)\n",
      "Requirement already satisfied: click in ./ch02_env/lib/python3.11/site-packages (from nltk>3.8.1->llama-index-core<0.13,>=0.12.0->llama-index-embeddings-huggingface) (8.2.1)\n",
      "Requirement already satisfied: joblib in ./ch02_env/lib/python3.11/site-packages (from nltk>3.8.1->llama-index-core<0.13,>=0.12.0->llama-index-embeddings-huggingface) (1.5.1)\n",
      "Requirement already satisfied: regex>=2021.8.3 in ./ch02_env/lib/python3.11/site-packages (from nltk>3.8.1->llama-index-core<0.13,>=0.12.0->llama-index-embeddings-huggingface) (2024.11.6)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in ./ch02_env/lib/python3.11/site-packages (from pydantic>=2.8.0->llama-index-core<0.13,>=0.12.0->llama-index-embeddings-huggingface) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.33.2 in ./ch02_env/lib/python3.11/site-packages (from pydantic>=2.8.0->llama-index-core<0.13,>=0.12.0->llama-index-embeddings-huggingface) (2.33.2)\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in ./ch02_env/lib/python3.11/site-packages (from pydantic>=2.8.0->llama-index-core<0.13,>=0.12.0->llama-index-embeddings-huggingface) (0.4.1)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in ./ch02_env/lib/python3.11/site-packages (from requests->huggingface-hub>=0.19.0->huggingface-hub[inference]>=0.19.0->llama-index-embeddings-huggingface) (3.4.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in ./ch02_env/lib/python3.11/site-packages (from requests->huggingface-hub>=0.19.0->huggingface-hub[inference]>=0.19.0->llama-index-embeddings-huggingface) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in ./ch02_env/lib/python3.11/site-packages (from requests->huggingface-hub>=0.19.0->huggingface-hub[inference]>=0.19.0->llama-index-embeddings-huggingface) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in ./ch02_env/lib/python3.11/site-packages (from requests->huggingface-hub>=0.19.0->huggingface-hub[inference]>=0.19.0->llama-index-embeddings-huggingface) (2025.6.15)\n",
      "Requirement already satisfied: greenlet>=1 in ./ch02_env/lib/python3.11/site-packages (from sqlalchemy[asyncio]>=1.4.49->llama-index-core<0.13,>=0.12.0->llama-index-embeddings-huggingface) (3.2.3)\n",
      "Collecting sympy>=1.13.3 (from torch>=1.11.0->sentence-transformers>=2.6.1->llama-index-embeddings-huggingface)\n",
      "  Using cached sympy-1.14.0-py3-none-any.whl.metadata (12 kB)\n",
      "Requirement already satisfied: tokenizers<0.22,>=0.21 in ./ch02_env/lib/python3.11/site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers>=2.6.1->llama-index-embeddings-huggingface) (0.21.2)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in ./ch02_env/lib/python3.11/site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers>=2.6.1->llama-index-embeddings-huggingface) (0.5.3)\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in ./ch02_env/lib/python3.11/site-packages (from typing-inspect>=0.8.0->llama-index-core<0.13,>=0.12.0->llama-index-embeddings-huggingface) (1.1.0)\n",
      "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in ./ch02_env/lib/python3.11/site-packages (from dataclasses-json->llama-index-core<0.13,>=0.12.0->llama-index-embeddings-huggingface) (3.26.1)\n",
      "Requirement already satisfied: anyio in ./ch02_env/lib/python3.11/site-packages (from httpx->llama-index-core<0.13,>=0.12.0->llama-index-embeddings-huggingface) (4.9.0)\n",
      "Requirement already satisfied: httpcore==1.* in ./ch02_env/lib/python3.11/site-packages (from httpx->llama-index-core<0.13,>=0.12.0->llama-index-embeddings-huggingface) (1.0.9)\n",
      "Requirement already satisfied: h11>=0.16 in ./ch02_env/lib/python3.11/site-packages (from httpcore==1.*->httpx->llama-index-core<0.13,>=0.12.0->llama-index-embeddings-huggingface) (0.16.0)\n",
      "Collecting threadpoolctl>=3.1.0 (from scikit-learn->sentence-transformers>=2.6.1->llama-index-embeddings-huggingface)\n",
      "  Using cached threadpoolctl-3.6.0-py3-none-any.whl.metadata (13 kB)\n",
      "Collecting mpmath<1.4,>=1.1.0 (from sympy>=1.13.3->torch>=1.11.0->sentence-transformers>=2.6.1->llama-index-embeddings-huggingface)\n",
      "  Using cached mpmath-1.3.0-py3-none-any.whl.metadata (8.6 kB)\n",
      "Requirement already satisfied: sniffio>=1.1 in ./ch02_env/lib/python3.11/site-packages (from anyio->httpx->llama-index-core<0.13,>=0.12.0->llama-index-embeddings-huggingface) (1.3.1)\n",
      "Requirement already satisfied: colorama>=0.4 in ./ch02_env/lib/python3.11/site-packages (from griffe->banks<3,>=2.0.0->llama-index-core<0.13,>=0.12.0->llama-index-embeddings-huggingface) (0.4.6)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in ./ch02_env/lib/python3.11/site-packages (from jinja2->banks<3,>=2.0.0->llama-index-core<0.13,>=0.12.0->llama-index-embeddings-huggingface) (3.0.2)\n",
      "Using cached llama_index_embeddings_huggingface-0.5.5-py3-none-any.whl (8.9 kB)\n",
      "Using cached sentence_transformers-4.1.0-py3-none-any.whl (345 kB)\n",
      "Using cached torch-2.7.1-cp311-none-macosx_11_0_arm64.whl (68.6 MB)\n",
      "Using cached scikit_learn-1.7.0-cp311-cp311-macosx_12_0_arm64.whl (10.7 MB)\n",
      "Using cached scipy-1.16.0-cp311-cp311-macosx_14_0_arm64.whl (20.8 MB)\n",
      "Using cached sympy-1.14.0-py3-none-any.whl (6.3 MB)\n",
      "Using cached threadpoolctl-3.6.0-py3-none-any.whl (18 kB)\n",
      "Using cached mpmath-1.3.0-py3-none-any.whl (536 kB)\n",
      "Installing collected packages: mpmath, threadpoolctl, sympy, scipy, torch, scikit-learn, sentence-transformers, llama-index-embeddings-huggingface\n",
      "Successfully installed llama-index-embeddings-huggingface-0.5.5 mpmath-1.3.0 scikit-learn-1.7.0 scipy-1.16.0 sentence-transformers-4.1.0 sympy-1.14.0 threadpoolctl-3.6.0 torch-2.7.1\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.0\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.1.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install transformers\n",
    "!pip install llama-index-embeddings-huggingface"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "fff7c58b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/gaheeyoon/llamaindex/ch02/ch02_env/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== 의미 기반 분할 결과 ===\n",
      "Chunk 1: 영화 '기생충'은 가난한 가족인 기우네가 부유한 박 사장네 집에 하나씩 취업하면서 벌어지는 이야기입니다. \n",
      "\n",
      "Chunk 2: 처음에는 평화로워 보이지만, 이들의 거짓말이 쌓이며 긴장감이 점점 고조됩니다. \n",
      "\n",
      "Chunk 3: 그러나 이 영화의 반전은 지하실에서 시작됩니다. \n",
      "\n"
     ]
    }
   ],
   "source": [
    "from llama_index.core.node_parser import SemanticSplitterNodeParser\n",
    "from llama_index.embeddings.huggingface import HuggingFaceEmbedding\n",
    "\n",
    "embed_model = HuggingFaceEmbedding(model_name=\"sentence-transformers/all-MiniLM-L6-v2\")\n",
    "\n",
    "splitter = SemanticSplitterNodeParser(\n",
    "    buffer_size=1, breakpoint_percentile_threshold=95, embed_model=embed_model\n",
    ")\n",
    "\n",
    "chunks = splitter.sentence_splitter(sample_text)\n",
    "print(\"=== 의미 기반 분할 결과 ===\")\n",
    "for i, chunk in enumerate(chunks):\n",
    "    print(f\"Chunk {i + 1}:\", chunk.strip(), \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "085b86a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core import VectorStoreIndex\n",
    "from llama_index.core import SimpleDirectoryReader\n",
    "\n",
    "reader = SimpleDirectoryReader(\"data\")\n",
    "documents = reader.load_data()\n",
    "\n",
    "# Document 객체를 전달하여 인덱스 생성\n",
    "index = VectorStoreIndex.from_documents(documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "643ac8c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[검색된 상위 3개 문서]\n",
      "\n",
      "[문서 1]\n",
      "고양이는 물을 충분히 마셔야 합니다. 수분이 부족하면 신장 문제가 발생할 수 있습니다.\n",
      "건식 사료보다 습식 사료가 수분 공급에 도움이 됩니다.\n",
      "\n",
      "[문서 2]\n",
      "고양이는 육식 동물입니다. 주로 고기, 생선, 그리고 가공된 고양이 사료를 먹습니다.\n",
      "특히, 단백질이 풍부한 음식을 선호하며, 탄수화물 섭취는 적은 편입니다.\n",
      "\n",
      "[문서 3]\n",
      "고양이는 초콜릿, 양파, 마늘 같은 음식은 먹으면 안 됩니다.\n",
      "특히, 초콜릿에 포함된 테오브로민 성분은 고양이에게 치명적일 수 있습니다.\n",
      "\n",
      "[답변]\n",
      "고양이에게 수분 공급이 중요한 이유는 신장 문제를 예방하기 위해서입니다.\n"
     ]
    }
   ],
   "source": [
    "from llama_index.core import VectorStoreIndex\n",
    "from llama_index.core import SimpleDirectoryReader\n",
    "\n",
    "reader = SimpleDirectoryReader(\"data\")\n",
    "documents = reader.load_data()\n",
    "\n",
    "index = VectorStoreIndex.from_documents(documents)\n",
    "\n",
    "# 상위 3개의 결과를 반환\n",
    "query_engine = index.as_query_engine(similarity_top_k=3)\n",
    "\n",
    "response = query_engine.query(\"고양이에게 수분 공급이 중요한 이유는?\")\n",
    "\n",
    "print(\"[검색된 상위 3개 문서]\")\n",
    "for idx, node in enumerate(response.source_nodes):\n",
    "    print(f\"\\n[문서 {idx+1}]\\n{node.text}\")\n",
    "print(\"\\n[답변]\")\n",
    "\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "6ef10548",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting chromadb\n",
      "  Using cached chromadb-1.0.13-cp39-abi3-macosx_11_0_arm64.whl.metadata (7.0 kB)\n",
      "Collecting build>=1.0.3 (from chromadb)\n",
      "  Using cached build-1.2.2.post1-py3-none-any.whl.metadata (6.5 kB)\n",
      "Requirement already satisfied: pydantic>=1.9 in ./ch02_env/lib/python3.11/site-packages (from chromadb) (2.11.7)\n",
      "Collecting pybase64>=1.4.1 (from chromadb)\n",
      "  Using cached pybase64-1.4.1-cp311-cp311-macosx_11_0_arm64.whl.metadata (8.4 kB)\n",
      "Collecting uvicorn>=0.18.3 (from uvicorn[standard]>=0.18.3->chromadb)\n",
      "  Using cached uvicorn-0.34.3-py3-none-any.whl.metadata (6.5 kB)\n",
      "Requirement already satisfied: numpy>=1.22.5 in ./ch02_env/lib/python3.11/site-packages (from chromadb) (1.26.4)\n",
      "Collecting posthog>=2.4.0 (from chromadb)\n",
      "  Using cached posthog-6.0.0-py3-none-any.whl.metadata (6.0 kB)\n",
      "Requirement already satisfied: typing-extensions>=4.5.0 in ./ch02_env/lib/python3.11/site-packages (from chromadb) (4.14.0)\n",
      "Collecting onnxruntime>=1.14.1 (from chromadb)\n",
      "  Using cached onnxruntime-1.22.0-cp311-cp311-macosx_13_0_universal2.whl.metadata (4.5 kB)\n",
      "Collecting opentelemetry-api>=1.2.0 (from chromadb)\n",
      "  Using cached opentelemetry_api-1.34.1-py3-none-any.whl.metadata (1.5 kB)\n",
      "Collecting opentelemetry-exporter-otlp-proto-grpc>=1.2.0 (from chromadb)\n",
      "  Using cached opentelemetry_exporter_otlp_proto_grpc-1.34.1-py3-none-any.whl.metadata (2.4 kB)\n",
      "Collecting opentelemetry-sdk>=1.2.0 (from chromadb)\n",
      "  Using cached opentelemetry_sdk-1.34.1-py3-none-any.whl.metadata (1.6 kB)\n",
      "Requirement already satisfied: tokenizers>=0.13.2 in ./ch02_env/lib/python3.11/site-packages (from chromadb) (0.21.2)\n",
      "Collecting pypika>=0.48.9 (from chromadb)\n",
      "  Using cached pypika-0.48.9-py2.py3-none-any.whl\n",
      "Requirement already satisfied: tqdm>=4.65.0 in ./ch02_env/lib/python3.11/site-packages (from chromadb) (4.67.1)\n",
      "Collecting overrides>=7.3.1 (from chromadb)\n",
      "  Using cached overrides-7.7.0-py3-none-any.whl.metadata (5.8 kB)\n",
      "Collecting importlib-resources (from chromadb)\n",
      "  Using cached importlib_resources-6.5.2-py3-none-any.whl.metadata (3.9 kB)\n",
      "Collecting grpcio>=1.58.0 (from chromadb)\n",
      "  Using cached grpcio-1.73.1-cp311-cp311-macosx_11_0_universal2.whl.metadata (3.8 kB)\n",
      "Collecting bcrypt>=4.0.1 (from chromadb)\n",
      "  Using cached bcrypt-4.3.0-cp39-abi3-macosx_10_12_universal2.whl.metadata (10 kB)\n",
      "Collecting typer>=0.9.0 (from chromadb)\n",
      "  Using cached typer-0.16.0-py3-none-any.whl.metadata (15 kB)\n",
      "Collecting kubernetes>=28.1.0 (from chromadb)\n",
      "  Using cached kubernetes-33.1.0-py2.py3-none-any.whl.metadata (1.7 kB)\n",
      "Requirement already satisfied: tenacity>=8.2.3 in ./ch02_env/lib/python3.11/site-packages (from chromadb) (8.5.0)\n",
      "Requirement already satisfied: pyyaml>=6.0.0 in ./ch02_env/lib/python3.11/site-packages (from chromadb) (6.0.2)\n",
      "Collecting mmh3>=4.0.1 (from chromadb)\n",
      "  Using cached mmh3-5.1.0-cp311-cp311-macosx_11_0_arm64.whl.metadata (16 kB)\n",
      "Collecting orjson>=3.9.12 (from chromadb)\n",
      "  Using cached orjson-3.10.18-cp311-cp311-macosx_15_0_arm64.whl.metadata (41 kB)\n",
      "Requirement already satisfied: httpx>=0.27.0 in ./ch02_env/lib/python3.11/site-packages (from chromadb) (0.28.1)\n",
      "Collecting rich>=10.11.0 (from chromadb)\n",
      "  Using cached rich-14.0.0-py3-none-any.whl.metadata (18 kB)\n",
      "Collecting jsonschema>=4.19.0 (from chromadb)\n",
      "  Using cached jsonschema-4.24.0-py3-none-any.whl.metadata (7.8 kB)\n",
      "Requirement already satisfied: packaging>=19.1 in ./ch02_env/lib/python3.11/site-packages (from build>=1.0.3->chromadb) (25.0)\n",
      "Collecting pyproject_hooks (from build>=1.0.3->chromadb)\n",
      "  Using cached pyproject_hooks-1.2.0-py3-none-any.whl.metadata (1.3 kB)\n",
      "Requirement already satisfied: anyio in ./ch02_env/lib/python3.11/site-packages (from httpx>=0.27.0->chromadb) (4.9.0)\n",
      "Requirement already satisfied: certifi in ./ch02_env/lib/python3.11/site-packages (from httpx>=0.27.0->chromadb) (2025.6.15)\n",
      "Requirement already satisfied: httpcore==1.* in ./ch02_env/lib/python3.11/site-packages (from httpx>=0.27.0->chromadb) (1.0.9)\n",
      "Requirement already satisfied: idna in ./ch02_env/lib/python3.11/site-packages (from httpx>=0.27.0->chromadb) (3.10)\n",
      "Requirement already satisfied: h11>=0.16 in ./ch02_env/lib/python3.11/site-packages (from httpcore==1.*->httpx>=0.27.0->chromadb) (0.16.0)\n",
      "Requirement already satisfied: attrs>=22.2.0 in ./ch02_env/lib/python3.11/site-packages (from jsonschema>=4.19.0->chromadb) (25.3.0)\n",
      "Collecting jsonschema-specifications>=2023.03.6 (from jsonschema>=4.19.0->chromadb)\n",
      "  Using cached jsonschema_specifications-2025.4.1-py3-none-any.whl.metadata (2.9 kB)\n",
      "Collecting referencing>=0.28.4 (from jsonschema>=4.19.0->chromadb)\n",
      "  Using cached referencing-0.36.2-py3-none-any.whl.metadata (2.8 kB)\n",
      "Collecting rpds-py>=0.7.1 (from jsonschema>=4.19.0->chromadb)\n",
      "  Using cached rpds_py-0.25.1-cp311-cp311-macosx_11_0_arm64.whl.metadata (4.1 kB)\n",
      "Requirement already satisfied: six>=1.9.0 in ./ch02_env/lib/python3.11/site-packages (from kubernetes>=28.1.0->chromadb) (1.17.0)\n",
      "Requirement already satisfied: python-dateutil>=2.5.3 in ./ch02_env/lib/python3.11/site-packages (from kubernetes>=28.1.0->chromadb) (2.9.0.post0)\n",
      "Collecting google-auth>=1.0.1 (from kubernetes>=28.1.0->chromadb)\n",
      "  Using cached google_auth-2.40.3-py2.py3-none-any.whl.metadata (6.2 kB)\n",
      "Collecting websocket-client!=0.40.0,!=0.41.*,!=0.42.*,>=0.32.0 (from kubernetes>=28.1.0->chromadb)\n",
      "  Using cached websocket_client-1.8.0-py3-none-any.whl.metadata (8.0 kB)\n",
      "Requirement already satisfied: requests in ./ch02_env/lib/python3.11/site-packages (from kubernetes>=28.1.0->chromadb) (2.32.4)\n",
      "Collecting requests-oauthlib (from kubernetes>=28.1.0->chromadb)\n",
      "  Using cached requests_oauthlib-2.0.0-py2.py3-none-any.whl.metadata (11 kB)\n",
      "Collecting oauthlib>=3.2.2 (from kubernetes>=28.1.0->chromadb)\n",
      "  Using cached oauthlib-3.3.1-py3-none-any.whl.metadata (7.9 kB)\n",
      "Requirement already satisfied: urllib3>=1.24.2 in ./ch02_env/lib/python3.11/site-packages (from kubernetes>=28.1.0->chromadb) (2.5.0)\n",
      "Collecting durationpy>=0.7 (from kubernetes>=28.1.0->chromadb)\n",
      "  Using cached durationpy-0.10-py3-none-any.whl.metadata (340 bytes)\n",
      "Collecting coloredlogs (from onnxruntime>=1.14.1->chromadb)\n",
      "  Using cached coloredlogs-15.0.1-py2.py3-none-any.whl.metadata (12 kB)\n",
      "Collecting flatbuffers (from onnxruntime>=1.14.1->chromadb)\n",
      "  Using cached flatbuffers-25.2.10-py2.py3-none-any.whl.metadata (875 bytes)\n",
      "Collecting protobuf (from onnxruntime>=1.14.1->chromadb)\n",
      "  Using cached protobuf-6.31.1-cp39-abi3-macosx_10_9_universal2.whl.metadata (593 bytes)\n",
      "Requirement already satisfied: sympy in ./ch02_env/lib/python3.11/site-packages (from onnxruntime>=1.14.1->chromadb) (1.14.0)\n",
      "Collecting importlib-metadata<8.8.0,>=6.0 (from opentelemetry-api>=1.2.0->chromadb)\n",
      "  Using cached importlib_metadata-8.7.0-py3-none-any.whl.metadata (4.8 kB)\n",
      "Collecting googleapis-common-protos~=1.52 (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb)\n",
      "  Using cached googleapis_common_protos-1.70.0-py3-none-any.whl.metadata (9.3 kB)\n",
      "Collecting opentelemetry-exporter-otlp-proto-common==1.34.1 (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb)\n",
      "  Using cached opentelemetry_exporter_otlp_proto_common-1.34.1-py3-none-any.whl.metadata (1.9 kB)\n",
      "Collecting opentelemetry-proto==1.34.1 (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb)\n",
      "  Using cached opentelemetry_proto-1.34.1-py3-none-any.whl.metadata (2.4 kB)\n",
      "Collecting protobuf (from onnxruntime>=1.14.1->chromadb)\n",
      "  Using cached protobuf-5.29.5-cp38-abi3-macosx_10_9_universal2.whl.metadata (592 bytes)\n",
      "Collecting opentelemetry-semantic-conventions==0.55b1 (from opentelemetry-sdk>=1.2.0->chromadb)\n",
      "  Using cached opentelemetry_semantic_conventions-0.55b1-py3-none-any.whl.metadata (2.5 kB)\n",
      "Collecting backoff>=1.10.0 (from posthog>=2.4.0->chromadb)\n",
      "  Using cached backoff-2.2.1-py3-none-any.whl.metadata (14 kB)\n",
      "Requirement already satisfied: distro>=1.5.0 in ./ch02_env/lib/python3.11/site-packages (from posthog>=2.4.0->chromadb) (1.9.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in ./ch02_env/lib/python3.11/site-packages (from pydantic>=1.9->chromadb) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.33.2 in ./ch02_env/lib/python3.11/site-packages (from pydantic>=1.9->chromadb) (2.33.2)\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in ./ch02_env/lib/python3.11/site-packages (from pydantic>=1.9->chromadb) (0.4.1)\n",
      "Collecting markdown-it-py>=2.2.0 (from rich>=10.11.0->chromadb)\n",
      "  Using cached markdown_it_py-3.0.0-py3-none-any.whl.metadata (6.9 kB)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in ./ch02_env/lib/python3.11/site-packages (from rich>=10.11.0->chromadb) (2.19.2)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.16.4 in ./ch02_env/lib/python3.11/site-packages (from tokenizers>=0.13.2->chromadb) (0.33.1)\n",
      "Requirement already satisfied: click>=8.0.0 in ./ch02_env/lib/python3.11/site-packages (from typer>=0.9.0->chromadb) (8.2.1)\n",
      "Collecting shellingham>=1.3.0 (from typer>=0.9.0->chromadb)\n",
      "  Using cached shellingham-1.5.4-py2.py3-none-any.whl.metadata (3.5 kB)\n",
      "Collecting httptools>=0.6.3 (from uvicorn[standard]>=0.18.3->chromadb)\n",
      "  Using cached httptools-0.6.4-cp311-cp311-macosx_11_0_arm64.whl.metadata (3.6 kB)\n",
      "Requirement already satisfied: python-dotenv>=0.13 in ./ch02_env/lib/python3.11/site-packages (from uvicorn[standard]>=0.18.3->chromadb) (1.1.1)\n",
      "Collecting uvloop>=0.15.1 (from uvicorn[standard]>=0.18.3->chromadb)\n",
      "  Using cached uvloop-0.21.0-cp311-cp311-macosx_10_9_universal2.whl.metadata (4.9 kB)\n",
      "Collecting watchfiles>=0.13 (from uvicorn[standard]>=0.18.3->chromadb)\n",
      "  Using cached watchfiles-1.1.0-cp311-cp311-macosx_11_0_arm64.whl.metadata (4.9 kB)\n",
      "Collecting websockets>=10.4 (from uvicorn[standard]>=0.18.3->chromadb)\n",
      "  Using cached websockets-15.0.1-cp311-cp311-macosx_11_0_arm64.whl.metadata (6.8 kB)\n",
      "Collecting cachetools<6.0,>=2.0.0 (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb)\n",
      "  Using cached cachetools-5.5.2-py3-none-any.whl.metadata (5.4 kB)\n",
      "Collecting pyasn1-modules>=0.2.1 (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb)\n",
      "  Using cached pyasn1_modules-0.4.2-py3-none-any.whl.metadata (3.5 kB)\n",
      "Collecting rsa<5,>=3.1.4 (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb)\n",
      "  Using cached rsa-4.9.1-py3-none-any.whl.metadata (5.6 kB)\n",
      "Requirement already satisfied: filelock in ./ch02_env/lib/python3.11/site-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers>=0.13.2->chromadb) (3.18.0)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in ./ch02_env/lib/python3.11/site-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers>=0.13.2->chromadb) (2025.5.1)\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.1.2 in ./ch02_env/lib/python3.11/site-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers>=0.13.2->chromadb) (1.1.5)\n",
      "Collecting zipp>=3.20 (from importlib-metadata<8.8.0,>=6.0->opentelemetry-api>=1.2.0->chromadb)\n",
      "  Using cached zipp-3.23.0-py3-none-any.whl.metadata (3.6 kB)\n",
      "Collecting mdurl~=0.1 (from markdown-it-py>=2.2.0->rich>=10.11.0->chromadb)\n",
      "  Using cached mdurl-0.1.2-py3-none-any.whl.metadata (1.6 kB)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in ./ch02_env/lib/python3.11/site-packages (from requests->kubernetes>=28.1.0->chromadb) (3.4.2)\n",
      "Requirement already satisfied: sniffio>=1.1 in ./ch02_env/lib/python3.11/site-packages (from anyio->httpx>=0.27.0->chromadb) (1.3.1)\n",
      "Collecting humanfriendly>=9.1 (from coloredlogs->onnxruntime>=1.14.1->chromadb)\n",
      "  Using cached humanfriendly-10.0-py2.py3-none-any.whl.metadata (9.2 kB)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in ./ch02_env/lib/python3.11/site-packages (from sympy->onnxruntime>=1.14.1->chromadb) (1.3.0)\n",
      "Collecting pyasn1<0.7.0,>=0.6.1 (from pyasn1-modules>=0.2.1->google-auth>=1.0.1->kubernetes>=28.1.0->chromadb)\n",
      "  Using cached pyasn1-0.6.1-py3-none-any.whl.metadata (8.4 kB)\n",
      "Using cached chromadb-1.0.13-cp39-abi3-macosx_11_0_arm64.whl (17.9 MB)\n",
      "Using cached bcrypt-4.3.0-cp39-abi3-macosx_10_12_universal2.whl (498 kB)\n",
      "Using cached build-1.2.2.post1-py3-none-any.whl (22 kB)\n",
      "Using cached grpcio-1.73.1-cp311-cp311-macosx_11_0_universal2.whl (10.6 MB)\n",
      "Using cached jsonschema-4.24.0-py3-none-any.whl (88 kB)\n",
      "Using cached kubernetes-33.1.0-py2.py3-none-any.whl (1.9 MB)\n",
      "Using cached mmh3-5.1.0-cp311-cp311-macosx_11_0_arm64.whl (40 kB)\n",
      "Using cached onnxruntime-1.22.0-cp311-cp311-macosx_13_0_universal2.whl (34.3 MB)\n",
      "Using cached opentelemetry_api-1.34.1-py3-none-any.whl (65 kB)\n",
      "Using cached opentelemetry_exporter_otlp_proto_grpc-1.34.1-py3-none-any.whl (18 kB)\n",
      "Using cached opentelemetry_exporter_otlp_proto_common-1.34.1-py3-none-any.whl (18 kB)\n",
      "Using cached opentelemetry_proto-1.34.1-py3-none-any.whl (55 kB)\n",
      "Using cached opentelemetry_sdk-1.34.1-py3-none-any.whl (118 kB)\n",
      "Using cached opentelemetry_semantic_conventions-0.55b1-py3-none-any.whl (196 kB)\n",
      "Using cached orjson-3.10.18-cp311-cp311-macosx_15_0_arm64.whl (133 kB)\n",
      "Using cached overrides-7.7.0-py3-none-any.whl (17 kB)\n",
      "Using cached posthog-6.0.0-py3-none-any.whl (104 kB)\n",
      "Using cached pybase64-1.4.1-cp311-cp311-macosx_11_0_arm64.whl (31 kB)\n",
      "Using cached rich-14.0.0-py3-none-any.whl (243 kB)\n",
      "Using cached typer-0.16.0-py3-none-any.whl (46 kB)\n",
      "Using cached uvicorn-0.34.3-py3-none-any.whl (62 kB)\n",
      "Using cached importlib_resources-6.5.2-py3-none-any.whl (37 kB)\n",
      "Using cached backoff-2.2.1-py3-none-any.whl (15 kB)\n",
      "Using cached durationpy-0.10-py3-none-any.whl (3.9 kB)\n",
      "Using cached google_auth-2.40.3-py2.py3-none-any.whl (216 kB)\n",
      "Using cached googleapis_common_protos-1.70.0-py3-none-any.whl (294 kB)\n",
      "Using cached httptools-0.6.4-cp311-cp311-macosx_11_0_arm64.whl (103 kB)\n",
      "Using cached importlib_metadata-8.7.0-py3-none-any.whl (27 kB)\n",
      "Using cached jsonschema_specifications-2025.4.1-py3-none-any.whl (18 kB)\n",
      "Using cached markdown_it_py-3.0.0-py3-none-any.whl (87 kB)\n",
      "Using cached oauthlib-3.3.1-py3-none-any.whl (160 kB)\n",
      "Using cached protobuf-5.29.5-cp38-abi3-macosx_10_9_universal2.whl (418 kB)\n",
      "Using cached referencing-0.36.2-py3-none-any.whl (26 kB)\n",
      "Using cached rpds_py-0.25.1-cp311-cp311-macosx_11_0_arm64.whl (359 kB)\n",
      "Using cached shellingham-1.5.4-py2.py3-none-any.whl (9.8 kB)\n",
      "Using cached uvloop-0.21.0-cp311-cp311-macosx_10_9_universal2.whl (1.4 MB)\n",
      "Using cached watchfiles-1.1.0-cp311-cp311-macosx_11_0_arm64.whl (397 kB)\n",
      "Using cached websocket_client-1.8.0-py3-none-any.whl (58 kB)\n",
      "Using cached websockets-15.0.1-cp311-cp311-macosx_11_0_arm64.whl (173 kB)\n",
      "Using cached coloredlogs-15.0.1-py2.py3-none-any.whl (46 kB)\n",
      "Using cached flatbuffers-25.2.10-py2.py3-none-any.whl (30 kB)\n",
      "Using cached pyproject_hooks-1.2.0-py3-none-any.whl (10 kB)\n",
      "Using cached requests_oauthlib-2.0.0-py2.py3-none-any.whl (24 kB)\n",
      "Using cached cachetools-5.5.2-py3-none-any.whl (10 kB)\n",
      "Using cached humanfriendly-10.0-py2.py3-none-any.whl (86 kB)\n",
      "Using cached mdurl-0.1.2-py3-none-any.whl (10.0 kB)\n",
      "Using cached pyasn1_modules-0.4.2-py3-none-any.whl (181 kB)\n",
      "Using cached rsa-4.9.1-py3-none-any.whl (34 kB)\n",
      "Using cached zipp-3.23.0-py3-none-any.whl (10 kB)\n",
      "Using cached pyasn1-0.6.1-py3-none-any.whl (83 kB)\n",
      "Installing collected packages: pypika, flatbuffers, durationpy, zipp, websockets, websocket-client, uvloop, uvicorn, shellingham, rpds-py, pyproject_hooks, pybase64, pyasn1, protobuf, overrides, orjson, oauthlib, mmh3, mdurl, importlib-resources, humanfriendly, httptools, grpcio, cachetools, bcrypt, backoff, watchfiles, rsa, requests-oauthlib, referencing, pyasn1-modules, posthog, opentelemetry-proto, markdown-it-py, importlib-metadata, googleapis-common-protos, coloredlogs, build, rich, opentelemetry-exporter-otlp-proto-common, opentelemetry-api, onnxruntime, jsonschema-specifications, google-auth, typer, opentelemetry-semantic-conventions, kubernetes, jsonschema, opentelemetry-sdk, opentelemetry-exporter-otlp-proto-grpc, chromadb\n",
      "Successfully installed backoff-2.2.1 bcrypt-4.3.0 build-1.2.2.post1 cachetools-5.5.2 chromadb-1.0.13 coloredlogs-15.0.1 durationpy-0.10 flatbuffers-25.2.10 google-auth-2.40.3 googleapis-common-protos-1.70.0 grpcio-1.73.1 httptools-0.6.4 humanfriendly-10.0 importlib-metadata-8.7.0 importlib-resources-6.5.2 jsonschema-4.24.0 jsonschema-specifications-2025.4.1 kubernetes-33.1.0 markdown-it-py-3.0.0 mdurl-0.1.2 mmh3-5.1.0 oauthlib-3.3.1 onnxruntime-1.22.0 opentelemetry-api-1.34.1 opentelemetry-exporter-otlp-proto-common-1.34.1 opentelemetry-exporter-otlp-proto-grpc-1.34.1 opentelemetry-proto-1.34.1 opentelemetry-sdk-1.34.1 opentelemetry-semantic-conventions-0.55b1 orjson-3.10.18 overrides-7.7.0 posthog-6.0.0 protobuf-5.29.5 pyasn1-0.6.1 pyasn1-modules-0.4.2 pybase64-1.4.1 pypika-0.48.9 pyproject_hooks-1.2.0 referencing-0.36.2 requests-oauthlib-2.0.0 rich-14.0.0 rpds-py-0.25.1 rsa-4.9.1 shellingham-1.5.4 typer-0.16.0 uvicorn-0.34.3 uvloop-0.21.0 watchfiles-1.1.0 websocket-client-1.8.0 websockets-15.0.1 zipp-3.23.0\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.0\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.1.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install chromadb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "d6135578",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to send telemetry event ClientStartEvent: capture() takes 1 positional argument but 3 were given\n"
     ]
    }
   ],
   "source": [
    "import chromadb\n",
    "\n",
    "# 크로마 클라이언트 초기화\n",
    "db = chromadb.PersistentClient(path=\"./chroma_db\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "82f49880",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to send telemetry event ClientCreateCollectionEvent: capture() takes 1 positional argument but 3 were given\n"
     ]
    }
   ],
   "source": [
    "# 컬렉션 생성하기\n",
    "chroma_collection = db.get_or_create_collection(\"quickstart\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "c920559a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting llama-index-vector-stores-chroma\n",
      "  Using cached llama_index_vector_stores_chroma-0.4.2-py3-none-any.whl.metadata (413 bytes)\n",
      "Requirement already satisfied: chromadb>=0.5.17 in ./ch02_env/lib/python3.11/site-packages (from llama-index-vector-stores-chroma) (1.0.13)\n",
      "Requirement already satisfied: llama-index-core<0.13,>=0.12.0 in ./ch02_env/lib/python3.11/site-packages (from llama-index-vector-stores-chroma) (0.12.44)\n",
      "Requirement already satisfied: build>=1.0.3 in ./ch02_env/lib/python3.11/site-packages (from chromadb>=0.5.17->llama-index-vector-stores-chroma) (1.2.2.post1)\n",
      "Requirement already satisfied: pydantic>=1.9 in ./ch02_env/lib/python3.11/site-packages (from chromadb>=0.5.17->llama-index-vector-stores-chroma) (2.11.7)\n",
      "Requirement already satisfied: pybase64>=1.4.1 in ./ch02_env/lib/python3.11/site-packages (from chromadb>=0.5.17->llama-index-vector-stores-chroma) (1.4.1)\n",
      "Requirement already satisfied: uvicorn>=0.18.3 in ./ch02_env/lib/python3.11/site-packages (from uvicorn[standard]>=0.18.3->chromadb>=0.5.17->llama-index-vector-stores-chroma) (0.34.3)\n",
      "Requirement already satisfied: numpy>=1.22.5 in ./ch02_env/lib/python3.11/site-packages (from chromadb>=0.5.17->llama-index-vector-stores-chroma) (1.26.4)\n",
      "Requirement already satisfied: posthog>=2.4.0 in ./ch02_env/lib/python3.11/site-packages (from chromadb>=0.5.17->llama-index-vector-stores-chroma) (6.0.0)\n",
      "Requirement already satisfied: typing-extensions>=4.5.0 in ./ch02_env/lib/python3.11/site-packages (from chromadb>=0.5.17->llama-index-vector-stores-chroma) (4.14.0)\n",
      "Requirement already satisfied: onnxruntime>=1.14.1 in ./ch02_env/lib/python3.11/site-packages (from chromadb>=0.5.17->llama-index-vector-stores-chroma) (1.22.0)\n",
      "Requirement already satisfied: opentelemetry-api>=1.2.0 in ./ch02_env/lib/python3.11/site-packages (from chromadb>=0.5.17->llama-index-vector-stores-chroma) (1.34.1)\n",
      "Requirement already satisfied: opentelemetry-exporter-otlp-proto-grpc>=1.2.0 in ./ch02_env/lib/python3.11/site-packages (from chromadb>=0.5.17->llama-index-vector-stores-chroma) (1.34.1)\n",
      "Requirement already satisfied: opentelemetry-sdk>=1.2.0 in ./ch02_env/lib/python3.11/site-packages (from chromadb>=0.5.17->llama-index-vector-stores-chroma) (1.34.1)\n",
      "Requirement already satisfied: tokenizers>=0.13.2 in ./ch02_env/lib/python3.11/site-packages (from chromadb>=0.5.17->llama-index-vector-stores-chroma) (0.21.2)\n",
      "Requirement already satisfied: pypika>=0.48.9 in ./ch02_env/lib/python3.11/site-packages (from chromadb>=0.5.17->llama-index-vector-stores-chroma) (0.48.9)\n",
      "Requirement already satisfied: tqdm>=4.65.0 in ./ch02_env/lib/python3.11/site-packages (from chromadb>=0.5.17->llama-index-vector-stores-chroma) (4.67.1)\n",
      "Requirement already satisfied: overrides>=7.3.1 in ./ch02_env/lib/python3.11/site-packages (from chromadb>=0.5.17->llama-index-vector-stores-chroma) (7.7.0)\n",
      "Requirement already satisfied: importlib-resources in ./ch02_env/lib/python3.11/site-packages (from chromadb>=0.5.17->llama-index-vector-stores-chroma) (6.5.2)\n",
      "Requirement already satisfied: grpcio>=1.58.0 in ./ch02_env/lib/python3.11/site-packages (from chromadb>=0.5.17->llama-index-vector-stores-chroma) (1.73.1)\n",
      "Requirement already satisfied: bcrypt>=4.0.1 in ./ch02_env/lib/python3.11/site-packages (from chromadb>=0.5.17->llama-index-vector-stores-chroma) (4.3.0)\n",
      "Requirement already satisfied: typer>=0.9.0 in ./ch02_env/lib/python3.11/site-packages (from chromadb>=0.5.17->llama-index-vector-stores-chroma) (0.16.0)\n",
      "Requirement already satisfied: kubernetes>=28.1.0 in ./ch02_env/lib/python3.11/site-packages (from chromadb>=0.5.17->llama-index-vector-stores-chroma) (33.1.0)\n",
      "Requirement already satisfied: tenacity>=8.2.3 in ./ch02_env/lib/python3.11/site-packages (from chromadb>=0.5.17->llama-index-vector-stores-chroma) (8.5.0)\n",
      "Requirement already satisfied: pyyaml>=6.0.0 in ./ch02_env/lib/python3.11/site-packages (from chromadb>=0.5.17->llama-index-vector-stores-chroma) (6.0.2)\n",
      "Requirement already satisfied: mmh3>=4.0.1 in ./ch02_env/lib/python3.11/site-packages (from chromadb>=0.5.17->llama-index-vector-stores-chroma) (5.1.0)\n",
      "Requirement already satisfied: orjson>=3.9.12 in ./ch02_env/lib/python3.11/site-packages (from chromadb>=0.5.17->llama-index-vector-stores-chroma) (3.10.18)\n",
      "Requirement already satisfied: httpx>=0.27.0 in ./ch02_env/lib/python3.11/site-packages (from chromadb>=0.5.17->llama-index-vector-stores-chroma) (0.28.1)\n",
      "Requirement already satisfied: rich>=10.11.0 in ./ch02_env/lib/python3.11/site-packages (from chromadb>=0.5.17->llama-index-vector-stores-chroma) (14.0.0)\n",
      "Requirement already satisfied: jsonschema>=4.19.0 in ./ch02_env/lib/python3.11/site-packages (from chromadb>=0.5.17->llama-index-vector-stores-chroma) (4.24.0)\n",
      "Requirement already satisfied: aiohttp<4,>=3.8.6 in ./ch02_env/lib/python3.11/site-packages (from llama-index-core<0.13,>=0.12.0->llama-index-vector-stores-chroma) (3.12.13)\n",
      "Requirement already satisfied: aiosqlite in ./ch02_env/lib/python3.11/site-packages (from llama-index-core<0.13,>=0.12.0->llama-index-vector-stores-chroma) (0.21.0)\n",
      "Requirement already satisfied: banks<3,>=2.0.0 in ./ch02_env/lib/python3.11/site-packages (from llama-index-core<0.13,>=0.12.0->llama-index-vector-stores-chroma) (2.1.3)\n",
      "Requirement already satisfied: dataclasses-json in ./ch02_env/lib/python3.11/site-packages (from llama-index-core<0.13,>=0.12.0->llama-index-vector-stores-chroma) (0.6.7)\n",
      "Requirement already satisfied: deprecated>=1.2.9.3 in ./ch02_env/lib/python3.11/site-packages (from llama-index-core<0.13,>=0.12.0->llama-index-vector-stores-chroma) (1.2.18)\n",
      "Requirement already satisfied: dirtyjson<2,>=1.0.8 in ./ch02_env/lib/python3.11/site-packages (from llama-index-core<0.13,>=0.12.0->llama-index-vector-stores-chroma) (1.0.8)\n",
      "Requirement already satisfied: filetype<2,>=1.2.0 in ./ch02_env/lib/python3.11/site-packages (from llama-index-core<0.13,>=0.12.0->llama-index-vector-stores-chroma) (1.2.0)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in ./ch02_env/lib/python3.11/site-packages (from llama-index-core<0.13,>=0.12.0->llama-index-vector-stores-chroma) (2025.5.1)\n",
      "Requirement already satisfied: llama-index-workflows<2,>=1.0.1 in ./ch02_env/lib/python3.11/site-packages (from llama-index-core<0.13,>=0.12.0->llama-index-vector-stores-chroma) (1.0.1)\n",
      "Requirement already satisfied: nest-asyncio<2,>=1.5.8 in ./ch02_env/lib/python3.11/site-packages (from llama-index-core<0.13,>=0.12.0->llama-index-vector-stores-chroma) (1.6.0)\n",
      "Requirement already satisfied: networkx>=3.0 in ./ch02_env/lib/python3.11/site-packages (from llama-index-core<0.13,>=0.12.0->llama-index-vector-stores-chroma) (3.5)\n",
      "Requirement already satisfied: nltk>3.8.1 in ./ch02_env/lib/python3.11/site-packages (from llama-index-core<0.13,>=0.12.0->llama-index-vector-stores-chroma) (3.9.1)\n",
      "Requirement already satisfied: pillow>=9.0.0 in ./ch02_env/lib/python3.11/site-packages (from llama-index-core<0.13,>=0.12.0->llama-index-vector-stores-chroma) (11.2.1)\n",
      "Requirement already satisfied: requests>=2.31.0 in ./ch02_env/lib/python3.11/site-packages (from llama-index-core<0.13,>=0.12.0->llama-index-vector-stores-chroma) (2.32.4)\n",
      "Requirement already satisfied: setuptools>=80.9.0 in ./ch02_env/lib/python3.11/site-packages (from llama-index-core<0.13,>=0.12.0->llama-index-vector-stores-chroma) (80.9.0)\n",
      "Requirement already satisfied: sqlalchemy>=1.4.49 in ./ch02_env/lib/python3.11/site-packages (from sqlalchemy[asyncio]>=1.4.49->llama-index-core<0.13,>=0.12.0->llama-index-vector-stores-chroma) (2.0.41)\n",
      "Requirement already satisfied: tiktoken>=0.7.0 in ./ch02_env/lib/python3.11/site-packages (from llama-index-core<0.13,>=0.12.0->llama-index-vector-stores-chroma) (0.9.0)\n",
      "Requirement already satisfied: typing-inspect>=0.8.0 in ./ch02_env/lib/python3.11/site-packages (from llama-index-core<0.13,>=0.12.0->llama-index-vector-stores-chroma) (0.9.0)\n",
      "Requirement already satisfied: wrapt in ./ch02_env/lib/python3.11/site-packages (from llama-index-core<0.13,>=0.12.0->llama-index-vector-stores-chroma) (1.17.2)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in ./ch02_env/lib/python3.11/site-packages (from aiohttp<4,>=3.8.6->llama-index-core<0.13,>=0.12.0->llama-index-vector-stores-chroma) (2.6.1)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in ./ch02_env/lib/python3.11/site-packages (from aiohttp<4,>=3.8.6->llama-index-core<0.13,>=0.12.0->llama-index-vector-stores-chroma) (1.3.2)\n",
      "Requirement already satisfied: attrs>=17.3.0 in ./ch02_env/lib/python3.11/site-packages (from aiohttp<4,>=3.8.6->llama-index-core<0.13,>=0.12.0->llama-index-vector-stores-chroma) (25.3.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in ./ch02_env/lib/python3.11/site-packages (from aiohttp<4,>=3.8.6->llama-index-core<0.13,>=0.12.0->llama-index-vector-stores-chroma) (1.7.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in ./ch02_env/lib/python3.11/site-packages (from aiohttp<4,>=3.8.6->llama-index-core<0.13,>=0.12.0->llama-index-vector-stores-chroma) (6.6.0)\n",
      "Requirement already satisfied: propcache>=0.2.0 in ./ch02_env/lib/python3.11/site-packages (from aiohttp<4,>=3.8.6->llama-index-core<0.13,>=0.12.0->llama-index-vector-stores-chroma) (0.3.2)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in ./ch02_env/lib/python3.11/site-packages (from aiohttp<4,>=3.8.6->llama-index-core<0.13,>=0.12.0->llama-index-vector-stores-chroma) (1.20.1)\n",
      "Requirement already satisfied: griffe in ./ch02_env/lib/python3.11/site-packages (from banks<3,>=2.0.0->llama-index-core<0.13,>=0.12.0->llama-index-vector-stores-chroma) (1.7.3)\n",
      "Requirement already satisfied: jinja2 in ./ch02_env/lib/python3.11/site-packages (from banks<3,>=2.0.0->llama-index-core<0.13,>=0.12.0->llama-index-vector-stores-chroma) (3.1.6)\n",
      "Requirement already satisfied: platformdirs in ./ch02_env/lib/python3.11/site-packages (from banks<3,>=2.0.0->llama-index-core<0.13,>=0.12.0->llama-index-vector-stores-chroma) (4.3.8)\n",
      "Requirement already satisfied: packaging>=19.1 in ./ch02_env/lib/python3.11/site-packages (from build>=1.0.3->chromadb>=0.5.17->llama-index-vector-stores-chroma) (25.0)\n",
      "Requirement already satisfied: pyproject_hooks in ./ch02_env/lib/python3.11/site-packages (from build>=1.0.3->chromadb>=0.5.17->llama-index-vector-stores-chroma) (1.2.0)\n",
      "Requirement already satisfied: anyio in ./ch02_env/lib/python3.11/site-packages (from httpx>=0.27.0->chromadb>=0.5.17->llama-index-vector-stores-chroma) (4.9.0)\n",
      "Requirement already satisfied: certifi in ./ch02_env/lib/python3.11/site-packages (from httpx>=0.27.0->chromadb>=0.5.17->llama-index-vector-stores-chroma) (2025.6.15)\n",
      "Requirement already satisfied: httpcore==1.* in ./ch02_env/lib/python3.11/site-packages (from httpx>=0.27.0->chromadb>=0.5.17->llama-index-vector-stores-chroma) (1.0.9)\n",
      "Requirement already satisfied: idna in ./ch02_env/lib/python3.11/site-packages (from httpx>=0.27.0->chromadb>=0.5.17->llama-index-vector-stores-chroma) (3.10)\n",
      "Requirement already satisfied: h11>=0.16 in ./ch02_env/lib/python3.11/site-packages (from httpcore==1.*->httpx>=0.27.0->chromadb>=0.5.17->llama-index-vector-stores-chroma) (0.16.0)\n",
      "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in ./ch02_env/lib/python3.11/site-packages (from jsonschema>=4.19.0->chromadb>=0.5.17->llama-index-vector-stores-chroma) (2025.4.1)\n",
      "Requirement already satisfied: referencing>=0.28.4 in ./ch02_env/lib/python3.11/site-packages (from jsonschema>=4.19.0->chromadb>=0.5.17->llama-index-vector-stores-chroma) (0.36.2)\n",
      "Requirement already satisfied: rpds-py>=0.7.1 in ./ch02_env/lib/python3.11/site-packages (from jsonschema>=4.19.0->chromadb>=0.5.17->llama-index-vector-stores-chroma) (0.25.1)\n",
      "Requirement already satisfied: six>=1.9.0 in ./ch02_env/lib/python3.11/site-packages (from kubernetes>=28.1.0->chromadb>=0.5.17->llama-index-vector-stores-chroma) (1.17.0)\n",
      "Requirement already satisfied: python-dateutil>=2.5.3 in ./ch02_env/lib/python3.11/site-packages (from kubernetes>=28.1.0->chromadb>=0.5.17->llama-index-vector-stores-chroma) (2.9.0.post0)\n",
      "Requirement already satisfied: google-auth>=1.0.1 in ./ch02_env/lib/python3.11/site-packages (from kubernetes>=28.1.0->chromadb>=0.5.17->llama-index-vector-stores-chroma) (2.40.3)\n",
      "Requirement already satisfied: websocket-client!=0.40.0,!=0.41.*,!=0.42.*,>=0.32.0 in ./ch02_env/lib/python3.11/site-packages (from kubernetes>=28.1.0->chromadb>=0.5.17->llama-index-vector-stores-chroma) (1.8.0)\n",
      "Requirement already satisfied: requests-oauthlib in ./ch02_env/lib/python3.11/site-packages (from kubernetes>=28.1.0->chromadb>=0.5.17->llama-index-vector-stores-chroma) (2.0.0)\n",
      "Requirement already satisfied: oauthlib>=3.2.2 in ./ch02_env/lib/python3.11/site-packages (from kubernetes>=28.1.0->chromadb>=0.5.17->llama-index-vector-stores-chroma) (3.3.1)\n",
      "Requirement already satisfied: urllib3>=1.24.2 in ./ch02_env/lib/python3.11/site-packages (from kubernetes>=28.1.0->chromadb>=0.5.17->llama-index-vector-stores-chroma) (2.5.0)\n",
      "Requirement already satisfied: durationpy>=0.7 in ./ch02_env/lib/python3.11/site-packages (from kubernetes>=28.1.0->chromadb>=0.5.17->llama-index-vector-stores-chroma) (0.10)\n",
      "Requirement already satisfied: llama-index-instrumentation>=0.1.0 in ./ch02_env/lib/python3.11/site-packages (from llama-index-workflows<2,>=1.0.1->llama-index-core<0.13,>=0.12.0->llama-index-vector-stores-chroma) (0.2.0)\n",
      "Requirement already satisfied: click in ./ch02_env/lib/python3.11/site-packages (from nltk>3.8.1->llama-index-core<0.13,>=0.12.0->llama-index-vector-stores-chroma) (8.2.1)\n",
      "Requirement already satisfied: joblib in ./ch02_env/lib/python3.11/site-packages (from nltk>3.8.1->llama-index-core<0.13,>=0.12.0->llama-index-vector-stores-chroma) (1.5.1)\n",
      "Requirement already satisfied: regex>=2021.8.3 in ./ch02_env/lib/python3.11/site-packages (from nltk>3.8.1->llama-index-core<0.13,>=0.12.0->llama-index-vector-stores-chroma) (2024.11.6)\n",
      "Requirement already satisfied: coloredlogs in ./ch02_env/lib/python3.11/site-packages (from onnxruntime>=1.14.1->chromadb>=0.5.17->llama-index-vector-stores-chroma) (15.0.1)\n",
      "Requirement already satisfied: flatbuffers in ./ch02_env/lib/python3.11/site-packages (from onnxruntime>=1.14.1->chromadb>=0.5.17->llama-index-vector-stores-chroma) (25.2.10)\n",
      "Requirement already satisfied: protobuf in ./ch02_env/lib/python3.11/site-packages (from onnxruntime>=1.14.1->chromadb>=0.5.17->llama-index-vector-stores-chroma) (5.29.5)\n",
      "Requirement already satisfied: sympy in ./ch02_env/lib/python3.11/site-packages (from onnxruntime>=1.14.1->chromadb>=0.5.17->llama-index-vector-stores-chroma) (1.14.0)\n",
      "Requirement already satisfied: importlib-metadata<8.8.0,>=6.0 in ./ch02_env/lib/python3.11/site-packages (from opentelemetry-api>=1.2.0->chromadb>=0.5.17->llama-index-vector-stores-chroma) (8.7.0)\n",
      "Requirement already satisfied: googleapis-common-protos~=1.52 in ./ch02_env/lib/python3.11/site-packages (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb>=0.5.17->llama-index-vector-stores-chroma) (1.70.0)\n",
      "Requirement already satisfied: opentelemetry-exporter-otlp-proto-common==1.34.1 in ./ch02_env/lib/python3.11/site-packages (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb>=0.5.17->llama-index-vector-stores-chroma) (1.34.1)\n",
      "Requirement already satisfied: opentelemetry-proto==1.34.1 in ./ch02_env/lib/python3.11/site-packages (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb>=0.5.17->llama-index-vector-stores-chroma) (1.34.1)\n",
      "Requirement already satisfied: opentelemetry-semantic-conventions==0.55b1 in ./ch02_env/lib/python3.11/site-packages (from opentelemetry-sdk>=1.2.0->chromadb>=0.5.17->llama-index-vector-stores-chroma) (0.55b1)\n",
      "Requirement already satisfied: backoff>=1.10.0 in ./ch02_env/lib/python3.11/site-packages (from posthog>=2.4.0->chromadb>=0.5.17->llama-index-vector-stores-chroma) (2.2.1)\n",
      "Requirement already satisfied: distro>=1.5.0 in ./ch02_env/lib/python3.11/site-packages (from posthog>=2.4.0->chromadb>=0.5.17->llama-index-vector-stores-chroma) (1.9.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in ./ch02_env/lib/python3.11/site-packages (from pydantic>=1.9->chromadb>=0.5.17->llama-index-vector-stores-chroma) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.33.2 in ./ch02_env/lib/python3.11/site-packages (from pydantic>=1.9->chromadb>=0.5.17->llama-index-vector-stores-chroma) (2.33.2)\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in ./ch02_env/lib/python3.11/site-packages (from pydantic>=1.9->chromadb>=0.5.17->llama-index-vector-stores-chroma) (0.4.1)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in ./ch02_env/lib/python3.11/site-packages (from requests>=2.31.0->llama-index-core<0.13,>=0.12.0->llama-index-vector-stores-chroma) (3.4.2)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in ./ch02_env/lib/python3.11/site-packages (from rich>=10.11.0->chromadb>=0.5.17->llama-index-vector-stores-chroma) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in ./ch02_env/lib/python3.11/site-packages (from rich>=10.11.0->chromadb>=0.5.17->llama-index-vector-stores-chroma) (2.19.2)\n",
      "Requirement already satisfied: greenlet>=1 in ./ch02_env/lib/python3.11/site-packages (from sqlalchemy[asyncio]>=1.4.49->llama-index-core<0.13,>=0.12.0->llama-index-vector-stores-chroma) (3.2.3)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.16.4 in ./ch02_env/lib/python3.11/site-packages (from tokenizers>=0.13.2->chromadb>=0.5.17->llama-index-vector-stores-chroma) (0.33.1)\n",
      "Requirement already satisfied: shellingham>=1.3.0 in ./ch02_env/lib/python3.11/site-packages (from typer>=0.9.0->chromadb>=0.5.17->llama-index-vector-stores-chroma) (1.5.4)\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in ./ch02_env/lib/python3.11/site-packages (from typing-inspect>=0.8.0->llama-index-core<0.13,>=0.12.0->llama-index-vector-stores-chroma) (1.1.0)\n",
      "Requirement already satisfied: httptools>=0.6.3 in ./ch02_env/lib/python3.11/site-packages (from uvicorn[standard]>=0.18.3->chromadb>=0.5.17->llama-index-vector-stores-chroma) (0.6.4)\n",
      "Requirement already satisfied: python-dotenv>=0.13 in ./ch02_env/lib/python3.11/site-packages (from uvicorn[standard]>=0.18.3->chromadb>=0.5.17->llama-index-vector-stores-chroma) (1.1.1)\n",
      "Requirement already satisfied: uvloop>=0.15.1 in ./ch02_env/lib/python3.11/site-packages (from uvicorn[standard]>=0.18.3->chromadb>=0.5.17->llama-index-vector-stores-chroma) (0.21.0)\n",
      "Requirement already satisfied: watchfiles>=0.13 in ./ch02_env/lib/python3.11/site-packages (from uvicorn[standard]>=0.18.3->chromadb>=0.5.17->llama-index-vector-stores-chroma) (1.1.0)\n",
      "Requirement already satisfied: websockets>=10.4 in ./ch02_env/lib/python3.11/site-packages (from uvicorn[standard]>=0.18.3->chromadb>=0.5.17->llama-index-vector-stores-chroma) (15.0.1)\n",
      "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in ./ch02_env/lib/python3.11/site-packages (from dataclasses-json->llama-index-core<0.13,>=0.12.0->llama-index-vector-stores-chroma) (3.26.1)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in ./ch02_env/lib/python3.11/site-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb>=0.5.17->llama-index-vector-stores-chroma) (5.5.2)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in ./ch02_env/lib/python3.11/site-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb>=0.5.17->llama-index-vector-stores-chroma) (0.4.2)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in ./ch02_env/lib/python3.11/site-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb>=0.5.17->llama-index-vector-stores-chroma) (4.9.1)\n",
      "Requirement already satisfied: filelock in ./ch02_env/lib/python3.11/site-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers>=0.13.2->chromadb>=0.5.17->llama-index-vector-stores-chroma) (3.18.0)\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.1.2 in ./ch02_env/lib/python3.11/site-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers>=0.13.2->chromadb>=0.5.17->llama-index-vector-stores-chroma) (1.1.5)\n",
      "Requirement already satisfied: zipp>=3.20 in ./ch02_env/lib/python3.11/site-packages (from importlib-metadata<8.8.0,>=6.0->opentelemetry-api>=1.2.0->chromadb>=0.5.17->llama-index-vector-stores-chroma) (3.23.0)\n",
      "Requirement already satisfied: mdurl~=0.1 in ./ch02_env/lib/python3.11/site-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->chromadb>=0.5.17->llama-index-vector-stores-chroma) (0.1.2)\n",
      "Requirement already satisfied: sniffio>=1.1 in ./ch02_env/lib/python3.11/site-packages (from anyio->httpx>=0.27.0->chromadb>=0.5.17->llama-index-vector-stores-chroma) (1.3.1)\n",
      "Requirement already satisfied: humanfriendly>=9.1 in ./ch02_env/lib/python3.11/site-packages (from coloredlogs->onnxruntime>=1.14.1->chromadb>=0.5.17->llama-index-vector-stores-chroma) (10.0)\n",
      "Requirement already satisfied: colorama>=0.4 in ./ch02_env/lib/python3.11/site-packages (from griffe->banks<3,>=2.0.0->llama-index-core<0.13,>=0.12.0->llama-index-vector-stores-chroma) (0.4.6)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in ./ch02_env/lib/python3.11/site-packages (from jinja2->banks<3,>=2.0.0->llama-index-core<0.13,>=0.12.0->llama-index-vector-stores-chroma) (3.0.2)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in ./ch02_env/lib/python3.11/site-packages (from sympy->onnxruntime>=1.14.1->chromadb>=0.5.17->llama-index-vector-stores-chroma) (1.3.0)\n",
      "Requirement already satisfied: pyasn1<0.7.0,>=0.6.1 in ./ch02_env/lib/python3.11/site-packages (from pyasn1-modules>=0.2.1->google-auth>=1.0.1->kubernetes>=28.1.0->chromadb>=0.5.17->llama-index-vector-stores-chroma) (0.6.1)\n",
      "Using cached llama_index_vector_stores_chroma-0.4.2-py3-none-any.whl (6.0 kB)\n",
      "Installing collected packages: llama-index-vector-stores-chroma\n",
      "Successfully installed llama-index-vector-stores-chroma-0.4.2\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.0\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.1.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install llama-index-vector-stores-chroma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "fd70261d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.vector_stores.chroma import ChromaVectorStore\n",
    "from llama_index.core import StorageContext\n",
    "\n",
    "# 크로마를 벡터 저장소로 지정\n",
    "vector_store = ChromaVectorStore(chroma_collection=chroma_collection)\n",
    "storage_context = StorageContext.from_defaults(vector_store=vector_store)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "d9f3c825",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to send telemetry event CollectionAddEvent: capture() takes 1 positional argument but 3 were given\n"
     ]
    }
   ],
   "source": [
    "from llama_index.core import VectorStoreIndex\n",
    "\n",
    "# 문서 리스트 (임의의 예시)\n",
    "documents = [\n",
    "    Document(text=\"Llama2 is a large language model developed by Meta.\"),\n",
    "    Document(text=\"Chroma is an open-source vector store.\"),\n",
    "]\n",
    "\n",
    "# 문서를 벡터 스토어 인덱스로 저장\n",
    "index = VectorStoreIndex.from_documents(documents, storage_context=storage_context)\n",
    "\n",
    "# 저장된 벡터 인덱스 데이터 저장\n",
    "index.storage_context.persist(persist_dir=\"./index_data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "8fb60cda",
   "metadata": {},
   "outputs": [],
   "source": [
    "index = VectorStoreIndex.from_vector_store(\n",
    "    vector_store, storage_context=storage_context\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "e710335e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to send telemetry event ClientStartEvent: capture() takes 1 positional argument but 3 were given\n",
      "Failed to send telemetry event ClientCreateCollectionEvent: capture() takes 1 positional argument but 3 were given\n",
      "Failed to send telemetry event ClientStartEvent: capture() takes 1 positional argument but 3 were given\n",
      "Failed to send telemetry event ClientCreateCollectionEvent: capture() takes 1 positional argument but 3 were given\n",
      "Failed to send telemetry event CollectionQueryEvent: capture() takes 1 positional argument but 3 were given\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chroma is an open-source vector store.\n"
     ]
    }
   ],
   "source": [
    "import chromadb\n",
    "from llama_index.core import VectorStoreIndex\n",
    "from llama_index.vector_stores.chroma import ChromaVectorStore\n",
    "from llama_index.core import StorageContext\n",
    "\n",
    "# 크로마 클라이언트 초기화\n",
    "db = chromadb.PersistentClient(path=\"./chroma_db\")\n",
    "\n",
    "# 저장된 컬렉션을 다시 가져오기 (또는 생성하기)\n",
    "chroma_collection = db.get_or_create_collection(\"quickstart\")\n",
    "\n",
    "# 저장된 크로마 벡터 스토어 설정\n",
    "vector_store = ChromaVectorStore(chroma_collection=chroma_collection)\n",
    "storage_context = StorageContext.from_defaults(vector_store=vector_store)\n",
    "\n",
    "# 벡터 스토어 인덱스에 문서를 저장 (데이터 임베딩 후 저장)\n",
    "index = VectorStoreIndex.from_documents(documents, storage_context=storage_context)\n",
    "\n",
    "# 인덱스 데이터를 로컬 디렉터리에 저장\n",
    "index.storage_context.persist(persist_dir=\"./index_data\")\n",
    "\n",
    "# --- 이후 다시 데이터를 불러오고 쿼리 수행 ---\n",
    "\n",
    "# 크로마 클라이언트 다시 초기화\n",
    "db = chromadb.PersistentClient(path=\"./chroma_db\")\n",
    "\n",
    "# 저장된 컬렉션을 다시 가져오기\n",
    "chroma_collection = db.get_or_create_collection(\"quickstart\")\n",
    "\n",
    "# 저장된 크로마 벡터 스토어 설정\n",
    "vector_store = ChromaVectorStore(chroma_collection=chroma_collection)\n",
    "storage_context = StorageContext.from_defaults(vector_store=vector_store)\n",
    "\n",
    "# 4. 저장된 벡터 데이터를 이용해 인덱스를 다시 로드\n",
    "index = VectorStoreIndex.from_vector_store(\n",
    "    vector_store, storage_context=storage_context\n",
    ")\n",
    "\n",
    "# 5. 쿼리 엔진 생성 및 쿼리 수행\n",
    "query_engine = index.as_query_engine()\n",
    "response = query_engine.query(\"What is Chroma?\")\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "640df9e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I can help you create personalized emails based on the customer's personal information.\n"
     ]
    }
   ],
   "source": [
    "query_engine = index.as_query_engine()\n",
    "response = query_engine.query(\n",
    "    \"고객의 개인 정보를 참고하여 맞춤형 이메일을 작성해 주세요.\"\n",
    ")\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "0f28873e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core.retrievers import VectorIndexRetriever\n",
    "\n",
    "retriever = VectorIndexRetriever(\n",
    "    index=index,\n",
    "    similarity_top_k=5,  # 상위 5개의 결과 반환\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "43997a1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core.postprocessor import SimilarityPostprocessor\n",
    "\n",
    "postprocessor = SimilarityPostprocessor(similarity_cutoff=0.7)\n",
    "query_engine = index.as_query_engine(node_postprocessors=[postprocessor])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "526cb274",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core.response_synthesizers import get_response_synthesizer\n",
    "from llama_index.core.query_engine import RetrieverQueryEngine\n",
    "\n",
    "# 응답 합성기 설정\n",
    "response_synthesizer = get_response_synthesizer(response_mode=\"compact\")\n",
    "\n",
    "# 쿼리 엔진 구성\n",
    "query_engine = RetrieverQueryEngine.from_args(\n",
    "    retriever=index.as_retriever(),\n",
    "    response_synthesizer=response_synthesizer,\n",
    ")\n",
    "\n",
    "# 쿼리 실행\n",
    "response = query_engine.query(\"Llama2란?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "2ec83f99",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core import VectorStoreIndex, get_response_synthesizer\n",
    "from llama_index.core.retrievers import VectorIndexRetriever\n",
    "from llama_index.core.query_engine import RetrieverQueryEngine\n",
    "from llama_index.core.postprocessor import SimilarityPostprocessor\n",
    "\n",
    "# 문서를 기반으로 인덱스 생성\n",
    "index = VectorStoreIndex.from_documents(documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "452b82b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 검색기 설정 (상위 10개의 유사한 결과 반환)\n",
    "retriever = VectorIndexRetriever(\n",
    "    index=index,\n",
    "    similarity_top_k=10,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "8a527ea6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 응답 합성기 설정\n",
    "response_synthesizer = get_response_synthesizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "450318c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 후처리 설정 (유사도 0.7 이상인 노드만 선택)\n",
    "postprocessor = SimilarityPostprocessor(similarity_cutoff=0.7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "8937c920",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 쿼리 엔진\n",
    "query_engine = RetrieverQueryEngine(\n",
    "    retriever=retriever,\n",
    "    response_synthesizer=response_synthesizer,\n",
    "    node_postprocessors=[SimilarityPostprocessor(similarity_cutoff=0.7)],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "52636576",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Mona Lisa painting is displayed at the Louvre Museum in Paris, France.\n"
     ]
    }
   ],
   "source": [
    "# 쿼리 실행 및 결과 출력\n",
    "response = query_engine.query(\"모나리자 그림은 어디에 전시되어 있나요?\")\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83a36be3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ch02_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
